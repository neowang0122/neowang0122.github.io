---
dg-publish: true
doc_type: weread-highlights-reviews
bookId: "3300048853"
author: 杜雨 张孜铭
cover: https://weread-1258476243.file.myqcloud.com/weread/cover/89/cpplatform_adrq2ka1kfgsnzsc4etxsb/t7_cpplatform_adrq2ka1kfgsnzsc4etxsb1676455609.jpg
reviewCount: 0
noteCount: 100
isbn: 9787500173458
category: 计算机-人工智能
lastReadDate: 2023-05-30
---
# 元数据
> [!abstract] AIGC：智能创作时代
> - ![ AIGC：智能创作时代|200](https://weread-1258476243.file.myqcloud.com/weread/cover/89/cpplatform_adrq2ka1kfgsnzsc4etxsb/t7_cpplatform_adrq2ka1kfgsnzsc4etxsb1676455609.jpg)
> - 书名： AIGC：智能创作时代
> - 作者： 杜雨 张孜铭
> - 简介： 在人工智能发展的漫长历程中，如何让机器学会创作一直被视为难以逾越的天堑，“创造力”也因此被视为人类与机器最本质的区别之一。然而，人类的创造力也终将赋予机器创造力，把世界送入智能创作的新时代。人工智能绘画作品的夺冠、超级聊天机器人ChatGPT的出现，无疑拉开了智能创作时代的序幕。从机器学习到智能创造，从PGC、UGC到AIGC，我们即将见证一场深刻的生产力变革，而这份变革也会影响我们工作与生活的方方面面。本书将结合生动的比喻和有趣的案例，向所有关注未来科技的从业者、创业者、投资人、政府部门科普AIGC的商业落地场景和行业应用案例。让我们一起迎接全新的智能创作时代。
> - 出版时间 2023-03-01 00:00:00
> - ISBN： 9787500173458
> - 分类： 计算机-人工智能
> - 出版社： 中译出版社

# 高亮划线

## 代序 AIGC和智能数字化新时代——媲美新石器时代的文明范式转型


- 📌 它完成了机器学习算法发展中，自然语言处理领域的历史性跨越，即通过大规模预训练模型，形成人工智能技术理解自然语言和文本生成能力，可以生成文字、语音、代码、图像、视频，且能完成脚本编写、文案撰写、翻译等任务。这是人类文明史上翻天覆地的革命，开启了任何阶层、任何职业都可以以任何自然语言和人工智能交流，并且生产出从美术作品到学术论文的多样化内容产品。在这样的过程中，AIGC“异化”为一种理解、超越和生成各种自然语言文本的超级“系统”。 ^3300048853-17-1567-1782
    - ⏱ 2023-05-20 15:12:16 

- 📌 图0-2　机器学习常用算法资料来源：程序员zhenguo(2023)，“梳理机器学习常用算法（含深度学习）” ^3300048853-17-2505-2594
    - ⏱ 2023-05-21 12:34:08 

- 📌 而在自然语言处理(NLP)系统中，“Transformer”是一种融入注意力机制和神经网络模型领域的主流模型和关键技术。Transformer具有将所处理的任何文字和句子“向量”或者“矢量”化，最大限度反映精准意义的能力。 ^3300048853-17-3019-3130
    - ⏱ 2023-05-21 12:35:05 

- 📌 总之，没有Transformer，就没有NLP的突破；没有大模型化的AIGC,ChatGPT升级就没有可能 ^3300048853-17-3155-3208
    - ⏱ 2023-05-21 12:35:17 

- 📌 图0-4　多种重要、高效的Transformer的集合模型资料来源：Tay et al (2022)，“Efficient Transformers:A Survey”，doi:10.48550/arXiv.2009.06732 ^3300048853-17-3466-3615
    - ⏱ 2023-05-21 12:35:59 

- 📌 第六，AIGC开放性创造力的重要来源是扩散(Diffusion)模型。扩散模型的概念最早在2015年的论文《利用非均衡热力学的深度非监督学习》(Deep Unsupervised Learning Using Nonequilibrium Thermodynamics)中被提出 ^3300048853-17-3640-3807
    - ⏱ 2023-05-21 12:37:40 

- 📌 从技术的角度来看，扩散模型是一个潜在变量(Latent Variable)模型，通过马尔可夫链(Markov chain)映射到潜在空间。[插图]一般来说，AIGC因为吸纳和依赖扩散模型，而拥有开放性创造力。 ^3300048853-17-4268-4562
    - ⏱ 2023-05-21 12:37:55 

- 📌 于Transformer架构等的模型称为“基础模型”(Foundation model)，也常译作大模型。Transformer推动了AI整个范式的转变（图0-5）。 ^3300048853-17-4613-4696
    - ⏱ 2023-05-21 12:38:06 

- 📌 第七，AIGC的进化是参数以几何级数扩展为基础。AIGC的训练过程，就是调整变量和优化参数的过程。所以，参数的规模是重要前提。 ^3300048853-17-5114-5177
    - ⏱ 2023-05-21 12:38:43 

- 📌 AIGC形成的学习能力取决于参数的规模。GPT-2大约有15亿个参数，而GPT-3最大的模型有1 750亿个参数，上升了两个数量级。而且，它不仅参数规模更大，训练所需的数据也更多。根 ^3300048853-17-5326-5417
    - ⏱ 2023-05-21 12:39:32 

- 📌 第八，AIGC的算力需求呈现显著增长。数据、算法、算力是人工智能的稳定三要素。根据OpenAI分析，自2012年以来，6年间AI算力需求增长约30万倍（图0-7）。 ^3300048853-17-5914-5996
    - ⏱ 2023-05-21 12:40:39 

- 📌 AI芯片需要实现CPU、GPU、FPGA和DSP共存 ^3300048853-17-6707-6733
    - ⏱ 2023-05-21 12:41:01 

- 📌 随着AIGC的发展，计算技术的发展不再仅仅依靠通用芯片在制程工艺上的创新，而是结合多种创新方式，形成智能计算和计算智能技术。例如，根据应用需求重新审视芯片、硬件和软件的协同创新，即思考和探索新的计算架构，满足日益巨大、复杂、多元的各种计算场景。其间，量子计算会得到突破性发展。 ^3300048853-17-6734-6872
    - ⏱ 2023-05-21 12:43:58 

- 📌 第十，AIGC将为区块链、NFT、Web3.0和元宇宙带来深层改变。AIGC不可枯竭的创造资源和能力，将从根本上改变目前的NFT概念生态。Web3.0结合区块链、智能合约、加密货币等技术，实现去中心化理念，而AIGC是满足这个目标的最佳工具和模式。 ^3300048853-17-6897-7021
    - ⏱ 2023-05-21 12:44:14 

- 📌 没有悬念，在Web3.0的环境下，AIGC内容将出现指数级增长。元宇宙的本质是社会系统、信息系统、物理环境形态通过数字构成了一个动态耦合的大系统，需要大量的数字内容来支撑，人工来设计和开发根本无法满足需求，AIGC可以最终完善元宇宙生态的底层基础设施。随着AIGC技术的逐渐成熟，传统人类形态不可能进入元宇宙这样的虚拟世界。未来的元宇宙主体将是虚拟人，即经过AIGC技术，特别融合ChatGPT技术，以代码形式呈现的模型化的虚拟人。 ^3300048853-17-7046-7262
    - ⏱ 2023-05-21 12:46:19 

- 📌 伴随AIGC生成算法的优化与改进，AIGC对于普通人来说也不再是一种遥不可及的尖端技术。AIGC在文字、图像、音频、游戏和代码生成中的商业模型渐显。2B（to Business的简称）将是AIGC的主要商业模式，因为它有助于B端提高效率和降低成本，以填补数字鸿沟。 ^3300048853-17-7895-8027
    - ⏱ 2023-05-21 12:48:00 

- 📌 在这样的新兴产业构造和商业模式下，就业市场会发生根本性改变：其一，专业职场重组，相当多的职业可能衰落和消亡；其二，原本支持IT和AI产业的码农队伍面临严重萎缩。因为AIGC将极大地刺激全球外包模式并取代码农 ^3300048853-17-8767-8870
    - ⏱ 2023-05-21 12:48:50 

- 📌 2022年8月的AI绘画作品《太空歌剧院》(Théatre D'opéra Spatial)推动AIGC进入大众视野，那么，ChatGPT的底层模型GPT-3.5是一个划时代的产物。 ^3300048853-17-9575-9694
    - ⏱ 2023-05-21 12:49:43 

- 📌 特别值得关注的是被称为“人工智能激进变革先锋”的BLOOM（大型开放科学获取多语言模型）的诞生。从2021年3月11日到2022年7月6日，60个国家和250多个机构的1 000多名研究人员，在法国巴黎南部的超级计算机上整整训练了117天，创造了BLOOM。这无疑是一场意义深远的历史变革的前奏。 ^3300048853-17-10177-10325
    - ⏱ 2023-05-21 12:50:03 

- 📌 斯坦福大学心理学和计算机科学助理教授丹尼尔·亚明斯(Daniel Yamins)说过：“人工智能网络并没有直接模仿大脑，但最终看起来却像大脑一样，这在某种意义上表明，人工智能和自然之间似乎发生了某种趋同演化。” ^3300048853-17-10350-10455
    - ⏱ 2023-05-21 12:50:13 
## 前言 从机器学习到智能创造


- 📌 不知道你有没有想过这样一个问题：是什么让我们得以思考？从如同一张白纸的婴儿，成长为洞悉世事的成人，正是长辈的教诲和十年寒窗塑造了我们如今的思考力。学习，似乎就是智能形成的最大奥秘。 ^3300048853-18-409-524
    - ⏱ 2023-05-21 12:51:49 

- 📌 如同人类通过学习获得智能一样，自20世纪80年代起，机器学习成为人工智能发展的重要力量。 ^3300048853-18-794-838
    - ⏱ 2023-05-21 12:52:17 

- 📌 机器学习在造福人类的同时，似乎也暴露出了一些问题，这样的人工智能并非人类最终期望的模样，它缺少了人类“智能”二字所涵盖的基本特质——创造力。 ^3300048853-18-901-971
    - ⏱ 2023-05-21 12:52:36 

- 📌 这也让创造力成为区分人类与机器最本质的标准之一。 ^3300048853-18-1069-1093
    - ⏱ 2023-05-21 12:56:21 

- 📌 我们写诗，我们作画，我们谱曲，我们尽情发挥着创造力去描绘我们的所见所闻，我们因此成为人类的一分子，这既是智能的意义，也是我们生活的意义。 ^3300048853-18-1255-1323
    - ⏱ 2023-05-21 12:56:34 
## 第一章 AIGC：内容生产力的大变革


- 📌 几十年前，科学家的普遍观念也许如阿达·洛芙莱斯(Ada Lovelace)所言：“机器不会自命不凡地创造任何事物，它只能根据我们能够给出的任何指令完成任务。 ^3300048853-19-616-694
    - ⏱ 2023-05-21 12:57:28 

- 📌 PGC虽然具有高质量、易变现、针对性强等优势，但也存在着明显的不足。因为专业的质量要求往往导致这类内容创作门槛高、制作周期长，由此带来了产量不足、多样性有限的问题。此外，由于生产成本高，采购平台或用户通常需要支付相对较高的成本来获取内容，从而导致普通用户的日常高频次、多样化的内容消费需求无法得到满足。基于上述原因，互联网需要新的内容生产形式来解决这些问题。 ^3300048853-19-2682-2861
    - ⏱ 2023-05-21 13:11:57 

- 📌 与PGC类似，UGC突出的内容优势也必然伴随着不可避免的痛点，极其丰富的内容背后存在着内容质量参差不齐的问题，平台方需要投入大量精力和成本去进行创作者教育、内容审核、版权把控等方面的工作。此外，虽然从平台层面，内容生产供给的问题得到了解决，但对于每个创作者个体而言，依然面临着内容质量、原创程度和更新频率的不可能三角，即上述三个方面不可能同时做到。相较于PGC的团队工作，UGC的创作者很多都是单打独斗，难以在保证内容质量、原创程度的情况下还能兼顾更新频率。而与此同时，创作者数量的增多使竞争变得更加激烈，许多创作者不得不选择降低质量、洗稿抄袭等捷径，用高频率的更新留住关注者。长此以往，健康的创作生态将遭到破坏，这种创作者的窘境呼吁着内容生产方式的全新变革，生产效率的提升已迫在眉睫。 ^3300048853-19-3547-3890
    - ⏱ 2023-05-23 15:37:01 

- 📌 生成式人工智能(Generative AI)， ^3300048853-19-4296-4319
    - ⏱ 2023-05-23 15:38:10 

- 📌 主要研究人工智能如何被用于创建文本、音频、图像、视频等各种模态的信息 ^3300048853-19-4319-4353
    - ⏱ 2023-05-23 15:38:20 

- 📌 AI文本生成的方式大体分为两类：非交互式文本生成与交互式文本生成。非交互式文本生成的主要应用方向包括结构化写作（如标题生成与新闻播报）、非结构化写作（如剧情续写与营销文本）、辅助性写作。其中，辅助性写作主要包括相关内容推荐及润色帮助，通常不被认为是严格意义上的AIGC。交互式文本生成则多用于虚拟男/女友、心理咨询、文本交互游戏等涉及互动的场景。前 ^3300048853-19-7070-7269
    - ⏱ 2023-05-24 07:53:40 

- 📌 AI不具备个人色彩，行文相对严谨、客观，因此在地震信息播报、体育快讯报道、公司年报数据、股市讯息等领域具有较大优势。 ^3300048853-19-7326-7384
    - ⏱ 2023-05-24 07:53:51 

- 📌 AI结构化写作还可以被用于生成自动标题与摘要，它可以通过自然语言处理（Natural Language Processing，简称NLP）对一篇纯文本内容进行读取与加工，从而生成标题与摘要。 ^3300048853-19-7520-7615
    - ⏱ 2023-05-24 07:59:51 

- 📌 ChatGPT具有很强的上下文连接与多轮对话的能力。ChatGPT还具有记忆能力，当向它追问“能不能再夸张一点”时，它可以在之前生成的文案基础上进行改写。这种连续对话大幅提高了人机交互体验。 ^3300048853-19-13289-13384
    - ⏱ 2023-05-24 08:03:11 

- 📌 人们迫切希望打造一个与现实世界相平行、高度沉浸化的虚拟世界。这样一个“世界级”的工程项目，单靠人力创作可能难以做到尽善尽美，而AIGC的介入将可能大大提升元宇宙的构建效率 ^3300048853-19-24266-24351
    - ⏱ 2023-05-24 08:10:33 

- 📌 人们迫切希望打造一个与现实世界相平行、高度沉浸化的虚拟世界。这样一个“世界级”的工程项目，单靠人力创作可能难以做到尽善尽美，而AIGC的介入将可能大大提升元宇宙的构建 ^3300048853-19-24266-24349
    - ⏱ 2023-05-24 08:10:30 
## 第二章 AIGC的技术思想


- 📌 人们总喜欢活在舒适区内，用粗暴的断言安慰自己，例如机器永远无法模仿人类的某些特性。但我给不了这样的安慰，因为我认为并不存在无法模仿的人类特性。——艾伦·图灵(Alan Turing) ^3300048853-20-463-585
    - ⏱ 2023-05-24 13:28:11 

- 📌 而图灵就在论文中提出，在用机器替换人类的情况下，根据小明这类角色回答错误概率有没有显著增加，可以评估这个替换的机器是否具备智能，这也就是著名的“图灵测试”（图2-1 ^3300048853-20-1745-1827
    - ⏱ 2023-05-24 13:29:35 

- 📌 在人工智能诞生早期，就出现了“符号主义”和“联结主义”两种不同的发展流派，并都取得了一系列阶段性的成果。符号主义认为人的智能来自逻辑推理，世界上所有信息都可以抽象为各种符号，而人类的认知过程可以看作运用逻辑规则操作这些符号的过程。在这样的前提假设下，如果计算机能够自动化地执行和人脑一样的各种规则，说不定就可以实现完全的智能化。 ^3300048853-20-2580-2769
    - ⏱ 2023-05-24 18:02:36 

- 📌 而联结主义则认为，让机器模拟人类智能的关键不是去想办法实现跟思考有关的功能，而是应该模仿人脑的结构。联结主义把智能归结为人脑中神经元彼此联结成网络共同处理信息的结果，希望能够运用计算机模拟出神经网络的工作模式来打造人工智能，并在“人工智能”领域正式形成之前就开始了各种尝试。 ^3300048853-20-2911-3048
    - ⏱ 2023-05-24 18:02:59 

- 📌 可以说，不论是符号主义还是联结主义，在人工智能诞生的前十余年，都取得了一个又一个令人震惊的成果，但好景不长，20世纪60年代末，人工智能的发展陷入瓶颈，人工智能的研究者遇到了很多难以克服的难题，其中包括两个最典型的难题：·受限的计算能力：当时计算机有限的内存和处理速度不足以支持AI算法的实际应用。·认知信息的匮乏：许多人工智能领域的应用需要大量认知信息，当时的数据库条件无法让程序获得如此丰富的信息源。 ^3300048853-20-3276-3532
    - ⏱ 2023-05-24 18:04:28 

- 📌 而对于联结主义，明斯基指出了感知器的致命缺陷：只能处理线性分类问题，连异或最简单的非线性分类问题无法得到支持，直接宣判了感知器的“死刑” ^3300048853-20-3674-3742
    - ⏱ 2023-05-24 18:04:42 

- 📌 1950年，图灵在他的论文《计算机器与智能》中提出了“学习机器”的概念，强调与其去编程模拟成人的大脑，还不如选择更简单的儿童大脑，通过辅之以惩罚和奖励的教学过程，让机器在学习后具备智能。此后，“机器学习”逐渐发展成为一个专门的细分研究领域，在人工智能领域占据了一席之地。 ^3300048853-20-5074-5209
    - ⏱ 2023-05-24 18:06:26 

- 📌 综上所述，机器学习模型的训练过程可以分为以下四步。·数据获取：为机器提供用于学习的数据。·特征工程：提取出数据中的有效特征，并进行必要的转换。·模型训练：学习数据，并根据算法生成模型。·评估与应用：将训练好的模型应用在需要执行的任务上并评估其表现，如果取得了令人满意的效果就可以投入应用。 ^3300048853-20-5647-5899
    - ⏱ 2023-05-24 18:07:23 

- 📌 根据训练的方式，机器学习可以简单划分为监督学习和无监督学习。监督学习就好比小明每次做完题之后，老师都会对题目进行批改，让小明知道每道题是否答对。分类就是最经典的监督学习场景，机器先学习具备什么样特征的数据属于什么样的类别，然后当获取新的数据后，它就可以根据数据特征将数据划分到正确的类别。而无监督学习则好比老师把大量题目直接丢给小明，让小明在题海中自己发现题目规律，当题量足够大的时候，小明虽然不能完全理解每道题，但也会发现一些知识点的固定的选项表述。聚类是最经典的无监督学习场景，机器获得数据后并不知道每种特征的数据分别属于什么类别，而是根据数据特征之间的相似或相异等关系，自动把数据划分为几个类别。 ^3300048853-20-5924-6225
    - ⏱ 2023-05-24 18:07:49 

- 📌 人工神经网络也需要在训练数据的过程中反复调整各神经元连接的权重，以完成模型的学习过程。而调整的依据是对比数据和模型的结果来查看神经网络有没有犯错误。如果在数据上存在误差，就相当于造成了损失，输出每个样本数据损失的函数叫作损失函数(Loss Function)。而所有的损失综合在一起的平均情况，会反应在代价函数(Cost Function)里，描述训练这一个模型产生的错误代价。 ^3300048853-20-8248-8437
    - ⏱ 2023-05-24 18:11:20 

- 📌 强化学习的概念强化学习是机器学习除监督学习与无监督学习之外的又一领域，也可以与深度学习结合进行深度强化学习。区别于监督学习和无监督学习，强化学习并不是要对数据本身进行学习，而是在给定的数据环境下，让智能体学习如何选择一系列行动，来达成长期累计收益最大化的目标。强化学习本质上学习的是一套决策系统而非数据本身。它与监督学习、无监督学习的区别如表2-1所示。 ^3300048853-20-8705-8908
    - ⏱ 2023-05-24 18:12:05 

- 📌 整个强化学习的过程，是为了学到好的策略(Policy)，本质上就是学习在某个状态下应该选择什么样的行动 ^3300048853-20-10535-10586
    - ⏱ 2023-05-24 18:13:27 

- 📌 在构建策略时，还有一个需要考虑的关键因素叫作价值(Value)，它反映的是将来能够获得所有奖励的期望值。例如，马里奥为了达成目标，获得更多的奖励，所以应该选择多进入高价值的状态，并且在高价值状态下选择能够产生高价值的行动。 ^3300048853-20-10694-10805
    - ⏱ 2023-05-24 18:13:44 

- 📌 经过前面对机器学习的介绍，我们可以知道，特征的选取和处理对于模型训练是十分重要的，但在一些场景下，想要直接提取出合适的有效特征无疑是非常困难的，比如提取图片和句子的特征。在这种情况下，机器需要学习的并不是图片中的颜色数量、图形大小，或是句子里的词语数量等这种浅层次的特征，而是需要学习深藏在图片像素之间的复杂关系，或是句子中词语之间的上下文联系。人类无法自行处理这种深层特征的提取转换，而是需要由有深度的模型进行自动计算，采用的模型主要是复杂化了的神经网络，也被称为深度神经网络。而所谓的深度学习，简单理解就是采用像深度神经网络这样有深度的层次结构进行机器学习的方法，是机器学习的一个子领域。深度学习与无监督学习、监督学习及强化学习的关系如图2-6所示。 ^3300048853-20-11939-12266
    - ⏱ 2023-05-24 18:15:17 

- 📌 深度神经网络与一般神经网络的区别根据前面的描述，可以得出深度神经网络和一般神经网络的四点区别：·深度神经网络具有更多的神经元。·深度神经网络层次更多、连接方式更复杂。·深度神经网络需要更庞大的计算能力加以支持。·深度神经网络能够自动提取特征 ^3300048853-20-12682-12936
    - ⏱ 2023-05-24 18:15:58 

- 📌 生成器我们可以向生成器(Generator)输入包含一串随机数的向量，生成器会根据这一串随机数生成并输出图像或句子。向量里的每一个数字都会与生成的图像或句子的特征相关联。打一个并不严谨的比方，假设生成器收到的输入是[0.1,-0.5,0.2 … 0.9]，据此生成了一张小猫的图片，而第一个数是和小猫的颜色相关的，当你把0.1换成0.2时，小猫可能就从橘猫变成了白猫。因为随机数是可以随意构造的，因此我们就可以利用生成器生成各种各样的新图片。不过，和一般的神经网络一样，在生成之前会有提前训练的过程，我们需要准备一个全是各种各样小猫图片的数据集供生成器训练。二　判别器判别器(Discriminator)用于评价生成器生成的图像或句子到底看起来有多么真实。判别是否真实的方式也很简单，就是看这个图像或句子像不像来自生成器训练用的数据集，因为数据集是最真实的。我们可以向判别器输入一个生成的图像或句子，判别器会输出一个数值（也被称为得分）。一般来说，我们会使用0到1的区间来表示得分，如果这个图像或句子非常像数据集里的真实数据，得分就会靠近1；反之，得分就会靠近0。三　生成对抗过程以图像生成的过程为例，生成器就好像一个学习画画的学生，而判别器就是评价学生画作的老师。一开始，学生读一年级，他看了一堆小猫的图片，然后随便画了一只猫，老师看了看学生画的猫，说画得不够逼真，看不清小猫的两只眼睛，这就是最开始的生成器和判别器的交互过程。学生努力练习画画，终于画好了小猫的两只眼睛，老师一看说合格了，然后学生升到了二年级，老师也开始依照二年级的评价标准去评价学生的画作，相当于生成器和判别器的性能都提升了。升到二年级后，学生再拿出原来的小猫画作肯定就无法令老师满意了，老师会觉得画得不够真实，无法看清小猫的脸部轮廓，于是学生又反复练习修改，直到令老师满意，于是学生升到三年级。如此循环往复，学生画画的水平会越来越精湛，画作看起来越来越真实。而老师判别画作的标准也会越来越严苛，督促学生完善画技，这就是生成器和判别器对抗过程的基本思想（图2-7）。而就具体的实现过程来说，可以把GAN的训练过程分为两个步骤。[插图] ^3300048853-20-13377-14651
    - ⏱ 2023-05-24 18:18:11 

- 📌 Diffusion模型的基本原理Diffusion模型是一类应用于细粒度图像生成的模型，尤其是在跨模态图像的生成任务中，已逐渐替代GAN成为主流。 ^3300048853-20-16320-16419
    - ⏱ 2023-05-24 18:21:25 

- 📌 传统的GAN虽然已经能较好地完成与图像相关的生成任务，但依然存在以下诸多问题。·需要同时训练生成器和判别器这两个深度神经网络，训练难度较大。·生成器的核心目标是骗过判别器，因而可能会选择走捷径，学到一些并不希望被学到的特征，模型并不稳定，有可能会生成奇怪的结果。·生成器生成的结果通常具备较差的多样性，因为具有多样性的结果不利于骗过判别器。 ^3300048853-20-16519-16770
    - ⏱ 2023-05-24 18:21:59 

- 📌 那么换一个角度去思考，既然任何一张图像都可以在不断添加噪声后，变成一张完全随机的噪声图像，那我们能不能将这个过程翻转，让神经网络学习这个噪声扩散的过程之后逆向扩散，把随机生成的噪声图像，逐渐转化为清晰的生成图像呢？Diffusion模型就是基于这个思想实现的。 ^3300048853-20-16964-17094
    - ⏱ 2023-05-24 18:23:06 

- 📌 Stable Diffusion对于生成当代艺术图像具有较强的理解力，善于刻画图像的细节，但为了还原这些细节，它在图像描述上需要进行非常复杂细致的说明，比较适合生成涉及较多创意细节的复杂图像，在创作普通图像时可能会略显乏力。 ^3300048853-20-19158-19270
    - ⏱ 2023-05-24 18:24:32 

- 📌 人工智能领域的注意力机制一开始主要用于图像标注领域，后续被引入到自然语言处理领域，主要是为了解决机器翻译的问题。虽然Seq2Seq模型可以实现将一种语言翻译为另一种语言，但随着句子长度的增加，翻译的性能将急剧恶化，这主要是因为很难用固定长度的向量去概括长句子里的所有细节，实现这一点需要足够大的深度神经网络和漫长的训练时间。为了解决这一问题，学者们引入了注意力机制。 ^3300048853-20-21551-21734
    - ⏱ 2023-05-24 18:26:47 

- 📌 无论是观看图像还是阅读文字，人们都会有选择性地关注一小部分重点内容，并忽略另一部分不重要的内容。从数学的角度来说，可以将“注意力”理解为一种“权重”，在理解图片或文本时，大脑会赋予对于认知有重要意义的内容高权重，赋予不重要的内容低权重，在不同的上下文中专注不同的信息，这样可以帮助人们更好地理解信息，同时还能降低信息处理的难度。这就是注意力机制，这种机制被应用在人工智能领域，帮助机器更好地解决图像处理和文本处理方面的一些问题。 ^3300048853-20-22217-22431
    - ⏱ 2023-05-24 18:27:50 

- 📌 阅读完这段话之后，你一定发现，虽然图片上的语句是乱序的，但是并没有干扰你的阅读，这种现象原理与人工智能的自注意力(Self-Attention)机制非常相近，下面我们用通俗易懂的语言对这套机制进行分析。首先，你的眼睛捕捉到了第一个字“研”，并且扫过那一行的后续文字“表”“究”“明”。然后，大脑在过去学习的认知库里去搜寻“研表”“研究”“研明”等，发现“研究”两个字关联最为紧密，所以就给了它较高的权重进行编码计算，并按类似的方式完成后续内容的编码。编码完毕后，按照权重对内容进行重新组装，信息也就组合成了“研究表明”这一常见用法。通过这种自注意力机制，人工智能可以很好地捕捉文本内在的联系并进行再表示 ^3300048853-20-22779-23080
    - ⏱ 2023-05-24 18:28:52 

- 📌 而除了自注意力机制，另外一种广泛应用于人工智能领域的注意力机制叫作多头注意力(Multi-Head Attention)机制。多头注意力机制主要通过多种变换进行加权计算，然后将计算结果综合起来，增强自注意力机制的效果。 ^3300048853-20-23081-23190
    - ⏱ 2023-05-24 18:30:13 

- 📌 在GPT-1诞生之前，大部分自然语言处理模型如果想要学习大量样本，基本上都是采用监督学习的方式对模型进行训练，这不仅要求大量高质量的标注数据，而且因为这类标注数据往往具有领域特性，很难训练出具有通用性的模型 ^3300048853-20-25220-25323
    - ⏱ 2023-05-24 18:37:58 

- 📌 在GPT-1诞生之前，大部分自然语言处理模型如果想要学习大量样本，基本上都是采用监督 ^3300048853-20-25220-25262
    - ⏱ 2023-05-24 18:37:53 

- 📌 为了解决这一问题，GPT-1的核心思想是将无监督学习作用于监督学习模型的预训练目标，先通过在无标签的数据上学习一个通用的语言模型，然后再根据问答和常识推理、语义相似度判断、文本分类、自然语言推理等特定语言处理任务对模型进行微调，来实现大规模通用语言模型的构建，这可以理解成一种半监督学习的形式。 ^3300048853-20-25324-25471
    - ⏱ 2023-05-24 18:38:29 

- 📌 为了增强GPT模型的泛化能力，GPT-2在GPT-1的基础上进行了技术思想上的优化。GPT-2的核心出发点是：在语言模型领域，所有监督学习都可以看作无监督学习的子集。例如，把“小明是A省2022年高考状元”丢给算法做无监督学习，但是它也能学会完成“A省2022年高考状元是谁？”“小明是2022年哪个省的高考状元？”等需要标注正确答案的监督学习任务。因此，当模型的容量非常大且数据量足够丰富时，一个无监督学习的语言模型就可以覆盖所有监督学习的任务 ^3300048853-20-25692-25915
    - ⏱ 2023-05-24 18:39:34 

- 📌 GPT-3基本上沿用了GPT-2的结构，但在参数量和训练数据集上进行了大幅增加，参数量增加了百倍以上，预训练数据增加了千倍以上。在这样夸张的增幅下，GPT-3也最终实现了“大力出奇迹”，在自动问答、语义推断、机器翻译、文章生成等领域达到了前所未有的性能。 ^3300048853-20-26057-26184
    - ⏱ 2023-05-24 18:40:13 

- 📌 InstructGPT的主要优化方式是从人类反馈中进行强化学习（Reinforcement Learning from Human Feedback，简称RLHF）。而ChatGPT采用了和 InstructGPT一样的方法，只是调整了数据收集方式。 ^3300048853-20-26339-26464
    - ⏱ 2023-05-24 18:40:36 
## 第三章 AIGC的职能应用


- 📌 除了优化现有代码之外，人工智能根据不同种类的用户设备生成新的代码也是一个潜在的应用场景。尽管这个场景目前还没有出现被广泛使用的应用，但是对企业而言也意味着巨大的生产力提升。例如，许多互联网企业在开发一个新的程序时往往要对同一个应用进行数次开发，由完全不同的团队输出完全不同的代码以确保用户可以在不同设备上使用，仅仅移动端中需要考虑的环境就包括移动网页端、安卓、苹果、小程序等。与手动编写和迁移代码相比，人工智能的应用可以为开发人员节省大量的时间和精力。总的来说，通过为开发人员提供快速生成和优化代码的能力，AIGC可以帮助他们专注于工作中最重要和最具挑战性的方面，使他们能够更快、更容易地创建更好的软件。 ^3300048853-21-3129-3456
    - ⏱ 2023-05-24 18:48:43 

- 📌 在文字的基础之上，自然语言处理则可以帮助企业建立AI智能外呼系统，让人工智能主动对外拨打电话联系到更多的潜在客户，大幅度降低企业的成本。总部位于南京的云蝠智能(Telrobot)便是一个被很多企业使用的AI智能外呼系统，帮助企业打通更高效的销售流程。 ^3300048853-21-8858-8983
    - ⏱ 2023-05-26 14:23:04 

- 📌 让人工智能主动对外拨打电话联系到更多的潜在客户，大幅度降低企业的成本。总部位于南京的云蝠智能(Telrobot)便是一个被很多企业使用的AI智能外呼系统，帮助企业打通更高效的销售流程。AIGC工具还可 ^3300048853-21-8891-9016
    - ⏱ 2023-05-26 14:23:00 
## 第五章 AIGC的产业地图


- 📌 ClickHouse的主要产品是一个开源的列式数据库，在列式数据库中，数据按列进行物理分组和存储，从而最大限度地减少了磁盘访问次数并提高了性能，因为处理特定查询时每次只需要读取一小部分数据。此外，由于每一列都包含相同类型的数据，因此也可以使用有效的压缩机制降低存储成本。而正是这些独特的技术特性让ClickHouse受到了资本市场的充分关注。 ^3300048853-23-5079-5250
    - ⏱ 2023-05-30 20:04:11 

- 📌 Imply是一家基于Apache Druid提供数据查询与实时处理服务的公司。Apache Druid是一个实时分析型数据库，最初主要面向广告行业的数据存储、查询需求，因为广告数据对数据的实时性要求很高，对广告主而言，及时衡量曝光、点击、转化等关键指标有助于快速评估广告投放的效果，进而对广告投放策略进行调整。尤其是在自媒体时代，网络热词的时效性、用户的注意力、网红达人的生命周期都变短，这使得广告业对数据访问和处理的实时性要求变得越来越高 ^3300048853-23-5275-5495
    - ⏱ 2023-05-30 20:04:28 

- 📌 这个环节对数据的处理主要包括提取（Extract，简称E）、加载（Load，简称L）和转换（Transform，简称T）三个模块，因此产业界通常将该环节称为ELT或ETL ^3300048853-23-5682-5767
    - ⏱ 2023-05-30 20:04:28 

- 📌 ·提取：从各种来源获取数据。·加载：将数据移动至目标位置。·转换：处理和组织数据，使其具备业务可用性。 ^3300048853-23-5849-5954
    - ⏱ 2023-05-30 20:04:26 

- 📌 而知识型文本处理应用则更注重信息的“输入”，帮助用户更好地进行信息的归纳、接收和整理，就好比一个小学生在写作业之前，要用思维导图等工具把上课学到的知识点整理好，内化为之后写作业、考试可以用到的技能，但这个过程可能需要花费很长时间，去不同的教材、笔记本、错题本上搜索信息。 ^3300048853-23-21363-21498
    - ⏱ 2023-05-30 20:04:30 

- 📌 对于企业员工来说，搜索信息、管理信息一直是一件耗费精力的事，因为员工把大量时间花在了“重新发明轮子”上。一些人工智能文本生成工具就专注于解决这个问题 ^3300048853-23-21498-21572
    - ⏱ 2023-05-30 20:04:16 

- 📌 Boomy使用由AI驱动的音乐自动化技术，让用户在几秒钟内免费创建和保存原创歌曲，创建的歌曲可以在Spotify、Apple Music、TikTok和YouTube等主要流媒体服务中传播，创作者可以获得版税分成，而Boomy拥有版权 ^3300048853-23-26430-26547
    - ⏱ 2023-05-30 20:04:05 

- 📌 图片因其创作门槛比文字高，信息传递更直观，所以在传统商业世界中的商业化潜力总体而言比文字更高。随着越来越多的AIGC相关技术应用到图片创作领域，图像处理也将从广告、设计、编辑等角度带来产业的商业化机遇。 ^3300048853-23-28053-28154
    - ⏱ 2023-05-30 20:04:27 

- 📌 Stable Diffusion是Stability AI公司旗下的产品，具备强大的图像生成能力和开源属性，这使它成为众多广告从业者生成图片的生产力工具。相比订阅制的Midjourney、付费也未必能用得上的DALL·E 2,Stable Diffusion凭借极为罕见的开源特征，积累了相当规模的用户群体和开源社区资源。Stability AI的创始人兼首席执行官埃马德·莫斯塔克(Emad Mostaque)具有优良的教育背景与工作背景，不仅取得了牛津大学的数学与计算机硕士学位，还曾担任多家对冲基金经理，而对冲基金也是Stability AI早期的资金来源之一。截至2022年10月，Stablility.AI已获得来自Coatue和光速的1.01亿美元投资，且估值将达10亿美元。Stablility.AI目前已与亚马逊云科技达成合作，继续构建图像、语言、音频、视频和3D内容生成模型。 ^3300048853-23-28340-28737
    - ⏱ 2023-05-30 20:04:11 

- 📌 随着5G时代的到来，人们花在视频上的时间已经逐渐超过图文，视频也正在成为移动互联网时代最主流的内容消费形态。因此，利用AI生成视频是应用拓展层的赛点，也是技术难度最大的模态。 ^3300048853-23-30779-30866
    - ⏱ 2023-05-30 20:04:13 

- 📌 虚拟人型视频处理是视频处理中一个特殊的细分赛道，主打为视频生成虚拟形象。这个赛道有两家典型公司：Hour One和Synthesia ^3300048853-23-32671-32737
    - ⏱ 2023-05-30 20:04:10 

- 📌 让Hour One一战成名的是在2020年国际消费类电子产品展览会(CES)中的“真实或合成”(real or synthetic)相似度测试，Hour One合成的虚拟人和真实人类看起来几乎没有差别。 ^3300048853-23-33000-33101
    - ⏱ 2023-05-30 20:04:08 

- 📌 同年，Hour One获得种子轮500万美元的融资。2022年4月，Hour One完成了A轮2 000万美元的融资。目前，Hour One的主要产品是Reals自助服务平台，主要功能包括创建虚拟人，以及输入文本自动生成相应的AI虚拟人演讲视频 ^3300048853-23-33101-33223
    - ⏱ 2023-05-30 20:04:02 
## 第六章 AIGC的未来


- 📌 一　大模型的广泛应用人工智能的发展经历过多次春天与寒冬，每一次春天与寒冬的交织都与“通用化”和“专用化”的分歧息息相关。一方面，“通用化”人工智能代表着人类对于未来的美好畅想，但在每个阶段都会遇到不可跨越的瓶颈；另一方面，“专业化”人工智能可以带来更好的应用落地，但从技术演进的发展周期来看，它只是帮助科技开枝散叶的加速器，并非科技应该奔赴的未来。在“通用化”与“专业化”矛盾交织的过程中，人工智能的技术一直进步着 ^3300048853-24-915-1148
    - ⏱ 2023-05-30 20:04:14 

- 📌 而当我们将眼光收束到20世纪的前二十年，我们不难发现相似的演进趋势。为了推动人工智能快速落地，各类人工智能企业都遵循着类似的应用范式：基于特定的应用场景收集特定的数据，再利用这些数据训练算法模型，最终解决特定的任务。诚然，这样的应用范式在初期确实取得了显著的应用效果，但随着越来越多复杂场景的出现，尤其是与生成内容相关的应用场景，这种范式就会显得力不从心。在这种情况下，人工智能陷入了“手工作坊式”的应用怪圈，针对什么任务训练什么模型，复杂的任务就拆分成多个简单任务进行拼合连接。这虽然符合一般的工程思想，但也越来越偏离人工智能的初衷，这种专业化、碎片化的下游应用严重阻碍了人工智能产业化的步伐。在这样的情况下，主打“通用化”的大模型在时代的浪潮下孕育而生。通过“预训练大模型+下游任务微调”的方式，人们可以让模型从大量标记和未标记的数据中捕获知识，并在微调后将模型的能力迁移到各类任务场景中，极大地扩展了模型的通用能力。如果说这种“预训练+微调”的模型训练方式使大模型的广泛使用成为可能，那模型规模的增长则让这些大模型变得强大无比。 ^3300048853-24-1174-1666
    - ⏱ 2023-05-30 20:04:26 

- 📌 现在，这些大模型通常都有着数以百万乃至数千亿为单位的参数量，这些模型在接受了海量数据的训练后，能够捕获数据中更加深层次的复杂规则和关系，从而能够胜任各种类型的复杂任务。有三大因素促使了这类大模型的产生：[插图]·计算机硬件的改进，以及GPU等处理器算力的增加令如此规模的大模型训练成为可能。·Transformer等重要模型架构的出现让人们可以利用硬件的并行性去训练比以前更具表现力的模型。·互联网与大数据的高速发展提供了丰富的数据，可以支撑大模型的规模化训练。 ^3300048853-24-1666-2144
    - ⏱ 2023-05-30 20:04:13 

- 📌 过去，数据一直是机器学习模型的重要瓶颈，因为针对特定的任务场景，需要人工进行大量数据的标注才能让机器完成学习，许多业内专家将这种现象戏称为“人工智能就是大量人工才能换来的智能”。 ^3300048853-24-2597-2686
    - ⏱ 2023-05-30 20:04:04 

- 📌 许多大模型的训练开始采用综合监督学习和无监督学习的方式，例如通过“无监督预训练，监督微调”的方式，减少对标注数据的依赖。同时，除了在数据标注角度的革新外，许多大模型在训练数据的选取上也更加别出心裁，充分利用互联网上自然生成的PGC、UGC内容进行训练，以获得更加丰富的可用数据和更加自然的语言表达。 ^3300048853-24-2714-2863
    - ⏱ 2023-05-30 20:04:24 

- 📌 虽然符号主义确实取得了一定成功，但由于人们无法定义人类智能的所有规则细节，它很快在历史的长河中被淘汰。就以语言翻译的任务为例，为了准确地将一个句子从一种语言翻译成另一种语言，需要让系统包含这两种语言的所有语法和语法规则。然而，这些规则通常有许多细微差别和例外情况，利用规则的界定让系统变成强大可用的工具是一个极其复杂和困难的事情。因此，基于规则的系统往往难以完成具有高度细微差别或灵活性高的任务。 ^3300048853-24-3376-3574
    - ⏱ 2023-05-30 20:04:23 

- 📌 联结主义则从更高的抽象层次去定义人工智能。智能产生于人脑，而人脑构成的神经节点促使了人类具备思考的能力，因此应该让机器去模仿人脑的结构而非人脑所表现出来的规则。虽然联结主义在发展初期遇到了诸多阻碍，发展至今也已经与当初的出发点相去甚远，但人工神经网络时至今日的蓬勃发展在一定程度上也验证了当初这种高度抽象化思考模式的胜利。 ^3300048853-24-3599-3760
    - ⏱ 2023-05-30 20:04:12 

- 📌 后来，诸多人工智能各个子领域的发展无疑不见证了这种在宏观层面模仿人类智能思路的正确性。基于人类通过学习而获得智能，诞生了机器学习；基于人类在学习过程中会有激励和惩罚，这些激励和惩罚会不断强化人类的能力，出现了强化学习；基于人类在接受信息时往往会将注意力集中在重要的信息上，产生了当代主流大模型的根基——Transformer；基于人类在学习认图时并非学习照片细节的纹路，而是直接被不断告知关于图片中物体的描述，诞生了AI绘画的奠基性模型——CLIP模型。总之，从领域开拓到细分应用，从模仿人类的学习过程到模仿人类的认知方式，人工智能逐渐从更宏观、更抽象的维度从人类身上汲取营养。伴随着人类对于自身智能产生根源的通晓，我们相信人工智能相关技术又会迎来一次前所未有的飞跃，为未来的AIGC带来更多的可能性。 ^3300048853-24-3785-4136
    - ⏱ 2023-05-30 20:04:29 

- 📌 借鉴强化学习思想的RLHF方法就是减少人工智能生成危害性内容的典型措施，前面反复提及的ChatGPT就是采用这种方式训练的。在RLHF的框架下，开发人员会在人工智能做出符合人类预期回答时给予奖励，而在做出有害内容的回答时施加惩罚，这种根据人类反馈信号直接优化语言模型的方法可以给予AI积极的引导。然而，即便采用这种方式，AI生成的内容也有可能在刻意诱导的情况下输出有害的内容 ^3300048853-24-5138-5325
    - ⏱ 2023-05-30 20:04:06 

- 📌 随着AIGC相关内容的爆火和出圈，互联网巨头闻风而动，国外的微软、谷歌、Meta，以及国内的百度、腾讯、字节跳动等大厂都在AIGC领域有所投入。不少创业者也在其中看到了商机，并想从中“掘金”。不过，相比于大厂拥有雄厚的研发资金、成熟的研发团队，创业公司的路走得似乎会更艰难。 ^3300048853-24-6330-6467
    - ⏱ 2023-05-30 20:04:15 

- 📌 目前，AIGC初创公司的产品大多是基于市面上现有的开源模型进行二次开发。虽然这种方式可以帮助创业公司快速开发出一个可用的AIGC产品，但也会让开发出的产品从技术角度失去韧性的技术壁垒，令短周期内的竞争达到非常激烈的水平。Stable Diffusion产品模型的“大开源”事件就是一个典型，在它选择开发核心AI算法模型、核心训练数据集以及AI生成图片的版权，并让全世界所有普通人、创业者、商业团体可以随心所欲地完成对Stable Diffusion的部署、运行、改进和商业化后，一时间市面上出现了上百家基于Stable Diffusion的AI绘画公司，这导致了AI绘画工具的泛滥、产品利润低以及严重同质化的问题。这是AIGC赛道创业的一个缩影，这个缩影反映出，打造产品在细分赛道的差异化及寻找合适的商业化场景落地，将成为这些创业公司竞争的关键。 ^3300048853-24-6492-6865
    - ⏱ 2023-05-30 20:04:07 

- 📌 除了竞争方面，商业模式的设计也是困扰很多AIGC创业者的核心难题。除了传统工具产品的付费模式外，目前尚无让人耳目一新的盈利方式。以AI绘画领域的头部公司Stability AI和Midjourney为例。Stability AI虽然彻底开源了Stable Diffusion的工具，但同时也推出了付费AI绘画产品DreamStudio。在Dream-Studio中，任何人都不需要安装软件，只需要具备编码知识就可以使用Stable Diffusion来生成图像。同时，用户还可以对生成图像进行分辨率调整等。DreamStudio产品的付费模式主要是积分制，首次注册后用户可以一次性获得100积分，大约可以供用户生成500张左右图像，但根据生成步骤和图像分辨率的不同，单个图像的收费可能会存在差异。如果用户消耗完所有积分，可以选择花费10美元去购置1 000积分来继续使用产品。而Midjourney则采用了较为常见的订阅制，新用户可免费生成25张图片，之后如果想要继续使用可以选择按月或者按年订阅Midjourney的会员，一共有基础版、标准版和进阶版三个版本的会员可供选择，以月订阅的基础版为例，每月支付10美元大约可以生成不到200张图像。 ^3300048853-24-6890-7412
    - ⏱ 2023-05-30 20:04:23 

- 📌 然而，无论是积分制还是会员订阅制，如果仅仅照搬这类公司的商业模式，AIGC创业公司很难在短期内取得成功。一个重要的原因是，这些平台已经积累了庞大的用户数量 ^3300048853-24-7437-7514
    - ⏱ 2023-05-30 20:04:22 

- 📌 但绝大多数AIGC初创平台都还属于快速积累原始用户的阶段，同时不少创业者还面临着快速变现的压力，需要稳定的现金流才能使团队有能力不断迭代产品。因此，许多AIGC创业公司并不是在产品研发完成之后，而是要在设计产品之初就考虑可行的商业模式，在这种情况下，照搬Stability AI和Midjourney的模式就并非好的选择。 ^3300048853-24-8173-8334
    - ⏱ 2023-05-30 20:04:09 

- 📌 前来看，相较于针对C端用户，AIGC在B端服务方面的变现模式反而更具有可行性。传统产业迫切需要AIGC技术来实现降本增效，许多公司对于能够提升业务效率或显著降低业务成本的技术具备极高的付费意愿 ^3300048853-24-8360-8456
    - ⏱ 2023-05-30 20:04:03 

- 📌 而且，因为行业及业务逻辑存在明显的差异，而主流的AIGC模型都较为通用，如果能针对特定的业务需求研发产品，仍然存在很大的机会 ^3300048853-24-8457-8519
    - ⏱ 2023-05-30 20:04:27 

- 📌 所以，对于创业者来说，找到一个可以落地的商业场景，并且锁定一个细分场景对AIGC进行训练，做出产品在特定领域的差异化，这是商业化落地的最好方式。 ^3300048853-24-8520-8592
    - ⏱ 2023-05-30 20:04:25 

- 📌 一个好的投资标的未必是运用先进技术的公司，而是可以确定实际的终端用户需求到底是什么、技术如何更好地制作产品并满足用户需求的公司。 ^3300048853-24-9774-9838
    - ⏱ 2023-05-30 20:04:24 
# 读书笔记

# 本书评论
