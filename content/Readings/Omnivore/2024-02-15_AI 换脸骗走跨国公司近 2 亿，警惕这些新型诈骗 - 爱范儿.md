---
id: 184064a0-cbe1-11ee-a3c7-d752abd13c87
title: |
  AI 换脸骗走跨国公司近 2 亿，警惕这些新型诈骗 | 爱范儿
author: |
  张成晨
tags:
  - RSS
date_saved: 2024-02-15 00:57:42
date_published: 2024-02-15 00:57:42
draft: true
---

# AI 换脸骗走跨国公司近 2 亿，警惕这些新型诈骗 | 爱范儿
#Omnivore

[Read on Omnivore](https://omnivore.app/me/ai-2-18dac01c279)

[Read Original](https://www.ifanr.com/1575397)

date_saved: 2024-02-15 00:57:42

date_published: 2024-02-15 00:57:42

--- 

# Full Content: 

![](https://proxy-prod.omnivore-image-cache.app/0x0,sjvU6HGISO4VA9SLs4wF-oVv0UiyHJHqsAG3fmmpi_q4/https://s3.ifanr.com/wp-content/uploads/2024/02/gu1.jpg!720) 

## AI 换脸骗走跨国公司近 2 亿，警惕这些新型诈骗

新年新气象，除了和财神爷搞好关系，守住钱袋子也很重要。

技术落地的过程，往往是黄色内容和诈骗套路的进化史。

趁着假期还有余额，教长辈警惕 AI 新型骗局，才能实现「相亲相爱一家人」家族群的「共同富裕」。

### 一抓一大把的 AI 博主，比「假靳东」更能骗人

《大话西游》里说，人是人他妈生的，妖是妖他妈生的，代码产出的 AI 没有父母，但想装得有血有肉，让你误解它是人类。

最近，视频号冒出了不少「俄罗斯美女」。她们个个肤白貌美，普通话流畅但断句和咬字奇怪，声调和前后鼻音读不准。当然，考虑到她们外国人的身份，带点口音才显得自然。

![](https://proxy-prod.omnivore-image-cache.app/600x830,saM9TIj5C0xc9m5T0mkSIaeCdnU_dphPg_joUGHA_fBQ/https://s3.ifanr.com/wp-content/uploads/2024/02/ezgif1.gif)

她们热情，也热爱中国文化，为视频打上「俄罗斯女孩在中国」「中俄友谊」之类的标签，为观众朋友带来「家乡特产」的牛筋肠、大列巴、羊奶粉、酸黄瓜、巧克力、手工皂。

![](https://proxy-prod.omnivore-image-cache.app/600x895,sPSFmw5BKzzl_Eq9qSjAtPVBjoWnwmJme5VagDhmn6Iw/https://s3.ifanr.com/wp-content/uploads/2024/02/ezgif2.gif)

她们两弯似蹙非蹙罥烟眉，一双似喜非喜含情目，除了带货也会输出观点，相信爱情无国界，信奉平平淡淡才是真，感叹这里的繁华，想把爸妈和妹妹也接来发展。

![](https://proxy-prod.omnivore-image-cache.app/1170x1447,s6Z069A89dSvqEiBYszH7tHG0yX8r8gFREN8RfUcDLSo/https://s3.ifanr.com/wp-content/uploads/2024/02/guan1.jpeg!720)

她们可能是彼此失散多年的姐妹，叶连娜和艾琳娜就长得一模一样，IP 还都是山东的。她们聚是一团火、散是满天星，分布在五湖四海，莉娜是上海的，尼娜是安徽的，艾琳是河北的，卡佳是辽宁的，阿丽莎是福建的。

![](https://proxy-prod.omnivore-image-cache.app/2340x2195,s_Hs1chvNlMaq6KZgie0YHNQzVJ5IO_8meq7IYK0NFrE/https://s3.ifanr.com/wp-content/uploads/2024/02/xiang1.jpeg!720)

这些俄罗斯美女都是 AI，平台贴心地标注了。通过她们虚化夸张的模糊背景、没抠好的头发丝、循环的几套表情和动作、过于接地气的台词，我们也能分辨一二。

![](https://proxy-prod.omnivore-image-cache.app/2355x1459,s6HhLYiWYCfoQ2u271gsoD90rLnLD3QbL4o4u3sXgdsY/https://s3.ifanr.com/wp-content/uploads/2024/02/ren1.jpg!720)

但评论区的中老年看不出来，真心希望她们留下来，「俄罗斯美女」们回复时只挂念着自己的任务，完成了一场不动声色的软性诈骗。

![](https://proxy-prod.omnivore-image-cache.app/1484x802,sQMbBjCwGpf8m2IXtg0d2IuSM9v6fxtrxArN8gkdYOG8/https://s3.ifanr.com/wp-content/uploads/2024/02/huo2.jpg!720)

被美貌所惑是人之常情，不分年龄。小红书的 AI 颜值博主，用时髦的、极具网感的人设实现老少通杀。「西装精英男」「白袜体育生」「纯欲女神」…… 乍一看，只以为是 P 图 P 过了的真人。

![](https://proxy-prod.omnivore-image-cache.app/1070x790,sbWgd6irRmqa0EMfK4g1G0I1ITRCljermx0GBFXaWu58/https://s3.ifanr.com/wp-content/uploads/2024/02/hong1.jpg!720)

这时候辨别是不是 AI，看手仍然是一种方式，因为脸相对平面，容易学习，而手有三维结构，比较耗费功夫。手指数量超出无须多言，手指关节扭曲得留个心眼，非必要不露手也十分可疑。类似地，肌肉、四肢、衣服等细节也可能有着显而易见的破绽。

其余的分辨方式越来越向玄学和直觉发展：画风油腻、文案网抑云、没有生活气息、光影效果不自然、眼神透着死气，脸部过于精致完美，只有静态图片没有视频，单看一张图片不好确定，但多看几张就能发现，什么姿势都是一个表情……

小红书 AI 博主 @cyberAngel\_ 本职是一名软件工程师，AI 绘画权当为爱发电的业余爱好，他不隐藏使用 AI 的事实，帖子标题注明「AI 绘画」，账号简介也写着「我只是一个没有感情的机器人」。

![](https://proxy-prod.omnivore-image-cache.app/1170x1530,sM2m6iURWnFG7fa6p5gcVgnlOMQVS2I1rC9cdl7aCCF0/https://s3.ifanr.com/wp-content/uploads/2024/02/cy1.jpeg!720)

▲ 图片来自：小红书 @cyberAngel\_

同时 @cyberAngel\_ 认为，未来的 AI 绘画将越来越难以分辨真假，AI 生成和 AI 检测是互相进化的，创作者们更加清楚 AI 哪里不像真人，所以会努力让这部分「像」真人，比如 AI 产出的美少女过于完美，可以适当模糊化，加点「胶片感」。

哪怕 AI 颜值博主还没那么真，和「俄罗斯美女」大同小异的剧情已经出现，平台明明已经提示「疑似包含 AI 创作信息」，评论区仍有人留下彩虹屁，甚至追着询问衣服链接，似乎真或假的问题，最终将不可避免地让位于美丽即是正义。

等到粉丝量上来了，AI 颜值博主的变现方式可以十分多样，有的自力更生，通过广告等将流量变现，有的知识付费，卖课、卖定制模型，按 @cyberAngel\_ 的话说，「新媒体有新媒体的变现方式，技术有技术的变现方式」。

![](https://proxy-prod.omnivore-image-cache.app/2358x1682,sapRaAfMwROrvVAe6XlcA1LwRTG6lKYGt-tscVn2uSuI/https://s3.ifanr.com/wp-content/uploads/2024/02/true1.jpeg!720)

▲真人模型.

AI「俄罗斯美女」和「颜值博主」，和之前骗中老年女性情感和钱财的「假靳东」有些相似之处，却更加可怕，也更加有想象空间。

「假靳东」没什么技术含量，和明星相关的视频和照片是下载或者打包购买的，深情的声音是用变声软件伪造的，粗糙得「一眼假」，AI 的段位更高，有时候还真的没那么好辨别。

只能说，当我们看到盘靓条顺的互联网帅哥美女时，最好不要默认是真人，也不必太真情实感，网红公司不想花钱在真人 KOL 上，观众也更加快速地消费批量的美貌和廉价的观点，多么符合互联网的传播规律。

### AI 模仿你的脸，还要恐吓你的心

除了通过「颜值博主」和「俄罗斯美女」广撒网，AI 同样也能精准锁定。

或者说，AI 既能编织出温柔乡，也能改头换面当 PUA 大师。

一类常见的 AI 诈骗是，骗子伪造来电显示和熟人声音，告诉接到电话的中老年，他们的孙子孙女遇到了麻烦，要么是犯了事需要拿钱消灾，要么是身陷险境得用赎金救出。

![](https://proxy-prod.omnivore-image-cache.app/1200x675,sy8QQ1HYQWKYrT3IWmRclAevtAPMxM4OduOloBx4e0i4/https://s3.ifanr.com/wp-content/uploads/2024/02/scam1.jpg!720)

国外报道了好几起这样的电话诈骗事件，剧情大同小异，绑架、受伤、酒驾追尾…… 类似的事情也发生在国内，尤其是利用「时空差」，编造留学生被绑架，从而诈骗家长。

套路本身并不新鲜，已经横行了几年，但因为技术发展，算力、样本等各方面的要求降低了，效果更逼真了，骗局更容易实施了。

AI 语音克隆界的领头羊 ElevenLabs 只需一美元和一分钟的高质量音频，让你瞬间掌握 29 种语言和多种语气，还保留自己的口音、语调和节奏。

虽然如今的 Elevenlabs 再三保证，只有你可以克隆自己的声音，并且有验证程序证明声音属于你自己，然而这是亡羊补牢，2023 年 Elevenlabs 刚推出测试版时，泰勒·斯威夫特等名人的克隆语音已经满天飞了。AI 泰勒·斯威夫特说什么，本人无权决定。

![](https://proxy-prod.omnivore-image-cache.app/1440x810,stwQnsQfxvKDvNCe4BqESM_KURYxTv1gO-xqVu_UPLi8/https://s3.ifanr.com/wp-content/uploads/2024/02/scam2.jpg!720)

不过，对方固然可以伪造来电显示和声音，但如果当事人头脑清醒，挂断电话，重新输入手机号，主动联系到亲人，谎言往往不攻自破。

比起语音，视频通话可能更让相信「眼见为实」的中老年怀疑人生。

![](https://proxy-prod.omnivore-image-cache.app/748x408,scOh7aahyqlJGtYaeRiQEf4rpxHRyUeubKd-ty2agBTg/https://s3.ifanr.com/wp-content/uploads/2024/02/zui1.gif)

屏幕那端不知是人是狗的古早笑话永不过时，技术上也不难实现。比较常见的操作是，通过虚拟摄像头软件和 AI 换脸功能，和对方进行聊天。

CCTV 采访的、为公安机关提供技术支持的一家深圳科技公司表示，进行视频聊天的实时换脸时，不管是头像还是朋友圈照片，上传图像后，特征识别只需要 30 秒左右，然后 AI 开始建模，建模完成后进行实时转换。

一对一的视频或许尚存戒心，如果一对多的「专业团队」呢？

最近，一家跨国公司香港分公司因为 AI 被骗走了 2500 万美元。受害人是一名财务职员，其收到了英国总部「CFO」的邮件，受邀参与了一场涉及「秘密交易」的视频会议，会上不仅有「CFO」，还有几个眼熟的「同事」。

与会同事并非真的在场，骗子下载了公开视频，通过 Deepfake 伪造了真人的脸和声音，再套用到视频会议。为了避免露馅，「CFO」单方面下指令，「同事」们没有和受害人交流，并且视频很快挂断了，骗子之后通过邮件等方式继续和受害人联系。

![](https://proxy-prod.omnivore-image-cache.app/1280x960,s_xAlMtrobYAjfqniw8ZDwR2YbN0CzgxymUaexGmXxhM/https://s3.ifanr.com/wp-content/uploads/2024/02/rthk.jpg!720)

▲ 警方示范怎么用 Deepfake 伪造多人视频会议.

虽然此事有了调查结果，也有网友怀疑是内鬼作祟而已。跨国公司的风险管控措施如何不为人知，但可以确定的是，AI 换脸还可以延伸到很多地方，从最早的色情片换头，到假冒明星在直播间带货。

所幸，AI 还没有那么完美，辨别方式依然简单可行。

假如是通过 AI 换脸视频，摄像头的原始画面在几层转换时十分消耗算力，声音和画面往往会有延时。另外，可以引导对方做些动作，比如张嘴、大幅度摇头、把手指挡在脸前来回移动等，若是 AI 换脸，「人脸」可能会出现变形和瑕疵。

![](https://proxy-prod.omnivore-image-cache.app/1970x1092,sAJtGE0uyNJrAJdWWYbCz1lO43ytGxEk914smoBsXaM8/https://s3.ifanr.com/wp-content/uploads/2024/02/cctv1.jpg!720)

除了从技术的 bug 突破重围，还有百试不爽的一招是，问些你知我知他不知的隐私问题，或者编造谎言故意套路，看对方如何接招。

当然，技术的不足只能解一时之困，不妨战略上蔑视、战术上重视，不能觉得自己一定不会被骗，可能只是高端局还没出现。

### AI 诈骗并不新，但新的数字鸿沟已经出现

2023 年被称为生成式 AI 的元年，然而技术的推广有滞后性，或许大多数普通人更能感知的是，看似并不新鲜的、但近年越发普及的技术，如何影响了日常生活。

技术是把双刃剑的道理人人明白，Elevenlabs 可以让有语言障碍的人发声，HeyGen 让霉霉对口型说出不带翻译腔的中文，妙鸭相机让人足不出户收获精修证件照，技术的光明面和阴暗面并无长短，只是客观存在罢了。

![](https://proxy-prod.omnivore-image-cache.app/1194x634,si0k7hG8VFlgMPQ8vaEzgR6Rdt5-l9d9YCqqXlBimBXs/https://s3.ifanr.com/wp-content/uploads/2024/02/mei1.jpg!720)

然而，对于很多中老年来说，智能手机和互联网本来就玩不明白，现在 AI 又来捣乱了。

AI 时代，文字、声音、图片和视频都有可能是假的，甚至以组合形式上场，骗子伪造的身份更加具体，诈骗也更加对症下药和真情实感，让中老年受骗的概率更高。

以魔法对抗魔法，以技术攻防技术，是个此消彼长的猫鼠游戏，中老年未必能快速消化，我们或许从诈骗的本质入手，降低中老年上当的可能。

不管技术如何发展，很多诈骗的套路万变不离其宗：窃取隐私，利用恐惧、贪欲、情绪价值编故事，冒充熟人或包装自己获取信任，图穷匕见以钱为最终目的。

![](https://proxy-prod.omnivore-image-cache.app/720x405,s39o-iu0I5L_js7vZnxNC8P4XYli5ATrzyWB_W8TIv_I/https://s3.ifanr.com/wp-content/uploads/2024/02/po3.jpg!720)

在 AI 时尚教皇出圈后，一位粉丝近 1300 万的 X（原 Twitter）大 V 感叹：「我以为教皇的羽绒服是真的，没有多想。我不可能在技术的未来中幸存下来。」

对于中老年来说，眼见不等于真实、有图未必是真相的规则更难被适应。我们可以告诉他们一些简单、传统但依然有效的办法。

一类是小心驶得万年船，不轻易相信互联网的内容，不接骚扰电话，不点陌生链接，尽量不在互联网过度暴露人脸、声音、指纹等个人生物信息。

![](https://proxy-prod.omnivore-image-cache.app/720x479,sOqdMdPGk6k1RVeXBuJ1LlGcmaMT97IyjtPxAZwQP5WE/https://s3.ifanr.com/wp-content/uploads/2024/02/laoren.jpg!720)

尤其接到可疑电话、短信时，不要盲目相信「一面之词」，不管对方是谁，谈到钱就多个心眼，通过多种方式验证对方身份，如果对方说家人遭遇了某事，再次回拨家人电话确认情况是否属实。

另一类是主动出击有备无患，中老年有自己偏好的媒体，家人可以将政府部门微信公众号等信源的反诈内容转发给他们。如果条件允许，也可以向中老年展示如何使用 ChatGPT 等 AI 工具。

当然，对于不懂智能手机的老人，尽量在源头解决问题，最好不要在微信、支付宝绑定银行卡，只存少量的零钱。

AI 诈骗得逞只是最后的结果，防范 AI 骗局却可以随时开始。

技术应当服务于每一个人，引路人为后来者照亮数字世界的灯塔，探明水下未知的暗礁，我们才能共同走向一个技术不被恐惧而是被合理使用的未来。

---

