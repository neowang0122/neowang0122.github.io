---
id: 202d30a0-ce9b-11ee-a273-170bcade1d65
title: |
  当AI能模仿作家笔触或艺术家风格时，哪些使用属于合理范畴？
author: |
  unknown
tags:
  - RSS
date_saved: 2024-02-18 05:48:28
date_published: 2024-02-18 05:48:28
draft: true
---

# 当AI能模仿作家笔触或艺术家风格时，哪些使用属于合理范畴？
#Omnivore

[Read on Omnivore](https://omnivore.app/me/ai-18dbde05fe8)

[Read Original](https://www.mittrchina.com/news/detail/13010)

date_saved: 2024-02-18 05:48:28

date_published: 2024-02-18 05:48:28

--- 

# Full Content: 

2023 年，可以直接应用的生成式人工智能工具突然出现，给我们带来了具有挑战性的社会和道德问题。

关于这项技术如何深刻地改变我们工作、学习和生活方式的愿景，让我们不得不关注如何以及是否可以负责任地使用这些技术，并就此进行对话。当然，随之而来的还有多到令人窒息的头条新闻。

负责任的技术使用（Responsible technology use）并不是什么新鲜事。它涵盖了许多我们耳熟能详的关注点，从算法中可能隐藏的偏见，到应用程序用户的数据隐私权，再到新工作方式对环境的影响。

技术咨询公司 Thoughtworks 的荣誉首席技术官丽贝卡·帕森斯（Rebecca Parsons）在“构建公平技术未来”的愿景中试图应对所有这些担忧，即随着新技术的部署，其优点将与所有人平等共享。

她说：“随着技术在人们的生活中变得越来越重要，我们希望设想一个让技术适用于每个人的未来。”

帕森斯指出，技术的使用经常会出现问题，“因为我们过于关注自己认为的好的东西，或者过于关注某一类特定受众，而不是更广泛的群体。”

这听起来就像是，一个应用程序开发人员只为一个想象中的客户构建程序，这个客户来自与他相同的地区，拥有和他一样的教育背景和富裕程度。

或者是一个产品团队没有考虑恶意行为者，以及他们可能会对产品生态系统造成什么伤害。

“产品开发者可能会天真地认为，人们会按照他设计的方式去使用产品，以他希望的方式去解决问题。”帕森斯说，“但在现实世界中，人们会发现情况并非如此。”

当然，人工智能也带来了一些独特的社会挑战和道德挑战。其中一些挑战是固有的，这源自于人工智能的工作方式：它的工作方式是基于统计学的，缺乏确定性。

它从过去的数据中识别和延续模式（规律），但这强化了现有的偏见，而且它对它不知道的东西缺乏认识，这会导致幻觉的出现。

人工智能面临的一些挑战源于技术的创造者和用户自己不知道的事情：人工智能模型使用的未经检查的训练数据、它输出内容的有限可解释性，以及它如何让人们误以为它具备类似人类的推理能力。

然而，帕森斯认为，人工智能并没有改变“负责任技术”这一感念，而是重新定义了其中的一些问题。

例如，知识产权的概念可以追溯到数百年前，但大型语言模型（LLM，large language models）的兴起带来了新的问题。当机器可以被训练来模仿作家的笔触或艺术家的风格时，哪些使用属于合理的范畴？

她解释说：“如果你侵犯了某人的知识产权，那就不是负责任的技术，但在我们拥有大模型之后，这个问题变得复杂多了。”

![](https://proxy-prod.omnivore-image-cache.app/0x0,sRKCEltMrMDbYBSlpHlA0GO8sUXfAj1zVvGVdm1AM6sE/https://p9-sign.toutiaoimg.com/tos-cn-i-6w9my0ksvp/7f072269f0dd4eb89b39783abc4bce11~tplv-obj.image?lk3s=ef143cfe&traceid=2024021818463772997FDF8E5101E8B794&x-expires=2147483647&x-signature=%2BoTGFnPFLQBaBII0xnlUTI0sQNE%3D)（来源：AI 生成）

在过去的几十年里，关于负责任的技术的研究制定了一系列原则，它们在今天的转变过程中仍然具有现实意义。

透明度、隐私和安全、深思熟虑的监管、对社会和环境影响的关注以及通过提升多样性和可访问性实现更广泛的参与度，这些仍然是让技术造福于人类的关键因素。

《麻省理工科技评论》Insights 与 Thoughtworks 联合发布的 2023 年《负责任技术现状》报告指出，企业高管们正在认真对待这些因素。

例如，73% 的受访企业领导者认为，在做出技术决策时，负责任的技术使用与业务和财务考量同样重要。

然而，这个“人工智能时刻”可能代表着独特的机会，可以克服此前阻碍负责任技术工作的障碍。

如今，缺乏高级管理意识（52% 的受访者认为这是采用负责任实践的最大障碍）不再是一个问题。

精明的管理人员很快就能熟练掌握人工智能这项新技术，并不断被提醒注意其潜在的后果、失败和社会危害。

其他主要障碍是组织对变革的抵制（46%）和内部其他优先事项（46%）。那些已根据人工智能战略重新调整了自己并了解其改变行业潜力的组织，也可能能够克服这种惰性和优柔寡断的态度。

在这个颠覆性的独特时刻，当人工智能提供工具和动力来重新设计我们的工作和生活方式时，如果我们愿意，就可以将负责任的技术原则融入到这种转变中。

就帕森斯而言，她对人类利用人工智能从事善事的能力深感乐观，同时她也相信人类可以用常识性指导方针、精心设计的流程和安全护栏来解决人工智能的局限性。

“作为技术专家，我们非常专注于我们试图解决的问题，以及我们如何解决它。”她说，“负责任技术的真正意义在于，抬起头环顾四周，看看世界上还有谁和我在做同样的事情。”

支持：Ren

运营/排版：何晨龙

---

