---
id: 9be742f0-d632-11ee-be3c-036a1bdeab0d
title: |
  Mistral AI 的大语言模型怎么样？ - 少数派
author: |
  玉树芝兰
tags:
  - RSS
date_saved: 2024-02-27 08:32:35
date_published: 2024-02-27 08:32:35
draft: true
---

# Mistral AI 的大语言模型怎么样？ - 少数派
#Omnivore

[Read on Omnivore](https://omnivore.app/me/mistral-ai-18defa12ea7)

[Read Original](https://sspai.com/post/86727)

date_saved: 2024-02-27 08:32:35

date_published: 2024-02-27 08:32:35

--- 

# Full Content: 

![](https://proxy-prod.omnivore-image-cache.app/0x0,sl39TLJYkaoezSbycYO-oVFmWvfLpD0SdoLUYGVHfnvA/https://cdn.sspai.com/2024/02/27/article/f4fcfd81d29a66e7fc3dadcc9815db4f?imageView2/2/w/1120/q/90/interlace/1/ignore-error/1)

对用户来说，更多的选择没坏处；如果这个选择本身还很优质，那就更棒了。

## **对话**

早上，我收到了 Mistral 发来的邮件，提示我拥有了访问 Le Chat 的权限。

![](https://proxy-prod.omnivore-image-cache.app/0x0,sB7KX6vWDHXfJ3XVMBb9ZHzH8SfffILehdskUV_niWGs/https://cdn.sspai.com/2024/02/27/article/edc267502a185acae506823ea314cbc9?imageView2/2/w/1120/q/90/interlace/1/ignore-error/1)

我一时觉得很奇怪，什么是 Le Chat？

然后我才弄明白，原来是 Mistral 对标 ChatGPT ，推出了一个自己的对话机器人界面。虽然 Mistral 的创始人是 Deepmind 和 Meta 的前员工，但是这个公司毕竟是在法国，所以弄个法语特色的名称，也不意外。

于是，我赶紧点进去看看这个 Mistral 的新对话平台。目前来说，界面还是非常清爽的。

![](https://proxy-prod.omnivore-image-cache.app/0x0,sUF7BW9QBPRQblGwKkhMxoYJB2EFJ7x7jlzck2U8sY6o/https://cdn.sspai.com/2024/02/27/article/5066ed22ebd2f4bf29c173e1471cc965?imageView2/2/w/1120/q/90/interlace/1/ignore-error/1)

你可以打开右上方的这个下拉菜单，选择使用的模型。

![](https://proxy-prod.omnivore-image-cache.app/0x0,skmC_5wDclkW-0vMeh3UC36sGYeEVTwB7SHPaKWGwwYc/https://cdn.sspai.com/2024/02/27/article/927a581c2226fd3602a506356de83a74?imageView2/2/w/1120/q/90/interlace/1/ignore-error/1)

这里有 3 种可选模型，分别是 Large, Next 和 Small 。

其中 Small 模型，我之前就测试过，属于轻量级模型。Next 我之前一直没有机会测试，据说在推理上是目前除 GPT-4 之外最强悍的。而 Large 模型则是这次的主角。几乎是和 Le Chat 一起推出的。

至于 Large 和 Next 究竟哪个更好用？我回头还得查查官方说明，以及用户的实际评测打分。不过 Mistral 发布的这个评测结果，显然让我对 Large 模型更加感兴趣。

![](https://proxy-prod.omnivore-image-cache.app/0x0,sugiHnvjeR3DCHYk0hhvqGCC9kavKlFpvpxUTK1ze54I/https://cdn.sspai.com/2024/02/27/article/d5c98d2f816fef9b78d83479fc0c703e?imageView2/2/w/1120/q/90/interlace/1/ignore-error/1)

可以看到，Mistral AI 宣称目前除了GPT-4，Mistral Large 已经**超越了其他所有大模型**。当然，我对这个宣称保持审慎和保留态度。原因是现在的模型测试标准简直是一言难尽。

不过，这里具体的数字如何，对普通用户其实没有什么太大用处。我更关心的，是模型用起来是不是符合咱们的需求。

那咱们今天，就先来看看这个最新的 Mistral Large 模型怎么样。

## **能力**

我先进行了一下问答测试。选用的题目是：

> 给我讲个关于程序员的笑话

之所以选择这个题目，是因为同样的问题，我 2 个多月以前就考过 Mistral Medium 模型。

![](https://proxy-prod.omnivore-image-cache.app/0x0,sDuij-4MYLNZD0zCWosRQiyZ0kqLDARsJbsHpLm--YgY/https://cdn.sspai.com/2024/02/27/article/0ce4f184bf1ca5c845c604a0b28623ce?imageView2/2/w/1120/q/90/interlace/1/ignore-error/1)

不知道是天冷还是笑话冷，反正我冻得够呛。

而这是 Mistral Large 的答案：

![](https://proxy-prod.omnivore-image-cache.app/0x0,s6A6g0cbk2--AhH92ZlqLPNDJP5J0hgkIzxu1k-DXp3E/https://cdn.sspai.com/2024/02/27/article/c5f513f919872ce346cd3f7fcffbdeed?imageView2/2/w/1120/q/90/interlace/1/ignore-error/1)

我觉得一般吧，再来一个：

![](https://proxy-prod.omnivore-image-cache.app/0x0,sRPdLtKAbtscMHN_4kI4qmw-yDlTG3Kj5rag1YnoQD98/https://cdn.sspai.com/2024/02/27/article/4a68e7726966cf3a183b20cfab6e2fba?imageView2/2/w/1120/q/90/interlace/1/ignore-error/1)

这个我觉得还有点儿意思，哈哈。

Mistral 官方表示，目前这个 Mistral Large 模型能够熟悉以下语言：

![](https://proxy-prod.omnivore-image-cache.app/0x0,seDQdOne56MdJhMFpRa5NxMkP8YI6ldgfMTEeGt_bdto/https://cdn.sspai.com/2024/02/27/article/723b971808264fa0d172d4182023a525?imageView2/2/w/1120/q/90/interlace/1/ignore-error/1)

但是根据我们实际测试的结果，它对中文理解和回答的能力也不差。

下面咱们试试它的编程（coding）能力好了。

编个啥呢？游戏吧。

我先考一个传统艺能，也是很多大语言模型测试代码编写能力的时候惯用设定目标 —— 贪吃蛇。

![](https://proxy-prod.omnivore-image-cache.app/0x0,sIuXAcj3tpQsMmROCyQLQIqseO9KAoYhgsdm4ieSd-dQ/https://cdn.sspai.com/2024/02/27/article/8c529070df3368a68722fb5100db8ecd?imageView2/2/w/1120/q/90/interlace/1/ignore-error/1)

一看见 Mistral Large 使用的是 curses ，我就觉得十拿九稳了。果不其然，我尝试运行了这段程序，然后这是运行的结果：

![](https://proxy-prod.omnivore-image-cache.app/0x0,sKsEwhaqizHRyQoQn8VQjcQ9CFzurZDVlS23Prqz7bOg/https://cdn.sspai.com/2024/02/27/article/9a739b6bf6ef7759ec82a520ff62fa7d?imageView2/2/w/1120/q/90/interlace/1/ignore-error/1)

没有任何报错，没有任何的迭代。就是这么顺畅。

于是我又尝试了另外一个游戏，Pong。

![](https://proxy-prod.omnivore-image-cache.app/0x0,sDNCDz97sq6mbxfirKEqi2vM3gL6ZikJYkNNllQkrOms/https://cdn.sspai.com/2024/02/27/article/79f275c917e214e9222fdfcd75dd12c6?imageView2/2/w/1120/q/90/interlace/1/ignore-error/1)

同样的，没有报错，一次成功。这次我一个人操作两个挡板（分别是上下左右和 WASD），手忙脚乱玩儿了一会儿。

![](https://proxy-prod.omnivore-image-cache.app/0x0,srg25CyROUXgQudIh0zdAEI6izFGcaz7ulJLjXaCqGZw/https://cdn.sspai.com/2024/02/27/article/0360f8eb4ad9526692054963a990b0a8?imageView2/2/w/1120/q/90/interlace/1/ignore-error/1)

老实说，Mistral Large 的效果，只是让我对它的稳定性信心更加充足而已。毕竟，早在 2 个多月以前，我就依次测试过 Mistral 的 Medium 模型和 Mixtral 8x7B 混合模型，它们都能够顺利编写和运行贪吃蛇游戏，而且输出速度更快。

当然，我觉得目前 Mistral Large 输出速度相较而言有些慢，可能是因为同时免费测试的用户太多的缘故。看看过几天是否有改进吧。

Mixtral 8x7B 模型更为有趣，它是广泛为大众所知的大语言模型里面，第一个应用了 MoE （专家混合）机制的。而且效果非常好。Google 的 Gemini Pro 1.5 也使用了这种机制，所以才有令人印象深刻的效果。

可惜啊，Gemini Pro 1.5 我是第一时间申请试用，到现在也没用上。

不过刚才咱们谈的这些大模型，基本上都得去调用 API 才能使用，数据都需要与云端进行交换。如果你不喜欢或者因为条件限制，根本做不到数据传递，那么也可以自己在本机部署 Mistral 7B 这个小模型来用。它的特点是小巧而强悍。

你看看 Mistral 推出 7B 模型时候选择的对比对象，根本就不是其他的 7B 模型，而是直接找出来 Llama 2 13B （比它几乎大了一倍）来比较，而且多项指标碾压对手。

![](https://proxy-prod.omnivore-image-cache.app/0x0,sirk4Xf7xxqrkbVzPYjiU3mUPpww-Ca_UepzeGd08vjg/https://cdn.sspai.com/2024/02/27/article/7b099c19dcff16107127270c03f4ecc2?imageView2/2/w/1120/q/40/interlace/1/ignore-error/1)

## **部署**

本地部署大语言模型的方式有好几种，例如 Ollama 之类。我比较喜欢 LM Studio，因为安装方便，界面用起来清爽。你可以 [从这里下载](https://sspai.com/link?target=https%3A%2F%2Flmstudio.ai%2F)。

![](https://proxy-prod.omnivore-image-cache.app/0x0,soeNpSjmLIEALE03giTHIhjvcY5KJjsZD-Ny1QNfBhKk/https://cdn.sspai.com/2024/02/27/article/e6eb7fe01768e2ece13c2b761e7f860a?imageView2/2/w/1120/q/40/interlace/1/ignore-error/1)

咱们在 LM Studio 主界面的搜索框搜索 Mistral 。

![](https://proxy-prod.omnivore-image-cache.app/0x0,sSsCruIlpDp1mzkG-W9xkea0ee-OsndltU8gargN4Xks/https://cdn.sspai.com/2024/02/27/article/1bbcf410c196ea65151ede7c3c05cc94?imageView2/2/w/1120/q/40/interlace/1/ignore-error/1)

我这里比较之后，选择的是 Dolphin 2.1 Mistral 7B GGUF 版本。选择「下载」后，请耐心等待下载完成。时间视网速而定。

![](https://proxy-prod.omnivore-image-cache.app/0x0,sGqyCgYAjv40tWuAS5QbWYqTDwN4dt8a2u_BfHu2eTDg/https://cdn.sspai.com/2024/02/27/article/b113252df6e70373b497b55dc696de18?imageView2/2/w/1120/q/40/interlace/1/ignore-error/1)

下载完成后，选择加载该模型。

![](https://proxy-prod.omnivore-image-cache.app/0x0,sT7Q01dAufa2BJxZW4YUXEz3jitChsR9_uW7djomABF8/https://cdn.sspai.com/2024/02/27/article/376ffb875d2554808a2f198f642d144a?imageView2/2/w/1120/q/40/interlace/1/ignore-error/1)

加载完毕之后，在这里输入你的问题即可。

![](https://proxy-prod.omnivore-image-cache.app/0x0,skh8EJ4GaA5UrLkP1PgUUKqWx6k-4Ot9ZU_r2g2Akxvk/https://cdn.sspai.com/2024/02/27/article/924fd0ba5bfe7494ea146eac110f96e3?imageView2/2/w/1120/q/40/interlace/1/ignore-error/1)

我出的题目，是：

> write python code to print 1 to 101

翻译过来，就是：

> 编写 Python 代码以打印 1 到 101。

然后，本地的 Mistral 7B 模型就开始思考和输出了。

![](https://proxy-prod.omnivore-image-cache.app/0x0,sCG6hmZc5feQDfNobyMtCbEIi09EIWyiFM8i32nSbdwk/https://cdn.sspai.com/2024/02/27/079efff8193dc831b96d4a1097aa1862.gif)

可以看到，它不光是完成了程序编写，还对这样写代码的原因进行了讲解。作为一个 7B 「小」模型，我觉得很棒。

在本地部署模型的好处，是你可以用它来作为 server ，给各种应用提供服务。

![](https://proxy-prod.omnivore-image-cache.app/0x0,sYHJU-kbBcnZGm5WMaeKQRRMVF0uJ-SZm5vdQBtJk908/https://cdn.sspai.com/2024/02/27/article/b9e4ca741c8d630e489d06991c087d4a?imageView2/2/w/1120/q/40/interlace/1/ignore-error/1)

上图说明了在其他程序中，如何调用目前这个 Mistral 7B 模型。点击 Start Server 按钮。

![](https://proxy-prod.omnivore-image-cache.app/0x0,srAJObMbq_WjUku3T8NOi2bgu1uDH-Db1PLWkg7EsQC8/https://cdn.sspai.com/2024/02/27/article/343a74f5feadcf296648e1bda5bf9155?imageView2/2/w/1120/q/40/interlace/1/ignore-error/1)

可以看到启动服务之后，在 1234 端口监听。因为咱们使用的是 GGUF 压缩模型，因此内存占用只有 4.29GB ，还是可以接受的。

这里多说一句，其实 Mistral 官方把 Mistral 7B 和 Mixtral 8X7B 都称作「开放权重」模型。你都可以在本地进行部署。

![](https://proxy-prod.omnivore-image-cache.app/0x0,sD2Ri3j4FvWoDv8gXmOXD2aChkVVsMCKpTJRDJs1J89M/https://cdn.sspai.com/2024/02/27/article/a27c059dba37e98f85cb2c407c4a1168?imageView2/2/w/1120/q/40/interlace/1/ignore-error/1)

只不过，后者的参数量高达 45B 。我担心电脑内存不够大，所以就没有进行测试。但 LM Studio 上面也有对应的模型可供下载。

![](https://proxy-prod.omnivore-image-cache.app/0x0,sozZVG6DDFiwgoXiJ57-S2Rz-1M76HIQduccpY912jFw/https://cdn.sspai.com/2024/02/27/article/03b32ca07e6878df0bcdc79123fd3cf9?imageView2/2/w/1120/q/40/interlace/1/ignore-error/1)

如果你尝试过，欢迎把测试结果告诉我。

## **支持**

这次 Mistral 的动作很大，包括接受微软的战略投资，充分利用 Azure 基础设施等。

但其实，它早就被各种第三方工具支持了，可谓「人缘极好」。

如果你打算尝试 Mistral 模型，目前有以下几个方法。

首先是 Poe ，这里你直接就可以调用 Mistral Large 模型。

![](https://proxy-prod.omnivore-image-cache.app/0x0,s5fQRdIkztuB2ncVWyEVMe7yf1ubB_I_R6lDXhpapUQU/https://cdn.sspai.com/2024/02/27/article/8727195dd2f12438eefeb68596365bc5?imageView2/2/w/1120/q/40/interlace/1/ignore-error/1)

注意，你不需要缴费成为 Poe 的付费订户，就能用 Mistral Large ，调用速度也非常快。当然这几天除外，因为大部分人还在新鲜期，玩儿命各种角度来测试。

另外就是 [我给你介绍过的 Perplexity](https://sspai.com/post/85330)，它 [专门提供了一个 Labs 功能](https://sspai.com/link?target=https%3A%2F%2Flabs.perplexity.ai%2F)，也是一个对话界面。里面包括了多种模型。

![](https://proxy-prod.omnivore-image-cache.app/0x0,ss3jCB9Osdf6BCyYWTDKxjzzOczUhG06QUGgSv97K5NE/https://cdn.sspai.com/2024/02/27/article/1e8af34f3a66a6b8cb6120b39d582d6d?imageView2/2/w/1120/q/40/interlace/1/ignore-error/1)

有的是 Perplexity 自己的，有的来自第三方，其中就包括 Mistral Medium 等。

![](https://proxy-prod.omnivore-image-cache.app/0x0,sw9tYh3zxfmuHWgwPdmVc1BY6fE4tbIAnIF6aZ69--RY/https://cdn.sspai.com/2024/02/27/article/e0ac924ebf44468b62d6b591242dca43?imageView2/2/w/1120/q/40/interlace/1/ignore-error/1)

另外，我给你 [介绍过的 Typingmind 里面](https://mp.weixin.qq.com/s?%5F%5Fbiz=MzIyODI1MzYyNA==&mid=2653545849&idx=1&sn=a9ada8c0ae2d4dfb4a13591706492244&chksm=f3898faec4fe06b802f1e4e5f235de4db05fe54bd4953fe158d7621298caa6faed95cce67ea7#rd)，也有 Mistral 模型的支持。

![](https://proxy-prod.omnivore-image-cache.app/0x0,sQipD3LysWM5U81dvUCgkwhnhWFU-4bi7dtC8SF6qskc/https://cdn.sspai.com/2024/02/27/article/75fe0fb40c71e8b40fd8ac257e757618?imageView2/2/w/1120/q/40/interlace/1/ignore-error/1)

[这里还提供了详尽的文档](https://sspai.com/link?target=https%3A%2F%2Fdocs.typingmind.com%2Fchat-models-settings%2Fuse-with-mistral-ai)，教你如何在 Typingmind 里面使用 Mistral AI。

![](https://proxy-prod.omnivore-image-cache.app/0x0,sIgk5mxtd9g_dBPhtiesjezrq77rMMQF8n4Po4C2C26k/https://cdn.sspai.com/2024/02/27/7c1c418528aae28e07fc4153a94885ff.png?imageView2/2/w/1120/q/40/interlace/1/ignore-error/1)

不仅如此，目前很火的多 AI Agent 框架，例如 Autogen Studio, CrewAI 等，都支持 Mistral 。

![](https://proxy-prod.omnivore-image-cache.app/0x0,sBLGIQNxBUqPtb7BzLdkOIUfpH8gqSeKSDiLz9h60wP0/https://cdn.sspai.com/2024/02/27/article/be8ebccce9948b9ac41f3711a6160b08?imageView2/2/w/1120/q/40/interlace/1/ignore-error/1)

就连 [之前给你介绍过的 Open Interpreter](https://mp.weixin.qq.com/s?%5F%5Fbiz=MzIyODI1MzYyNA==&mid=2653545713&idx=1&sn=e0750dbf04048a6873461198d13e0982&chksm=f3898e26c4fe0730ee23c56c08e86b7fa6d579695c38c9e6c0437f8c5bf273bc7882e1c7efbe#rd) ，也在文档里专门写明如何支持 Mistral 模型。

![](https://proxy-prod.omnivore-image-cache.app/0x0,sTqQcTFw3ShLaedjarHFvkd3UqEp-3Ygy2qd5cSDwrNw/https://cdn.sspai.com/2024/02/27/article/b9b8187109f5aa1944fb79ad5fb232b7?imageView2/2/w/1120/q/40/interlace/1/ignore-error/1)

## **编程**

如果你会编程，也可以在自己的应用中集成 Mistral API 调用。它的文档非常清晰，调用也很简单。

![](https://proxy-prod.omnivore-image-cache.app/0x0,saNwgtQpJvwTlZWlOCqhgu0hsfAn-8uADfc8d2OltoEs/https://cdn.sspai.com/2024/02/27/article/aa5dfa1314ca87242d7df760cbf6f182?imageView2/2/w/1120/q/40/interlace/1/ignore-error/1)

我最近，就尝试用 Perplexity 和 Mistral Medium 的 API ，做了个自动化文本处理工作流，帮我润色语音转写的文稿，还是比一遍遍打开对话界面重复机械输入提示词，要方便多了。

只不过，调用的时候，你不要忽略不同模型的价格差别。

![](https://proxy-prod.omnivore-image-cache.app/0x0,sA-QChByCStOv6fCFDfHYU8z6gpOqvJH_6_VptrCn4Xo/https://cdn.sspai.com/2024/02/27/825f443d3e0a15dd9df83dc2335eb22a.png?imageView2/2/w/1120/q/40/interlace/1/ignore-error/1)

对这个图，我不止一位朋友感叹 ——Mistral Large 的价格，直追 GPT-4 啊。

我算了算，也确实如此。所以如果我真的需要比较强的逻辑推理，可能目前还是更倾向于使用 GPT-4-Turbo-Preview 。毕竟价格相差不大，但是 GPT-4 能力公认更强一些。

## **小结**

本文我为你介绍了 Mistral AI 的大语言模型。从可以本机部署的 7B ，一直到能力与 GPT-4 相媲美的 Mistral Large ，这个模型家族各具特色。关键是，目前我们可以在很多应用的支持下，免费来尝试使用。如果你有调用大语言模型的需求，不妨试一试。欢迎你把自己实际使用的结果反馈在留言区，咱们一起交流讨论。

祝 Mistral AI 使用愉快！

如果你觉得本文有用，请**充电**。

如果本文可能对你的朋友有帮助，请**转发**给他们。

欢迎**关注**[我的专栏「科研利器」](https://sspai.com/column/245)，以便及时收到后续的更新内容。

[点击这个链接加入少数派会员](https://sspai.com/prime/subscription?referral=314606736)，立享 9 折优惠！获得专属会员内容、会员播客以及会员定制周边。在更多的领域和方向帮你打开脑洞，找到新的兴趣点，与少数派一起洞悉当下，探索新知。

![](https://proxy-prod.omnivore-image-cache.app/0x0,sQ0OyaSXTt1uXDPNt1tgsLhjfDWLM8NnjdKcmxUcFnqw/https://cdn.sspai.com/article/306432ff-1259-f987-3a4f-271211977cea.jpg?imageMogr2/auto-orient/quality/95/thumbnail/!200x268r/gravity/Center/crop/200x268/interlace/1) 

经验卷轴：入门学术论文写作

用二十余年的科研经验带你入门学术写作

## **延伸阅读**

* [文献综述 AI 应用对比 — Elicit, GPTs 与 Perplexity](https://mp.weixin.qq.com/s/ymLuS2Zz1kmJkTrD78aKHQ)
* [AI 真要成精了？ChatGPT 上手体验](https://sspai.com/post/77081)
* [智谱 GLM-4 大语言模型好用吗？](https://sspai.com/post/85906)
* [未来的写作长啥样？LEX 用 GPT-3 AI 给你点儿颜色看看](https://sspai.com/post/76362)
* [如何用 Python 和机器学习训练中文文本情感分类模型？](https://mp.weixin.qq.com/s/rjKphu6awe8fjciFGRxXNA)

[![玉树芝兰](https://proxy-prod.omnivore-image-cache.app/0x0,sIhEE6mQnHAMUsgSZXIumaiI4x6esguaDJ28N7iq6blE/https://cdn.sspai.com/article/02c1b4c9-ffb3-b89b-9fe1-bdc9abbc5d43.jpeg?imageMogr2/auto-orient/quality/95/thumbnail/!84x84r/gravity/Center/crop/84x84/interlace/1)![](https://proxy-prod.omnivore-image-cache.app/0x0,swNGK0FlxMz_yBJeOhOiSR4MTC5k8sDsv1pLeU1VQnMA/https://cdn-static.sspai.com/ui/badge/prime_S03_512.png)](https://sspai.com/u/a5xddvxl/updates)

 王树义。大学教师，终身学习者。稍微懂一点儿写作、演讲、Python和机器学习。欢迎关注我的公众号“玉树芝兰”(nkwangshuyi)。

---

