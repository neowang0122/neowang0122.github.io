---
id: eacb7a36-76f3-4bb9-94e0-625ab720b52b
title: |
  如何不编程用 ChatGPT 爬取网站数据？ - 少数派
author: |
  玉树芝兰
date_saved: 2024-04-07 00:25:20
draft: true
---

# 如何不编程用 ChatGPT 爬取网站数据？ - 少数派
#Omnivore

[Read on Omnivore](https://omnivore.app/me/https-sspai-com-post-87755-18eb6cd97f3)

[Read Original](https://sspai.com/post/87755)

date_saved: 2024-04-07 00:25:20


--- 

# Full Content: 

敢于大胆设想，才能在 AI 时代提出好问题。

![](https://proxy-prod.omnivore-image-cache.app/0x0,sSvu-DIZFQG0t3gOBTUe_cuB47dltLOVi5fYo4U_7f80/https://cdn.sspai.com/2024/04/02/article/787daf8c87dc51e3c02a006f0f04ad11.jpeg?imageView2/2/format/webp)

## **需求**

很多小伙伴，都需要为研究获取数据。从网上爬取数据，是其中关键一环。以往，这都需要编程来实现。

可最近，一位星友在知识星球提问：

![](https://proxy-prod.omnivore-image-cache.app/0x0,sTjN-ZqT42G8Q5xpDZQm5xVrsikN3tdiTbBCdPSsniIo/https://cdn.sspai.com/2024/04/02/article/684a48fdf03e6764140357ab1728812b.jpeg?imageView2/2/format/webp)

这里涉及到一些个人隐私，我就打了码。他的意思很清楚：

第一，他不想编程；

第二，他要获取数据。

在以前，这基本上算是空想。但现在可就不一样了。我觉得敢于设想，是很必要的。**这是个好问题**。

我之前在知识星球里就为你写过一篇相关的文章，叫做《[如何用 ChatGPT 的 Advanced Data Analysis 帮你采集数据](https://sspai.com/link?target=https%3A%2F%2Farticles.zsxq.com%2Fid%5Fp7982zsrnpg7.html)》。

![](https://proxy-prod.omnivore-image-cache.app/0x0,sLDiH-m8FaYUXcwKqu0po--43kYzWHP2HCsLhwTnNf2Q/https://cdn.sspai.com/2024/04/02/article/6fd56aac7b9fce01601bd43ff27f7307.jpeg?imageView2/2/format/webp)

ChatGPT 的 Advanced Data Analysis 模式（也叫做 Code Interpreter）可以自动编程并执行程序，曾经是数据分析的不二之选。好在现在我们有了更多选择。那篇文章对应的是一个活动网站的爬取（见下图），感兴趣的朋友 [可以去看看](https://sspai.com/link?target=https%3A%2F%2Farticles.zsxq.com%2Fid%5Fp7982zsrnpg7.html)。

![](https://proxy-prod.omnivore-image-cache.app/0x0,sLuRlDc5gya_nFvqK217K9MKboERM_y4UIc6JUQxaXnE/https://cdn.sspai.com/2024/04/02/article/89ec3aa3d5a0990d7fc096e6c164ba55.jpeg?imageView2/2/format/webp)

只不过，当时这篇文章里，咱们处理的方式，还少不了跟技术打交道。例如你需要获取一些文本的路径信息。

时隔数月，我在想，现在是不是有更简单直接的方法来处理数据呢？

## **工具**

我就到 OpenAI 的 GPTs Store 查看一番。

![](https://proxy-prod.omnivore-image-cache.app/0x0,sOb_FQzZ7v4QHN9Xv-ROjU4vYDlzcjE62Me4gK74w2Fo/https://cdn.sspai.com/2024/04/02/article/0cb32f3325d9a20919c7f798d9b05d24.jpeg?imageView2/2/format/webp)

这里汇集了许多人创造的各种 GPT 应用。你能想到的很多目标，都可以直接利用别人定制的 GPT 来完成，没必要重复发明轮子。咱们今天直奔主题，搜索 "Scraper"。

![](https://proxy-prod.omnivore-image-cache.app/0x0,spfl0Rc0PUIw6ve-YxfjXv5Vfn5fHP3ffnl59aCKyMeE/https://cdn.sspai.com/2024/04/02/article/e9c9195766d0571d55f1f6ed69f2ed3d.jpeg?imageView2/2/format/webp)

搜索结果中，我选择了排名第一的工具。你可以看到它的对话数量已经超过 1 万次，这是相当厉害的数据了。

![](https://proxy-prod.omnivore-image-cache.app/0x0,sYyfS4JY6TtG7u8IjAmPI4xtbo6SK4IBin8hudXdQwos/https://cdn.sspai.com/2024/04/02/article/5e0e9aeed3ba19999ef93ce6400cdc57.jpeg?imageView2/2/format/webp)

从右上角的数据统计可以看出，Scraper GPT 的评分是 3.9 分，有 430 人参与评分。页面上还列出了一些默认问题，可以帮助你了解它的工作方式。我选择了第一个问题：「我如何从网站获取数据？」

![](https://proxy-prod.omnivore-image-cache.app/0x0,s-dQJ5gU82rpXSk6OjJCvwFZxq_TEB1SeQYlfcbdwr1g/https://cdn.sspai.com/2024/04/02/article/2e271c0ecf946bd4cfd8a6989a443c4f.jpeg?imageView2/2/format/webp)

根据回答，我们可以利用 Scraper GPT 获取三类不同的数据：文本、链接和图像。只需告诉 Scraper GPT 网站地址就可以抓取内容，非常简单。

## **目标**

我们需要一个目标网站来进行抓取。本文我选择了我所在的天津师范大学管理学院数据科学系的 [师资介绍页面](https://sspai.com/link?target=https%3A%2F%2Fglxy.tjnu.edu.cn%2Fszdw%2Fsjkxx.htm)。

![](https://proxy-prod.omnivore-image-cache.app/0x0,sed22AZyAG9tM8YTaPnzowsmcQamWsnCxdTrir7nmzk0/https://cdn.sspai.com/2024/04/02/article/5ab6a87e6ade3063ce5b1b7a09150ce8.jpeg?imageView2/2/format/webp)

往下翻，你还能看见我，哈哈。

![](https://proxy-prod.omnivore-image-cache.app/0x0,sI6kUzHHLswW0QiEIN_H2zyPTDIjYDACvO9Q7fc0tVu8/https://cdn.sspai.com/2024/04/02/article/9e4c7bcce5a6c107367ae5a3e205f0a8.jpeg?imageView2/2/format/webp)

目标网站准备好了，[你把链接拷贝下来](https://sspai.com/link?target=https%3A%2F%2Fglxy.tjnu.edu.cn%2Fszdw%2Fsjkxx.htm)，就可以开始尝试了。

## **文本**

把页面网址复制粘贴到Scraper GPT对话框，我首先请求它帮我抓取网页中的**文本**。

![](https://proxy-prod.omnivore-image-cache.app/0x0,sDDVijoemkL60TYk2edIQDLhc580Wfgh0_JUprkkDU18/https://cdn.sspai.com/2024/04/02/article/a26f963308b5d917de3998c32614eaf9.jpeg?imageView2/2/format/webp)

很快，Scraper GPT 就把页面上所有文本都提取出来了，包括导航栏、页眉页脚等位置的文字，以及页面上每位老师的姓名、职称、联系方式等信息。

![](https://proxy-prod.omnivore-image-cache.app/0x0,sPUgl8dgD5dkvhvdVjMuc8gS9RCcxbk50ZmT9i0Q_7uY/https://cdn.sspai.com/2024/04/02/article/537beb42a28a70ef96d50a0bd2ce3d4f.jpeg?imageView2/2/format/webp)

最后 Scraper GPT 还表示，如果需要更进一步的信息，随时可以告诉它。真是服务态度一流。

![](https://proxy-prod.omnivore-image-cache.app/0x0,sXhi3wq5GJOvIKaXGvdnsyGAdPX1NVhY45kUg4PozUtA/https://cdn.sspai.com/2024/04/02/article/32cf9d3a2e548307568e98ce115c42c6.jpeg?imageView2/2/format/webp)

怎么样？是不是不用编程，直接搞定文本获取？

## **图像**

接下来咱们来试试获取网页中的全部图像。我把相同的网址发送过去，请求它抓取其中的图像。

![](https://proxy-prod.omnivore-image-cache.app/0x0,sRCDXIVT02RY3Jz-M9Sl3YC2c4Qm5NBgv6c-uA0tv8-M/https://cdn.sspai.com/2024/04/02/article/5280f7d070c65e58cb0a7ea1cba41084.jpeg?imageView2/2/format/webp)

这次它一共找到了 12 张图片，但在对话界面里**都无法正常显示**。

![](https://proxy-prod.omnivore-image-cache.app/0x0,sfTxiCdxTErVpijR05Vvp-B00ybaK80eoIEwkfBchf_o/https://cdn.sspai.com/2024/04/02/article/9654d4c06bfcc38d89cd1c986c736304.jpeg?imageView2/2/format/webp)

起初我觉得很失望，但马上意识到它已经成功获取了图片链接。我把链接复制到了 Visual Studio Code 里面，你可以看看它抓取到的内容。

![](https://proxy-prod.omnivore-image-cache.app/0x0,sWiCEodT0fxBOaFbc1yYPAaYWl8JimaLk54JAo3TrbeE/https://cdn.sspai.com/2024/04/02/article/ffdde40bb543d8eb791b11317c459aac.jpeg?imageView2/2/format/webp)

链接有了，如何正常显示呢？简单，咱们把所有内容复制到 Markdown 编辑器 Typora。你可以看到，所有老师的照片都依次展现出来了，很完美。

![](https://proxy-prod.omnivore-image-cache.app/0x0,s0FXVdoFMICOljoUbAa1qvpUgyEcSVXUJG5JxppRXZ1o/https://cdn.sspai.com/special/314/pic_404.png)

## **链接**

最后我要求Scraper GPT提取页面中的**所有链接**。

![](https://proxy-prod.omnivore-image-cache.app/0x0,sOPVwabo9PUw3wAk-5MW1dhVpGgwCvi8rzdDReUtbn74/https://cdn.sspai.com/2024/04/02/article/95030f1ab08d62e611d3bcef118406f4.jpeg?imageView2/2/format/webp)

从结果可以看出，Scraper GPT 找到了导航栏、学院简介等页面链接，以及三位老师的个人主页链接。

![](https://proxy-prod.omnivore-image-cache.app/0x0,sF22dF65vkMhb0SNcTsIPQow7VfHJu7U75yjmKIMqZqI/https://cdn.sspai.com/2024/04/02/article/38d77e02909f65fd01861a3f2de1b2e0.jpeg?imageView2/2/format/webp)

我觉得这个结果并不完整。不过仔细一看 Scraper GPT 自己已经表示，这「只是链接的一部分」。如果我需要某个特定区域的链接，尽管告诉它。

那我就不客气了，指明它需要给我显示所有「教师」部分的链接。

![](https://proxy-prod.omnivore-image-cache.app/0x0,sh_4gwIsurR-cse-RIjbd9luoxghp_5rSrWzdm71X3d8/https://cdn.sspai.com/2024/04/02/article/15305b01cbf78f6d4a3cd3e254bff7a9.jpeg?imageView2/2/format/webp)

于是全系所有 9 个老师的页面链接就都出现了。

![](https://proxy-prod.omnivore-image-cache.app/0x0,s5-J4QcNfiUAYYZX3yrZtHgBPLz3bAf2ld7sXBkXnq8I/https://cdn.sspai.com/2024/04/02/article/48597f21b0e78fbf714c565091ae214e.jpeg?imageView2/2/format/webp)

我把抓取到的链接内容复制到编辑器中，你可以清楚地看到每个链接。

![](https://proxy-prod.omnivore-image-cache.app/0x0,sbyp5T57SQXnBMg-8_njIG7yEhHMEIWppSDkJqFtWXzk/https://cdn.sspai.com/2024/04/02/article/db2ca56a0a59e436eb34164f62f74848.jpeg?imageView2/2/format/webp)

当然了，你一般不会满足于只获得某个网页上的内容，而是希望「顺藤摸瓜」。没问题，链接在手，你可以进一步要求Scraper GPT访问这些链接，**抓取二级页面**的内容。

## **深入**

这里我以 [翟羽佳老师的个人主页举例](https://sspai.com/link?target=https%3A%2F%2Fglxy.tjnu.edu.cn%2Finfo%2F1076%2F2823.htm)。

![](https://proxy-prod.omnivore-image-cache.app/0x0,sZwmr2sV5b4Gwo3wcnC_YfRFWbcbx_6MThWOqdYtV9Fk/https://cdn.sspai.com/2024/04/02/article/11c6a8ae966dc894446d9957018ca6eb.jpeg?imageView2/2/format/webp)

进入页面后，你可以看到翟老师的个人介绍、学术成果、研究课题等丰富信息。我用提示词让 Scraper GPT 把页面文本提取出来。

![](https://proxy-prod.omnivore-image-cache.app/0x0,scxKWyTAs4mHYtWr86AmaT6LWL6GUO8y4kY1nsjeYZ_k/https://cdn.sspai.com/2024/04/02/article/4844a2af2fe4e8125d457c1485077829.jpeg?imageView2/2/format/webp)

Scraper GPT 把翟老师的职称、联系方式、研究领域等内容都抓取到了。

![](https://proxy-prod.omnivore-image-cache.app/0x0,sYg0WVmXLm8omOpkAVTLBH1E0zbS7l4-0vXanGnmZfoA/https://cdn.sspai.com/2024/04/02/article/0e6bbd2ea8f24e9752f714f2d2147094.jpeg?imageView2/2/format/webp)

更进一步还抓取了翟老师的教育背景、工作经历、研究生指导等。

![](https://proxy-prod.omnivore-image-cache.app/0x0,sln37htLIEda_QG0TEIPJsmCHdho1d8F7ufQQkV1dvmw/https://cdn.sspai.com/2024/04/02/article/1c93c4b7c6a91fd477fd2b5551ddf6d5.jpeg?imageView2/2/format/webp)

在翟老师的个人主页上，这些信息位于默认页面底部。

![](https://proxy-prod.omnivore-image-cache.app/0x0,sOL3SbqHYi-OMyJzKvHV9TxjoMHw4S7VtJcvw-39DgiI/https://cdn.sspai.com/2024/04/02/article/a0cc7fcb23dde95953233be53de25f02.jpeg?imageView2/2/format/webp)

但对于那些需要点击展开才能看到的内容，比如学术成果、研究课题、讲授课程等，Scraper GPT 则没能捕捉到具体内容。

![](https://proxy-prod.omnivore-image-cache.app/0x0,sask77EF_vETgzFvAY1qTLEXg6yCvkkA05r_FwFQ0dcw/https://cdn.sspai.com/2024/04/02/article/9cb2e263719609487c09c7b92573519b.jpeg?imageView2/2/format/webp)

我要求 Scraper GPT 抓取学术成果这个部分。

![](https://proxy-prod.omnivore-image-cache.app/0x0,smRGf8CkZ-XRz_nlnbDOmi6SzqEfs2nPrwTf4t0dkR2Q/https://cdn.sspai.com/2024/04/02/article/2b66f1b4d97ba031e1ddc4b6f23edeca.jpeg?imageView2/2/format/webp)

结果 Scraper GPT 表示，无可奈何。

![](https://proxy-prod.omnivore-image-cache.app/0x0,stQDGRCCKUBNpgOedNnvPyXN3lJ3mgnkmIRhpVsWZ0cc/https://cdn.sspai.com/2024/04/02/article/129a55c4f1e63e996b7e20ce23a1098e.jpeg?imageView2/2/format/webp)

翻译过来就是：

> 之前提供的内容没有具体说明翟羽佳老师的「学术成果」部分的详细信息。看来这一部分的具体细节没有包含在抓取的文本中。这可能是由于网站内容的布局或动态加载方式造成的，单次抓取可能无法准确捕捉某些特定部分的详细信息。

> 如果您需要这一部分的详细信息，我建议您直接访问该网页。如果还有其他我可以协助您的地方，请告诉我！

我自己手动查找到翟老师学术成果第一条的 xpath 链接。

![](https://proxy-prod.omnivore-image-cache.app/0x0,szwkt3N3itCFePabY_mtyGJxlRYFG6NkRn1pq-Aiurk0/https://cdn.sspai.com/2024/04/02/article/6773715a8de294f36dcaa5740b258df7.jpeg?imageView2/2/format/webp)

然后我把这个 xpath 地址扔给了 Scraper GPT 。但是它还是告诉我，这些它处理不了。

![](https://proxy-prod.omnivore-image-cache.app/0x0,s0izu7ffECTH-xY6Uoro-45dwK1JlNvhOEaTU0dpjWGw/https://cdn.sspai.com/2024/04/02/article/3f9796217943a67f5e2fe81b6c730a53.jpeg?imageView2/2/format/webp)

翻译过来，就是：

> 我无法直接执行或解释 XPath 查询，也无法像浏览器或支持 JavaScript 的专用网页抓取工具那样与网页进行交互。我的能力集中在处理页面由服务器提供的静态内容中的文本、链接或图像，而不是在客户端脚本运行之前。

> 如果有 JavaScript 生成的内容或信息是动态加载的，我可能无法直接通过简单的抓取访问到它。对于动态加载的内容或需要交互或特定查询 (如 XPath) 的部分，我建议使用专门设计用于动态网页抓取的工具，如 Selenium 或 Puppeteer，它们可以像浏览器一样与网页的 DOM 进行交互。

> 但是，如果您需要的信息可以通过网页的静态 HTML 访问，请随时提供网址并描述您感兴趣的信息，我会尽力帮助您！

这样看来，如果你希望抓取动态网页内容，恐怕目前 Scraper GPT 无能为力，或许你还真的无法摆脱编程的必要步骤。

## **小结**

通过咱们的演示你可以看出，这款名叫 Scraper 的 GPT 工具非常方便好用。文本、图片、链接这些信息类型，Scrapper GPT都可以根据你提供的链接轻松获取。因为有了链接，你还可以进一步抓取二级页面的信息。重要的是，**整个过程完全不需要编程**。

当然Scraper GPT也有局限性，就是**无法准确处理动态网页的内容**。对于这些高阶操作，你目前可能还是需要借助 Selenium 等工具，通过编程来实现。但是我相信，随着 AI 能力的进一步提升，以及应用集成度的改进，这些强烈的用户需求，应该在不久后就有免费便捷的工具可以满足了。生活在这样一个人工智能快速进展的时代，真的很容易激动啊。

如果你觉得本文有用,请**充电**。

如果本文可能对你的朋友有帮助,请**转发**给他们。

欢迎**关注**[我的专栏「科研利器」](https://sspai.com/column/245),以便及时收到后续的更新内容。

[点击这个链接加入少数派会员](https://sspai.com/prime/subscription?referral=314606736),立享 9 折优惠!获得专属会员内容、会员播客以及会员定制周边。在更多的领域和方向帮你打开脑洞,找到新的兴趣点,与少数派一起洞悉当下,探索新知。

![](https://proxy-prod.omnivore-image-cache.app/0x0,sLlnRwoncQKjg1426Y_H0Psi8THOzOBAYXngwNqUAxWY/https://cdn.sspai.com/article/306432ff-1259-f987-3a4f-271211977cea.jpg?imageMogr2/auto-orient/thumbnail/!200x268r/gravity/center/crop/200x268/format/webp/ignore-error/1) 

经验卷轴：入门学术论文写作

用二十余年的科研经验带你入门学术写作

## **延伸阅读**

* [如何用 ChatGPT 的 Advanced Data Analysis 帮你采集数据？](https://mp.weixin.qq.com/s/nJZkaSb4RQoHGgFsvnpUJQ)
* [如何不编程，采集网站评论信息？（视频教程）](https://mp.weixin.qq.com/s/DrdZ8NAms7i9spjArPWmiw)
* [如何用 Python 爬数据？（一）网页抓取](https://mp.weixin.qq.com/s/BjULBfwVPO73Hk4lw1S%5FmQ)
* [如何用 ChatGPT 帮你自动分析数据？](https://sspai.com/post/79800)
* [如何用 ChatGPT 一句话生成 Web 应用？](https://sspai.com/post/80135)

[![玉树芝兰](https://proxy-prod.omnivore-image-cache.app/0x0,sqmDizW3yZzYMZ0RYy9g-kOTZ-Pxki-DR4Eit-78RdDk/https://cdn.sspai.com/article/02c1b4c9-ffb3-b89b-9fe1-bdc9abbc5d43.jpeg?imageMogr2/auto-orient/thumbnail/!84x84r/gravity/center/crop/84x84/format/webp/ignore-error/1)![](https://proxy-prod.omnivore-image-cache.app/0x0,swNGK0FlxMz_yBJeOhOiSR4MTC5k8sDsv1pLeU1VQnMA/https://cdn-static.sspai.com/ui/badge/prime_S03_512.png)](https://sspai.com/u/a5xddvxl/updates)

 王树义。大学教师，终身学习者。稍微懂一点儿写作、演讲、Python和机器学习。欢迎关注我的公众号“玉树芝兰”(nkwangshuyi)。

---

