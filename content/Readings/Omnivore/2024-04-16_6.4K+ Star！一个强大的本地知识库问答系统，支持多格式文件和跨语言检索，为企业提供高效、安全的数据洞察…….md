---
id: 9cda5c50-73a0-4e82-8fb7-4697e66f0b24
title: |
  6.4K+ Star！一个强大的本地知识库问答系统，支持多格式文件和跨语言检索，为企业提供高效、安全的数据洞察……
author: |
  鱼满满探索记
date_saved: 2024-04-16 11:51:18
date_published: 2024-04-04 12:40:00
draft: true
---

# 6.4K+ Star！一个强大的本地知识库问答系统，支持多格式文件和跨语言检索，为企业提供高效、安全的数据洞察……
#Omnivore

[Read on Omnivore](https://omnivore.app/me/-18ee70fe22e)

[Read Original](https://mp.weixin.qq.com/s/U9PMR2vZg7utHElj5jVeyQ)

date_saved: 2024-04-16 11:51:18

date_published: 2024-04-04 12:40:00

--- 

# Full Content: 

![cover_image](https://proxy-prod.omnivore-image-cache.app/0x0,shYOV9m8WKSdjbtJkpbdo0icUPLZDAK2c6NqBYqyk0ZU/https://mmbiz.qpic.cn/sz_mmbiz_jpg/YV7AAYWzu1Dibic5ISUSic3AP6jfWicC1XfQsc9eY324GicmUHOfQNe8z9A6EcRN0IqpPTx9SrmbIPTqUzosmbmFjeg/0?wx_fmt=jpeg) 

Original 鱼满满探索记  AIGC创想者 _2024-04-05 00:40_ _北京_ 

> https://github.com/netease-youdao/QAnything
> 
> 【阅读原文】跳转Github项目

## 项目简介

**QAnything** 是一个基于本地知识库的问答系统，它能够理解和回答基于任何类型文件的问题。

QAnything支持的文件格式非常广泛，包括`PDF、Word、PPT、XLS、Markdown、Email、TXT、Image、CSV和Web链接`等，这使得它能够适应多种不同的使用场景。

![Image](https://proxy-prod.omnivore-image-cache.app/0x0,s9pcNOO0eGUYt93Lf-KjIqeS6gD4vqmDAM5e3vRzjVJE/https://mmbiz.qpic.cn/sz_mmbiz_png/YV7AAYWzu1CuL31DcOdcOjGCEnhpMe8LSAKS1gG7dLbkI7QfbcWW7THVFeu8OOQMOQGpGcXfpw3rehBMXaiaNyg/640?wx_fmt=png&from=appmsg)

### 适用场景

QAnything适合于需要处理和分析大量文档和数据的场景，如企业知识管理、学术研究、法律文档审查、市场分析等。

1. 企业知识管理：企业可以利用QAnything构建内部知识库，员工通过自然语言问答的方式快速获取所需信息，提高工作效率。
2. 学术研究：研究人员可以使用QAnything来管理和分析大量的学术论文、报告和数据集，快速找到研究中需要的信息。
3. 法律文档审查：法律专业人士可以使用QAnything来审查和分析合同、法律文件等，确保文档的合规性和准确性。
4. 市场分析：市场分析师可以利用QAnything分析市场报告、消费者反馈等，以获得有价值的市场洞察。

### 使用方法

QAnything项目的安装步骤分为几个主要部分，包括系统要求、Docker安装和纯Python环境安装。以下是详细的安装步骤：

#### 系统要求

在开始安装之前，请确保您的系统满足以下最低要求：

* Linux：推荐使用NVIDIA GPU（至少GTX 1050Ti，更好的选择是RTX 3090），并确保GPU内存至少为4GB（如果使用OpenAI API）。
* NVIDIA驱动：版本至少为525.105.17。
* Docker：版本至少为20.10.5。
* Docker Compose：版本至少为2.23.3。
* Git Large File Storage (LFS)：需要安装。

#### Docker安装

1. 拉取QAnything仓库：

`git clone https://github.com/netease-youdao/QAnything.git
`

1. 进入项目根目录：

`cd QAnything
`

1. 根据提供的启动脚本和说明启动QAnything服务：
* 默认在GPU 0上启动（如果使用OpenAI API，确保GPU内存至少为4GB）。

`bash run.sh
`

1. 指定GPU启动（可选）：
* 对于Windows10/Windows11 WSL2用户，推荐使用以下命令启动：

`# For Windows OS: Need to enter the **WSL2** environment.
# Step 1. Download the public LLM model (e.g., Qwen-7B-QAnything) and save to "/path/to/QAnything/assets/custom_models"
# (Optional) Download Qwen-7B-QAnything from ModelScope: https://www.modelscope.cn/models/netease-youdao/Qwen-7B-QAnything
# (Optional) Download Qwen-7B-QAnything from Huggingface: https://huggingface.co/netease-youdao/Qwen-7B-QAnything
cd QAnything/assets/custom_models
git clone https://huggingface.co/netease-youdao/Qwen-7B-QAnything
# Step 2. Execute the service startup command. Here we use "-b hf" to specify the Huggingface transformers backend.
cd ../../
bash ./run.sh -c local -i 0 -b hf -m Qwen-7B-QAnything -t qwen-7b-qanything
`

* 对于GPU计算能力大于等于8.6且VRAM大于等于24GB的情况，可以使用多GPU启动：

`bcd QAnything
bash ./run.sh -c local -i 0,1 -b default  # gpu ids: 0,1, Please confirm how many GPUs are available. Supports up to two cards for startup. 
`

1. 体验应用：
* 通过在Web浏览器中输入以下地址来访问前端界面：`http://your_host:5052/qanything/`
* 如果需要访问API，请参考API地址：`http://your_host:8777/api/`
1. 关闭服务（如果需要）：
* 使用以下命令关闭服务：

`bash close.sh
`

1. 离线安装：

如果需要在没有网络的环境中安装QAnything，可以在有网络的机器上下载Docker镜像和代码，然后将镜像和代码复制到离线机器上，加载镜像并运行。

---

**注：本文内容仅供参考，具体项目特性请参照官方 GitHub 页面的最新说明。**

欢迎**关注&点赞&在看**，感谢阅读\~

---

