---
id: fbb9197c-a213-11ee-899c-5b67347ad523
title: |
  为什么大模型会「说胡话」？如何解决大模型的「幻觉」问题？ - 知乎
author: |
  unknown
date_saved: 2023-12-23 19:24:20
date_published: 2023-12-23 19:24:20
draft: true
---

# 为什么大模型会「说胡话」？如何解决大模型的「幻觉」问题？ - 知乎
#Omnivore

[Read on Omnivore](https://omnivore.app/me/-18c9a0ef497)

[Read Original](https://www.zhihu.com/question/635776684/answer/3336439291)

date_saved: 2023-12-23 19:24:20

date_published: 2023-12-23 19:24:20

--- 

# Full Content: 

## 为什么大模型会「说胡话」？如何解决大模型的「幻觉」问题？

[![](https://proxy-prod.omnivore-image-cache.app/0x0,sxm5euxPAaQhujrYDXUvPk4xRPi7C76qweZub0iidFEA/https://picx.zhimg.com/v2-a757af2df0311cd079e7e2951f3b0d9a.jpg?source=c885d018)79% 知友推荐 · 78 人评价2023 年已过去大半，历史扑面而来，我们身处其中也不断见证着无穷的变化。随着社会的自然发展，人们的思想观念、生活需求在不断更迭，我们正在经历哪些困境？明年还会遇到哪些新的问题？这些问题在新一年是否会有更优解？ 带着对未来的疑问和对世界的好奇遥望 2024 年，邀请你一起立足当下，探索未知世界的无限可能，向未来洞见答案。​​](https://www.zhihu.com/topic/28901735)

关注者

**178**

被浏览

**54,410**

[![平凡](https://proxy-prod.omnivore-image-cache.app/0x0,sWVj_UIfT35Uoeg-OhzhRe0k0RPxlxvRUkv_l50g4-30/https://picx.zhimg.com/v2-9f81432bb5f397e14ec2c65e949eb0d3_l.jpg?source=2c26e567)](https://www.zhihu.com/people/jzwa)

[平凡](https://www.zhihu.com/people/jzwa)

[​](https://www.zhihu.com/question/48509984)

英语等 2 个话题下的优秀答主

​ 关注

27 人赞同了该回答

​

目录

收起

幻觉的定义

幻觉的类型

源文本（天气报告）：

情况一：内在幻觉

情况二：外在幻觉

幻觉的原因

解决方法

未来方向

有一篇最近的高引用论文《Survey of Hallucination in Natural Language Generation》，是香港科技大学的成果。

讨论的正好就是大模型的幻觉问题，也就是Hallucination。

![](https://proxy-prod.omnivore-image-cache.app/2320x1500,siN313kr8O-uO-MBtTjKulrKRzpaP2vfk0b4_eek9DTg/https://picx.zhimg.com/50/v2-31df58c57535a9b350fb2db51bd69dd0_720w.jpg?source=2c26e567)

## 幻觉的定义

先说幻觉Hallucination的定义，作者采用了这个定义：

> the generated content that is nonsensical or unfaithful to the provided source content   
> 即生成的内容是无意义的或不忠实于提供的源内容

文中提到了，在自然语言处理之外的一般语境中，幻觉的定义是 

> hallucination is a psychological term referring to a particular type of perception。  
> 幻觉是一个心理学术语，指的是一种特定类型的感知。

在NLP或者大模型的语境下，幻觉是一种虚假的感知，但感觉上却是真实的。

这可能解释起来有点儿绕口，比如说我们问ChatGPT，离离原上草一岁一枯荣是谁写的？

ChatGPT可能会一本正经的跟你说这是明代诗人李白写的诗，如果你恰好不知道这个问题，那么明代是真实的，李白也是真实的，那么你就可能会相信ChatGPT说的是真的。

如果不清楚ChatGPT的生产原理，可以移步下文。

[](https://www.zhihu.com/question/598243591/answer/3331628116)

幻觉会觉文本给人一种流畅自然的印象，尽管它是不忠实和无意义的，这也是为什么幻觉会很难一眼看出来。

## 幻觉的类型

幻觉主要分类两种类型：

* **内在幻觉**：生成的内容与源内容相互矛盾
* **外在幻觉**：生成的内容无法从源内容中验证，既可能正确也可能错误。

让我们通过一个简单的例子来说明自然语言生成（NLG）中的幻觉现象：

假设有一个NLG系统，其任务是根据给定的天气报告文本生成简短的天气摘要。现在，考虑以下两种情况：

### 源文本（天气报告）：

"今天北京的天气晴朗，最高气温达到了30度。"

### 情况一：内在幻觉

**生成的摘要**："今天北京出现了大雨，气温下降到了20度。"

**解释**：这里，生成的摘要与源文本相矛盾。源文本提到天气晴朗和温度较高，而生成的摘要错误地提到了大雨和气温下降，这就是内在幻觉的一个例子。

### 情况二：外在幻觉

**生成的摘要**："今天北京天气晴朗，另外，明天有可能下雨。"

**解释**：在这个例子中，生成的摘要正确地提到了“今天北京天气晴朗”，这与源文本一致。但是，它还添加了“明天有可能下雨”的信息，这个信息在原始报告中没有提及。虽然这个附加信息可能是正确的，但因为它无法通过源文本进行验证，因此被视为外在幻觉。

内在幻觉和外在幻觉有可能同时存在，也可能单独存在，挺随机的现象。

_接下来的两个部分为幻觉产生的原因和解决方法，其中涉及到了很多专业知识，看不懂的朋友可以略过，你只要记住，大模型的幻觉在现阶段是不可避免的，它生产的内容只要是你不能确定的部分，都需要你手动去确认一遍。_

##   
幻觉的原因

* **数据驱动原因**：训练数据中源与参考的不匹配可能导致幻觉，如数据对不对齐，导致生成不忠实的文本。
* **表示和解码的不完善**：编码器理解能力的缺陷和解码器策略错误可能导致幻觉。解码器可能关注错误的输入部分，或使用增加幻觉风险的策略，例如基于采样的解码中的随机性。
* **参数知识偏见**：预训练模型可能偏好其参数中的知识而非新输入，从而导致幻觉。解决幻觉现象的方法

## 解决方法

* **构建忠实数据集**：手动创建含准确目标的数据集，或用标注员标记生成的数据中的幻觉。这种方法针对特定任务，可能资源密集型。
* **自动清洗数据**：在实例级别过滤掉幻觉内容，或根据参考修正输入数据，特别适用于结构化数据到文本任务。
* **信息增强**：用外部信息增强输入数据，更好地与目标对齐，提高模型的语义理解能力，减少与源的偏离。
* **模型和推理技术**：
   * 改进编码器和注意力机制：修改编码器架构和注意力机制，更多关注源数据，提高表示学习。
   * 改进解码器：使用多分支、意识到不确定性或受限的解码器来减少幻觉的可能性。
* **训练方法**：
   * 规划/草图：实施单独的规划步骤或将其整合到模型中，控制内容生成。
   * 强化学习：使用奖励优化模型，以减少幻觉。
   * 多任务学习：同时在多个任务上训练，提高模型的泛化能力，减少对单一数据集的依赖。
* **可控生成**：使用技术控制输出中的幻觉程度，适应不同的应用需求。
* **后处理**：使用生成-然后-精炼策略纠正输出中的幻觉，特别适用于嘈杂的数据集。

## 未来方向

* **自动化幻觉检测和评估方法**：发展更有效的自动化工具来识别和评估幻觉，例如基于注意力机制的分析和统计方法。
* **跨领域和多模态方法**：探索在不同领域（如图像、视频和文本）之间的幻觉识别和处理。
* **增强现实世界知识**：集成更多的外部信息和上下文知识，以提高模型对现实世界的理解和处理能力。
* **解释性和透明性**：提高模型的解释性，以便更好地理解和解释幻觉的原因。

参考文献：

Ziwei Ji, Nayeon Lee, Rita Frieske, Tiezheng Yu, Dan Su, Yan Xu, Etsuko Ishii, Ye Jin Bang, Andrea Madotto, and Pascale Fung. 2023\. Survey of Hallucination in Natural Language Generation. ACM Comput. Surv. 55, 12, Article 248 (December 2023), 38 pages. 

[编辑于 2023-12-24 00:24](https://www.zhihu.com/question/635776684/answer/3336439291)・IP 属地英国

​赞同 27​​2 条评论​收藏​喜欢收起​

[![小林不加班](https://proxy-prod.omnivore-image-cache.app/0x0,sXYrWz9IfkNRy2MQ4pSPgJPj9iNgFTDC4Nxrvj1NpV2g/https://picx.zhimg.com/v2-227bdc841183235523b20ceb473e7649_l.jpg?source=1def8aca)](https://www.zhihu.com/people/pdfji-qiao-da-shi)

[小林不加班](https://www.zhihu.com/people/pdfji-qiao-da-shi)

​![](https://proxy-prod.omnivore-image-cache.app/0x0,sEQaOWrSM4sYxMszrQ6lhsM51WgM5AvlqxCkeG6GJZz4/https://pic1.zhimg.com/v2-4812630bc27d642f7cafcd6cdeca3d7a.jpg?source=88ceefae)

好用办公软件推荐、省时办公技巧分享

​ 关注

## 问到点上了！

小林我在这一年里热衷于跟随潮流，也把玩过各种AI对话产品，其中有部分的乐趣和吐槽就来源于：AI的满嘴跑火车。

先给大家看个搞笑的，要论大模型一本正经的胡说八道，还属AI写作最为夸张

> 问：就“怀民亦未寝”......展开续写。  
> 答：

![](https://proxy-prod.omnivore-image-cache.app/288x645,sDHZRinVWedKr9kSx7MreobdqX4L5QZLlkwN3wI7qWww/https://picx.zhimg.com/50/v2-1aa4ab8aa40e418755502571f2cd411c_720w.jpg?source=1def8aca)

从张怀民揪住苏轼的领子之后开始放飞自我，已经不敢再让它再续写下去了。想象力那叫一个惊人！

## 科普时间丨

说来说去，AI如此能胡说八道，其实是因为它的「幻觉」在作怪。

也就是说，我们看到的那些AI生成的胡编乱造、非真实存在或不准确的信息，就是AI幻觉。

AI的幻觉和人的幻觉成因还挺相似的，大概就是：

> 不懂装懂  
> 自我认知偏差  
> and喝多了...

**AI幻觉也是大模型中常见的问题。**没办法，**这可能就是LLM的固有特性，**只能说AI没有真实世界的经历，单靠语料库中的数据，再加上使用者语言的引导，“幻觉”难以避免。

就目前来看，还没有一种模型是能够完全避免产生一些幻觉的，**就连ChatGPT在生成文本中大约就有15%至20%的内容存在幻觉。**

![](https://proxy-prod.omnivore-image-cache.app/1260x0,szo4OP2_4Cf0hMgAv9s8if2yvQq_gHwCPFsHe7QlJlY0/https://picx.zhimg.com/50/v2-48f0864ef95b0d9c895a02baf9793082_720w.jpg?source=1def8aca)

至于说解决办法，只能说，**_就目前来看还没有办法完全解决大模型「幻觉」的问题_**，前文也有讲到「幻觉」是现在LLM的固有特性。

## 既然不能完全解决，那我们就有效避免

AI不会明确地告诉你它何时会产生幻觉，咱们自己也没有哪一种方法是完全可以解决目前的AI幻觉问题，所以**有效避免幻觉更好的方法，就是透过提示工程学习和AI互动交流。**

### 那啥是提示工程呢？

和Prompt对应的一个专业词汇是Prompt Engineering（PE），它是AI领域中的一个概念，**尤其是自然语言处理（NLP）领域，它可以让机器理解和生成自然语言**，这就是提示工程。

就好比你想用GPT、DALL-E等这些模型来完成各种任务，如写诗、画画、编程等，但要想让它们完全根据自己意愿“做事”，这时候就需要有Prompt Engineering这一概念了。

![](https://proxy-prod.omnivore-image-cache.app/846x0,s8L-v-vTj1E_bSsBufW_6CndgvbOFR4kv5fzrM4OFTJk/https://pic1.zhimg.com/50/v2-449bca50f74d96e998d52079ef2a4f63_720w.jpg?source=1def8aca)

它的作用就在于**可以使AI更加灵活和精确地理解任务**，减少因为语言表达不清晰而导致的误解和错误，就好像我们和AI之间的桥梁。

如果你想要有效避免大模型幻觉，让AI真正懂你，特别是现在很多AI产品的智能化水平都还有待进一步提升的情况下，学一点Prompt Engineering的知识是很有必要的。

> 具体的学习步骤可以参考两点：

### ①精准表达任务指令（用官方、书面、礼貌、友善的语言撰写提示词）

比如你在文生图模型中，应该经常会看到类似：中国风、人物写真、低饱和度、超高细节等提示词，

如果把这些tag展开成流畅的自然语言作为Prompt，图像生成的效果反而更差，**以这种序列排布的标签Prompt，简短清晰，更能让AI理解操作。**

![](https://proxy-prod.omnivore-image-cache.app/455x0,s2u_u8Ylt-8e8ObeYCp7VvQzM_Y2VQANfGWQTUhRwjNY/https://pica.zhimg.com/50/v2-c8ea2a502a6f9fe9a6cea57bf281949d_720w.jpg?source=1def8aca)

### ②确定最终含义（比如你想要AI生成“好结果”，那你的提示词上就要有明确的指向）

Prompt的性能上限与我们对输出结果的理解程度成正比，**只有充分理解了所谓的“好结果”具体好在哪些“点”，我们才能将这些“点”形式化为Prompt**，从而把我们的意图更准确地传达给模型，当然不同的用户有不同的需求，例如：

> ✖：请写一篇关于《坚如磐石》的影评。  
> ✔：请从人物和剧情这两个角度入手，以专业的视角为《坚如磐石》写一份通俗易懂的800字影评。

身为GPT用户，相信我们每位都曾有过被GPT“欺骗”的经验。 就像在互联网上的任何地方，我们应该随时保持警惕，更要认识到“眼见不一定为实”，避免眼见为实的错误。

其实就从现在的大模型来看，它们并不完美。和人一样，也会犯错误，混淆视听，但在具有误导性的同时，也存在着创造性，总之对于AI大模型还是需要加以规范使用。

不过，**从另一种角度来看，AI幻觉有恰恰是创造力的表现**。因为正是这种创造性回应的能力使AI成为产生新想法或解开思考瓶颈的强大工具。

接下来**_介绍4款AI工具，带大家看看AI发挥创造力是会怎么样的\~_**

### 【百度作家平台】

一个专为网文作家开发的平台，集合了创作+投稿于一体，不仅可以辅助作家完成小说的内容创作，还方便他们发布投稿到平台中推广。

它可以通过与AI对话的方式，**帮我们解决创作中的问题：文笔、书写、剧情等方面都可以让它指导；还能帮我们续写小说的情节、故事大纲等内容**。

![](https://proxy-prod.omnivore-image-cache.app/553x0,sh2YCy2j_39-n7BrRkEwo5YGwzvK-mWKDgQ0egEtlStI/https://picx.zhimg.com/50/v2-8576353ccb20b7687ede4d7499ed6483_720w.jpg?source=1def8aca)

除此之外，它还有一系列AI自动生成功能，例如小说细节、角色起名、续写、润色等等，为我们的写作提供更多的灵感。

![](https://proxy-prod.omnivore-image-cache.app/306x0,sx3wME5C-z81G3FLh13OtlnVw7gJeOs5CYJm48QvjW7Q/https://picx.zhimg.com/50/v2-968b3b846fa08a7f9ff823a62cf5f8dc_720w.jpg?source=1def8aca)

### 【抠图改图王】

**一款AI全自动修图软件。同时它也是一个素材作图工具**，不仅提供各种AI修图功能，而且还内置了多种素材可供制作同款图片/海报。

它还有现在非常火爆的**AI扩图**功能，主要的应用场景还是图片美化，比如很多人在拍照过程中因为周围环境受限，无法进行比例恰当的构图，这个时候就可以利用扩图功能进行美化。

![](https://proxy-prod.omnivore-image-cache.app/1267x0,s444bszqNSxOUR_Mc0spayT7AZz2sn1jly-GnnD-GZrk/https://pic1.zhimg.com/50/v2-5c98f2b8bd70a97bb117d4253d2ff37f_720w.jpg?source=1def8aca)

操作玩法也非常简单，首页进入之后，就可以看到【AI扩图】功能。**只需要上传图片，然后选择扩图比例，等待片刻即可出片！**

![](https://proxy-prod.omnivore-image-cache.app/1080x0,syUwXPVHP7fJ01UW9UPv3iyaYCY-7Np1A-JB_gn1A0uk/https://picx.zhimg.com/50/v2-59ca79650b2ab73f29b2f16f4ea2ecb6_720w.jpg?source=1def8aca)

### 【Pika】

这款AI工具的创造力在于它可以由文字生成视频，而且是完全100%从文字生成视频内容，不需要我们提供任何画面。

![](https://proxy-prod.omnivore-image-cache.app/554x0,sdEDueX1raH0umsd-XApxLFok5G4ch3zazhTbKBonwto/https://picx.zhimg.com/50/v2-5535f0c4ec24b6004729dfec8dc067f7_720w.jpg?source=1def8aca)

它还可以对视频画面内的人物进行**一键换装**，比如，选定视频中的人物衣服，用文字输入你想让它搭配的服装，就可以完成一键换装。

同理，不止换装。它还可以作为AI魔法棒，视频中的任何区域有需要更改的，你都可以用这个方法，**一键选定区域，输入文字，就可以秒变你想要的画面**。

![](https://proxy-prod.omnivore-image-cache.app/554x0,s9TxTLhDwkYACvbHZhL6ATbDT5RBjmpICVXs4mYq9tFY/https://picx.zhimg.com/50/v2-3c2dc6eabfbdfadee4d45776830faf47_720w.jpg?source=1def8aca)

### 【通义万相】

通义系列上线了的通义万相这个AI绘画创作大模型，**主要的功能有文生图、相似图生成以及风格迁移。**

它可以对配色、布局、风格等图像设计元素进行拆解和组合，提供高度可控性和极大自由度的图像生成效果。

![](https://proxy-prod.omnivore-image-cache.app/554x0,sEWLOtwjwdQTfN4NXuc8BofwBiVO5xq3aVh60sCDmlR0/https://picx.zhimg.com/50/v2-e3b31c5776886e8e3bceaa548a559b0f_720w.jpg?source=1def8aca)

除此之外，我觉得它和其他AI绘画工具有区别的是：它的**虚拟模特**功能，它可以**借助AI生成一个万全虚拟的模特，用来展示画面中指定的商品**，完全不需要我们提供模特实图，即可自动生成，非常具有创造性。

![](https://proxy-prod.omnivore-image-cache.app/554x0,sVsVQSdHFMCJ9T1yPCZrFOLw6i04SteW4N1WEayV_MRM/https://pica.zhimg.com/50/v2-a299d65c5d0e42452d504b7e94af56b1_720w.jpg?source=1def8aca)

以上就是话题的全部内容，看完别忘了给小林留下点什么，这样 

[@小林不加班](https://www.zhihu.com/people/9f78574704eae60cfbb99223eff88494)

 才有动力继续分享，整理比上班还累的哇\~

展开阅读全文​

​赞同 20​​2 条评论​收藏​喜欢

[![赛车手](https://proxy-prod.omnivore-image-cache.app/0x0,sjU7TYH17Bi_BptGGEbtAnc2uOUcj-rPinpMUsdIxEfg/https://picx.zhimg.com/v2-adb331745947416ba87f07c0e752623d_l.jpg?source=1def8aca)](https://www.zhihu.com/people/leon-84-25)

[赛车手](https://www.zhihu.com/people/leon-84-25)

人工智能，大数据，云计算从业老兵

​ 关注

大模型会「说胡话」的原因主要有以下几个：

* \*\*数据偏差。\*\*大模型通常是通过大量的数据进行训练，而这些数据可能存在偏差。例如，一个训练了大量的网络文学数据的模型，可能会生成具有网络文学风格的「胡话」。
* \*\*模型复杂度。\*\*大模型的参数数量通常非常庞大，这使得模型的训练和控制变得困难。在某些情况下，模型可能会生成不符合逻辑或常识的「胡话」。
* \*\*算法缺陷。\*\*大模型的训练算法仍在不断发展，其中可能存在一些缺陷。这些缺陷可能会导致模型生成「胡话」。

解决大模型的「幻觉」问题，最常用的办法是RAG技术，也叫检索增强技术。

检索增强生成是将用户自有数据知识库的信息补充到大语言模型（LLM）中的过程。然后，LLM 可以使用这些信息来增强其生成的回答或响应。

这个流程始于用户提出的问题，例如“我该如何做<某件事>？”

**首先进行的是检索步骤。这个过程是根据用户的问题，从知识库中检索可能回答问题的最相关内容。**到目前为止，检索步骤是 RAG 链中最重要、最复杂的一个部分。但现在，只需把这个步骤当成一个黑盒子即可，它知道如何提取与用户查询最相关的信息块。

难道我们不能把整个知识库交给 LLM 吗？  
您可能会想知道，为什么我们要这样费心进行检索，而不是直接将整个知识库发送给LLM。其中一个原因是大模型预置了每次可读取文本的数量限制（尽管这些限制的上限正在快速增长）。第二个原因是成本 —- 发送大量文本是非常昂贵的。最后，有证据表明，仅发送少量相关信息会产生更好的答案。  
一旦我们从知识库中获取到了相关信息，就会将其与用户的问题一起发送给大语言模型（LLM）。**LLM会“读取”提供的信息并回答问题。这就是增强生成步骤。**

![](https://proxy-prod.omnivore-image-cache.app/658x0,seZxYojo3cNjpcdr7bbXby3UbvIeSNhrLAGVpJvgDGe0/https://pic1.zhimg.com/50/v2-7a592fdee4b2cca8e9532c53ff0069ea_720w.jpg?source=1def8aca)

**检索的核心是搜索操作——我们希望根据用户的输入查找最相关的信息。**就像搜索一样，检索有两个主要部分：

* **索引：**将知识库转换为可搜索/查询的内容。
* **查询：**从搜索内容中提取最相关的知识片段。  
**首先，我们需要对知识库进行索引。**使用加载器获取知识并将其转换为单个文档，然后使用分割器将其转换为小块或片段。有了这些片段后，我们将它们**传递给嵌入机**，嵌入机将它们转换为可以用于语义搜索的向量。我们**将这些嵌入向量与其文本片段一起保存在向量数据库中。**

![](https://proxy-prod.omnivore-image-cache.app/582x0,sNyL4q1cMQDB1zo1WV9csiSR1KqpoRtSjZe1DGFNMamg/https://picx.zhimg.com/50/v2-3efc61c566fcd731c500daa321715d93_720w.jpg?source=1def8aca)

**接下来是检索。**该过程始于提出的问题，然后将问题通过相同的嵌入机发送到向量数据库中，以**确定最匹配的片段**，最后将**使用这些片段来回答问题**。：

![](https://proxy-prod.omnivore-image-cache.app/856x0,swoBhB12pf-S0bFEEqqng6T77TQ73jqyFLa9HMIiAUdo/https://picx.zhimg.com/50/v2-f883b5fccd9391b051429cbe460b3a02_720w.jpg?source=1def8aca)

**最后是检索增强的答案生成。**将知识片段与自定义的system prompt和我们提出的问题一起格式化，**最终得到针对具体语境的答案**。

![](https://proxy-prod.omnivore-image-cache.app/993x0,snfF35DrlieWhH1GjA-JVT8JVdL0_GOOwtZ28jbCloF0/https://picx.zhimg.com/50/v2-874f9818cebf261a3ea6d50232ad1118_720w.jpg?source=1def8aca)

总结一下，RAG 技术将大规模预训练语言模型中的生成模块与大规模检索模块相结合。在回答问题时,RAG 先利用检索模块从大规模文本库中找到相关的证据文本,然后输入问题及相关证据到生成模块,产生符合逻辑和事实的回答。

相比单独使用大模型生成答案,RAG 引入检索机制具有以下优点:

1. 利用检索机制可以连接真实世界知识,避免模型生成虚假信息。
2. 检索到的证据文本可以指导并约束模型的生成,防止模型产生离题的答案。
3. 检索文档为模型提供外部信息,减少模型需要完全自主学习知识的压力,这样可以缩减模型大小,降低计算成本。
4. 检索文档为模型答案提供了事实依据和来源,增加了模型产生答案的可解释性和可信度。

综上,RAG技术通过引入检索机制,利用大量真实外部文本指导模型生成,可以明显减少大模型生成非理性、不真实答案的风险,避免陷入纯生成模型的幻觉问题。

展开阅读全文​

​赞同 6​​添加评论​收藏​喜欢

---

