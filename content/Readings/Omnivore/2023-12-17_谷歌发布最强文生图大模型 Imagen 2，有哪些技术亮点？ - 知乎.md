---
id: b5844fd0-9cd7-11ee-a98b-cb3101a18c46
title: |
  谷歌发布最强文生图大模型 Imagen 2，有哪些技术亮点？ - 知乎
author: |
  unknown
date_saved: 2023-12-17 04:16:48
date_published: 2023-12-17 04:16:48
draft: true
---

# 谷歌发布最强文生图大模型 Imagen 2，有哪些技术亮点？ - 知乎
#Omnivore

[Read on Omnivore](https://omnivore.app/me/imagen-2-18c77bf5586)

[Read Original](https://www.zhihu.com/question/635127674/answer/3328916353)

date_saved: 2023-12-17 04:16:48

date_published: 2023-12-17 04:16:48

--- 

# Full Content: 

卷疯了卷疯了，谷歌刚刚放出了文生图AI模型的巅峰之作Imagen 2，实测效果逼真细腻，生成的美女图仿佛真人照片，对于提示的还原程度已经打败了DALL…显示全部 ​

关注者

**178**

被浏览

**129,038**

[![段小草](https://proxy-prod.omnivore-image-cache.app/0x0,s-6yaWqXOcjinF3_fgLeMHsp9BgLZpI5tVrBCMPtLKhk/https://pica.zhimg.com/6cc78144fed4969434ee35c1f5b0344f_l.jpg?source=2c26e567)](https://www.zhihu.com/people/loveQt)

[段小草](https://www.zhihu.com/people/loveQt)

[​](https://www.zhihu.com/question/48509984)​![](https://proxy-prod.omnivore-image-cache.app/0x0,sKBtfFYtK0ROqGdvN0zCp5BhZ6pS4CW6jvNAosyO8byE/https://pica.zhimg.com/v2-4812630bc27d642f7cafcd6cdeca3d7a.jpg?source=88ceefae)

Python话题下的优秀答主

​ 关注

46 人赞同了该回答

谷歌 Imagen 2 [\[1\]](#ref%5F1)的最强文生图是谁封的…谷歌内部吗？下周 Midjourney 要发布 v6 了，日常使用有 ChatGPT plus 带的 Dall·E 3，Meta 也发布了 imagine[\[2\]](#ref%5F2)，关键是这几个产品都面向用户直接能用，我也看不出谷歌有什么突出的优势…说实话我会更期待 Midjourney v6 的表现。

![](https://proxy-prod.omnivore-image-cache.app/1072x1142,spI0Fc2JS_C_AdkfCb-brgVlOzC7E_yHFX4KODCunVxc/https://pica.zhimg.com/50/v2-5bdf50a66d93dc359531ea5547d2f3b7_720w.jpg?source=2c26e567)

而且谷歌目前是虚空发布，反正不让用，大家也只能拿官方宣发的 blog 吹（说是 API 可以用，但我自己没找到用的途径，如果有人知道能用上 Imagen 2 可以评论区说下，咱也不明白谷歌这么好的技术为啥不直接做个文生图的网站，要拐着弯用 API 调用）。

![](https://proxy-prod.omnivore-image-cache.app/1072x1090,sZUNhUJq-A6IDPi9vAG6ZZaPQ3iOUHeq8ggFVR8Num6I/https://pic1.zhimg.com/50/v2-64fea644dd14b90df50b2cb825313991_720w.jpg?source=2c26e567)

考虑到官方发布 cherry-pick 的传统，我不敢抱太大的希望…

---

谷歌这次主要宣传的几个特点[\[3\]](#ref%5F3)：

* 高质量图像：Imagen 2 可以通过改进的图像+文本理解技术和多种新型训练和建模技术实现准确、高质量的逼真图片输出。

![](https://proxy-prod.omnivore-image-cache.app/1400x522,sM8BrVMywvsrB98TOvn6j2kVuzl_GqrFLMKTa0k2pMlQ/https://pic1.zhimg.com/50/v2-33d37a06ec81b316bcc236c4fac38c3f_720w.jpg?source=2c26e567)

* 文本渲染支持：文生图技术通常难以正确渲染文本（确实，Dall·E 3表现也一般，而且不支持中文）。例如，如果模型被提示生成带有特定单词或短语的对象的图片，确保正确的短语是输出图像的一部分可能是具有挑战性的。Imagen 2可以帮助解决这个问题，这可以为组织的品牌和信息传达提供更深层次的控制。

![](https://proxy-prod.omnivore-image-cache.app/2000x1161,s-FZqNmL5qnrTLvPCyN5OsTO1tYD9jnty7USulDWQ8aw/https://picx.zhimg.com/50/v2-9f33c3144bdfe86adcf341c8c076bf00_720w.jpg?source=2c26e567)

* Logo生成：Imagen 2可以为企业、品牌和产品生成各种创意和逼真的徽标，包括徽章、字母标记和抽象logo等。它还可以将这些logo叠加到产品、服装、商业卡片和其他表面上。

![](https://proxy-prod.omnivore-image-cache.app/2000x1161,s8DYb9g9akiR6WHWLj3jjNlKovx0RFNn2y5C0VLQJwg8/https://pic1.zhimg.com/50/v2-a66bf948e657a9ea3927c0665df47c41_720w.jpg?source=2c26e567)

* 标题和问答：Imagen 2的增强图像理解能力可使客户创建具有描述性的长篇标题，并获得有关图像内元素的详细答案。
* 多语种提示：除了英语，Imagen 2 还支持六种其他语言 （中文，印地语，日语，韩语，葡萄牙语，西班牙语）进行预览，计划在2024年初发布更多语言。
* 安全性：Imagen 2包含内置的安全预防措施，以确保生成的图像与Google的负责任AI原则相一致。例如，Imagen 2与我们的实验性数字水印服务集成，由Google DeepMind的SynthID提供支持，允许列入白名单的客户生成不可见水印，并验证Imagen生成的图像。Imagen 2还包括全面的安全过滤器，以帮助防止生成潜在有害内容。

## 参考

1. [^](#ref%5F1%5F0)<https://deepmind.google/technologies/imagen-2/>
2. [^](#ref%5F2%5F0)<https://imagine.meta.com/>
3. [^](#ref%5F3%5F0)<https://cloud.google.com/blog/products/ai-machine-learning/imagen-2-on-vertex-ai-is-now-generally-available>

[发布于 2023-12-17 09:16](https://www.zhihu.com/question/635127674/answer/3328916353)・IP 属地河南

​赞同 46​​2 条评论​收藏​喜欢收起​

[![小小将](https://proxy-prod.omnivore-image-cache.app/0x0,sxxbIzWUuqCDOA_RAb80ILyvf0T4TvYZlC4fCKFkjuZY/https://picx.zhimg.com/v2-4c580ad38bc656abf65b1a7fb14d4573_l.jpg?source=1def8aca)](https://www.zhihu.com/people/xiaohuzc)

[小小将](https://www.zhihu.com/people/xiaohuzc)

[​](https://www.zhihu.com/question/48510028)

华中科技大学 工学硕士

​ 关注

![](https://proxy-prod.omnivore-image-cache.app/1024x1024,suKF7XT4A-Sja_wZjboi3HodAARByGP4KqPQsXFfn28c/https://pic1.zhimg.com/50/v2-49510d98b9635ec97fa2ec8ba3338b51_720w.jpg?source=1def8aca)

虽迟但到，Google终于在年底发布新的文生图模型Imagen 2，距离第一个版本Imagen发布已经一年多了。Google刚刚发布的Gemini是对标OpenAI的GPT-4，而这次发布的Imagen 2就是对标OpenAI的DALL-E 3。

我们先来看看Google对Imagen 2的整体描述：

> Imagen 2 is our most advanced **text-to-image diffusion technology**, delivering **high-quality, photorealistic outputs** that are closely **aligned and consistent with the user’s prompt.** It can generate more lifelike images by using the natural distribution of its training data, instead of adopting a pre-programmed style.

首先从技术上来看，Imagen 2是基于**扩散架构的文生图模型**，但具体方案是之前Imagen所采用的级联多个pixel diffusion模型，还是像SD那样采用一个latent diffusion模型，这就不清楚了。但是参考目前latent diffusion的火热，我更倾向认为Imagen 2是像DALL-E 3那样采用latent diffuion架构。

![](https://proxy-prod.omnivore-image-cache.app/1060x0,sdC7xHeB-Jvj5xoRkFBUYMPy9qyRLQXk95a20s5EvLXQ/https://pica.zhimg.com/50/v2-555a153d6024b15694e8e87b0278c710_720w.jpg?source=1def8aca)

从模型亮点来看，首先Imagen 2主打的是生成更**高质量的真实图像**，比如生成更真实的手和人脸：

![](https://proxy-prod.omnivore-image-cache.app/1232x0,sdORGu_Q6ET975EzoaJ-9AuHh0PeQc3X0szyP8on3giQ/https://picx.zhimg.com/50/v2-3fe9fe8ea89dde0320598442bb031248_720w.jpg?source=1def8aca)

为了提升生成图像质量，Google还专门训练了一个基于人类喜好的图像美学评分模型，类似LAION之前训练的[美学评分模型](https://link.zhihu.com/?target=https%3A//laion.ai/blog/laion-aesthetics/)。在Imagen 2的训练过程引入图像的美学评分作为条件，让模型能够学习到区分图像的美学质量。在生成图像时，就可以给一个比较高的美学评分作为条件来生成高质量图像。看起来这个方案是参考了之前SDXL所提出的micro condition策略。

![](https://proxy-prod.omnivore-image-cache.app/1232x0,sBc1YOdmUZxwPHacblmtk9Z5Q1-1IS9QCcOFK5T7ZthQ/https://pic1.zhimg.com/50/v2-9b5908d464e0632cd6b9c95455878475_720w.jpg?source=1def8aca)

Imagen 2生成的Flower图像，从左到右图像美学评分越来越高

Imagen 2的第二个亮点是**生成的图像更符合用户的prompt**，这个主要通过对训练数据集图像的caption进行增强，看起来是借鉴DALL-E 3那样来合成高质量caption。

![](https://proxy-prod.omnivore-image-cache.app/1200x0,s6YDUxcbTbx2fiMNCBX_ec8AznfOLciUbNuoj2ymLd6M/https://picx.zhimg.com/50/v2-bd08b600779bc8ca2dc837cbf95b3d98_720w.jpg?source=1def8aca)

Prompt: &quot;Soft purl the streams, the birds renew their notes, And through the air their mingled music floats.&quot; (A Hymn to the Evening by Phillis Wheatley)

![](https://proxy-prod.omnivore-image-cache.app/1200x0,sNGJ8YHV-szDm7eJdGiHcWlXZKzBnj4pXMsrlXpMpg5M/https://pic1.zhimg.com/50/v2-08e00306b28a9f9f0f74d8ea3f40982e_720w.jpg?source=1def8aca)

Prompt: &quot;Consider the subtleness of the sea; how its most dreaded creatures glide under water, unapparent for the most part, and treacherously hidden beneath the loveliest tints of azure.&quot; (Moby-Dick by Herman Melville)

![](https://proxy-prod.omnivore-image-cache.app/1200x0,s84fy5U26B7KuYuLg6BUemyApR5ln7sU6rkMofVeYSkg/https://picx.zhimg.com/50/v2-7273621fb1507bf7ddebd0fa654df61c_720w.jpg?source=1def8aca)

Prompt: &quot;The robin flew from his swinging spray of ivy on to the top of the wall and he openedhis beak and sang a loud, lovely trill, merely to show off. Nothing in the world is quite asadorably lovely as a robin when he shows off - and they are nearly always doing it.&quot;

Imagen 2也可以像DALL-E 3一样写文字，估计也是采用了T5-XXL作为text encoder，或者用了更好更大的text encoder。

![](https://proxy-prod.omnivore-image-cache.app/2000x0,sRJS5_s6Lrm6IVn9VCL_dMcsp3ve87umas6HqDQDdXPk/https://pic1.zhimg.com/50/v2-c0de20e3ef54672fd67c2680cc1c30ea_720w.jpg?source=1def8aca)

---

从Imagen 2公开信息来看，Imagen 2基本上是借鉴目前业界成熟的方案来升级模型。而Imagen 2所说的两个模型特色，其实是目前所有文生图模型都在努力提升的点。有人根据Imagen 2所给出的例子用其它模型比如Midjourney和DALL-E 3进行测试并对比：

[](https://www.zhihu.com/question/634751834/answer/3326571192)

从直观上看，我只能说Imagen 2的优势并不明显，至少从官方选的这几个例子上看。而且也没有像DALL-E 3发布的时给出的例子让人震撼。

Imagen 2除了主功能，还额外发布了两个功能，一个是可以使用一些参考的风格图像来引导模型生成同风格的图像：

![](https://proxy-prod.omnivore-image-cache.app/1232x0,s5PIoolN1Epph3wI1SEcQQF-XjTPajYGSUu_XmSP8jLQ/https://picx.zhimg.com/50/v2-0f464dd898fb37b0fe82209ab33b7f6c_720w.jpg?source=1def8aca)

然后是图像的inpainting和outpainting功能：

![](https://proxy-prod.omnivore-image-cache.app/0x0,sOIcKCMJKKqXXAe2WY2MIh06cVZPCqS8Arp4NFDYpqeo/data:image/svg+xml;utf8,%3Csvg%20xmlns%3D%22http%3A%2F%2Fwww.w3.org%2F2000%2Fsvg%22%20width%3D%221232%22%20height%3D%22693%22%3E%3C%2Fsvg%3E)![动图封面](https://proxy-prod.omnivore-image-cache.app/1232x0,sDCA-oHQskldT8Bh_NjwW-4UQABXqvBWPbzs7s9vi5FY/https://pic1.zhimg.com/50/v2-3619164d1c2aefdecf85a17fa178f650_720w.jpg?source=1def8aca)

![](https://proxy-prod.omnivore-image-cache.app/0x0,sOIcKCMJKKqXXAe2WY2MIh06cVZPCqS8Arp4NFDYpqeo/data:image/svg+xml;utf8,%3Csvg%20xmlns%3D%22http%3A%2F%2Fwww.w3.org%2F2000%2Fsvg%22%20width%3D%221232%22%20height%3D%22693%22%3E%3C%2Fsvg%3E)![动图封面](https://proxy-prod.omnivore-image-cache.app/1232x0,sHgz-Jk1m32lK2LDxMqwseNFfjsqhZjFODuYw3x6zxBs/https://picx.zhimg.com/50/v2-827d73874e6ba6ff79489ef354569455_720w.jpg?source=1def8aca)

这个两个功能比较中规中矩吧（风格迁移和图像inpainting目前SD和Midjourney都支持），只能说是锦上添花，并不能成为核心卖点。

Imagen 2到底能不能碾压DALL-E 3，还需要等待Imagen 2能测试后做更进一步的对比。

展开阅读全文​

​赞同 61​​20 条评论​收藏​喜欢

[![wgwang](https://proxy-prod.omnivore-image-cache.app/0x0,scfr7P2KUErHIyQhUaeH0S5xMMDq_75hb0uQ3vyFJmE8/https://picx.zhimg.com/db71edd8da1c9095946a0814daa0cb20_l.jpg?source=1def8aca)](https://www.zhihu.com/people/wgwang)

[wgwang](https://www.zhihu.com/people/wgwang)

​

隘(AI)门 • 隘内言微义小，门外海阔天高

​ 关注

分几个部分来说吧

## 1\. 概述

Google Imagen 2是一种先进的文本到图像的AI技术，它可以根据自然语言的输入，生成高质量、高分辨率、逼真的图像。Google Imagen 2是目前最先进的文本到图像的AI技术之一，它在多个方面超越了之前的技术，例如：图像质量、文本渲染、多语言支持、视觉问答等。Imagen 2的图像质量达到了前所未有的水平，它可以生成高达1024×1024像素的高分辨率图像，具有很高的逼真度和细节度。Imagen 2的文本渲染能力也很强，它可以根据文本输入，生成包含正确文字的图像，例如：公司或产品的logo，或者在图像上添加文字。Imagen 2还支持多种语言的文本输入，除了英语，还包括中文、日语、韩语、印地语、西班牙语和葡萄牙语。Imagen 2的视觉问答功能也很有趣，它可以根据图像生成描述性的长文本，或者回答关于图像细节的问题。其应用场景也很多，比如创意设计、品牌营销、教育娱乐等

![](https://proxy-prod.omnivore-image-cache.app/1200x1200,sVZ51dTECwn0yip7ozFjy_86szVoFF9LoltGDMQ7yvMA/https://pica.zhimg.com/50/v2-630f0875256c87c66d5e64e4b8e7211d_720w.jpg?source=1def8aca)

Prompt: Small canvas oil painting of an orange on a chopping board. Light is passing through orange segments, casting an orange light across part of the chopping board. There is a blue and white cloth in the background. Caustics, bounce light, expressive brush strokesImproved ima

## 2\. 技术

Google Imagen 2的技术架构主要包括两个部分：一个大型的Transformer语言模型，用于理解语言输入，和一个基于扩散模型的图像生成模型，用于创建图像输出。深入学习技术，请参阅下面这些论文：

[](https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s/3bOFfODR7rpnyzrpocHlfQ)

### 2.1 语言模型

据说是T5-XXL，有24层的编码器，每层有1024个隐藏单元，总共有30亿个参数。Imagen 2将文本输入通过T5-XXL编码器，得到一个256维的文本嵌入向量，作为图像生成模型的输入，用于理解文本输入；扩散模型是一种基于马尔可夫链的概率生成模型，它可以从高维的数据分布中采样出高质量的样本，例如：图像、音频、视频等。

### 2.2 扩散模型

扩散模型的基本思想是，将一个目标数据（例如：一张图像）逐渐加入噪声，直到变成一个随机的数据（例如：一张白噪声图像），然后再逐步去除噪声，恢复成目标数据。扩散模型的训练过程是学习如何在每一步加入或去除合适的噪声，使得最终的样本与目标数据的分布尽可能接近。Imagen 2使用了一个基于U-Net的扩散模型，它有12层的编码器和解码器，每层有256个隐藏单元，总共有1.5亿个参数。Imagen 2将文本嵌入向量和一个随机的图像作为扩散模型的输入，然后通过反向的扩散过程，生成一个与文本匹配的图像。

![](https://proxy-prod.omnivore-image-cache.app/1200x0,shJeU__e1_UYED-L5igAT_0pehcX-uwYRz8nNHFqQ0AY/https://pic1.zhimg.com/50/v2-f4c7d197230aad7c0d090ee9fddaff54_720w.jpg?source=1def8aca)

Prompt: “Soft purl the streams, the birds renew their notes, And through the air their mingled music floats.” 

## 3\. Fluid style conditioning

magen 2 基于扩散的技术提供了高度的灵活性，使得控制和调整图像的风格变得更加容易。通过提供参考风格图像与文本提示相结合，我们可以调节 Imagen 2 以生成遵循相同风格的新图像。

![](https://proxy-prod.omnivore-image-cache.app/1232x0,szOGBujijXziiajTXlFLk3aPjY9f14OLmYVadlCOlpF4/https://pic1.zhimg.com/50/v2-57bb28612f0e962fd32f805d4544f93a_720w.jpg?source=1def8aca)

## 4\. 如何使用

Imagen 2是Google Cloud的Vertex AI平台上的一项服务，它于2023年12月正式发布，是Imagen系列的最新版本。

## 5\. 点评

1. “Imagen 2是一种非常强大的AI技术，它可以根据任何文本生成逼真的图像，我用它来为我的网站和社交媒体创建了很多有趣和吸引人的图像，效果很好，我很喜欢。”
2. “Imagen 2的文本渲染功能很棒，它可以在图像上生成正确的文字，我用它来制作了一些logo和海报，很方便，也很有创意。”
3. “Imagen 2的多语言支持很有用，它可以根据不同语言的文本生成不同语言的图像，我用它来为我的国际客户提供了一些定制的图像，他们都很满意。”
4. “Imagen 2的图像质量很高，它可以生成高分辨率的图像，具有很高的逼真度和细节度，我用它来打印了一些图像，效果很好，我很喜欢。”
5. “Imagen 2的视觉问答功能很有趣，它可以根据图像生成描述性的长文本，或者回答关于图像细节的问题，我用它来学习了一些新的知识，也玩了一些有趣的游戏。”
6. “Imagen 2有时候会生成一些重复或者不相关的图像，我希望它能提高图像的多样性和创新性，让我看到更多的惊喜。”
7. “Imagen 2有时候会无法理解一些复杂或者模糊的文本，我希望它能提高文本的理解和处理能力，让我输入更多的内容和细节。”

展开阅读全文​

​赞同 4​​添加评论​收藏​喜欢

---

