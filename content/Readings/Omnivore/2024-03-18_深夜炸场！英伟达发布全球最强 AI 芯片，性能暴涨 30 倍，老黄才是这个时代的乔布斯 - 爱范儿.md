---
id: 63549ebc-e5ad-11ee-943a-df548fadcee3
title: |
  深夜炸场！英伟达发布全球最强 AI 芯片，性能暴涨 30 倍，老黄才是这个时代的乔布斯 | 爱范儿
author: |
  莫崇宇
tags:
  - RSS
date_saved: 2024-03-18 20:58:21
date_published: 2024-03-18 20:58:21
draft: true
---

# 深夜炸场！英伟达发布全球最强 AI 芯片，性能暴涨 30 倍，老黄才是这个时代的乔布斯 | 爱范儿
#Omnivore

[Read on Omnivore](https://omnivore.app/me/ai-30-18e5513a75f)

[Read Original](https://www.ifanr.com/1578539)

date_saved: 2024-03-18 20:58:21

date_published: 2024-03-18 20:58:21

--- 

# Full Content: 

![](https://proxy-prod.omnivore-image-cache.app/0x0,s9qBAcPd7hXmHv_UUKkfHJwwBYr8iGAmJgj_dtQwa3D4/https://s3.ifanr.com/wp-content/uploads/2024/03/7-10.jpg!720) 

刚刚，英伟达发布了全球最强的 AI 芯片。

> 生成式 AI 已经达到了引爆点。

两个小时的 GTC 2024 大会，更像一场大型演唱会，英伟达高级科学家 Jim Fan 调侃「黄仁勋是新的泰勒·斯威夫特」。

目前英伟达黄仁勋在 AI 行业的地位，大抵就是如此。

![](https://proxy-prod.omnivore-image-cache.app/1280x960,s3dzmpOXA9v34SCSp51Tk7uYg81NiZaoXqmXsH85hSkw/https://s3.ifanr.com/wp-content/uploads/2024/03/GTC11.jpg!720)

去年黄仁勋喊出 AI 的「iPhone 时刻」已经到来，让我们看到了日常生活如何被 AI 改写，而今天则展示了这个改变的速度正被疯狂加快。

在过去 10 年里，英伟达将 AI 推进了大约一百万倍，远超摩尔定律，或者说英伟达正在书写自己的迭代定律。从芯片算力到 AI 落地，从汽车制造到医疗物流，英伟达在自身进步的同时，也推动了各行各业发展。

摩尔定律已死，可英伟达让新的摩尔定律诞生了。

![](https://proxy-prod.omnivore-image-cache.app/1280x722,sYRw1TLOj7RoXL3X3oIlaSVQdAh9Z-T1Ym_lnRHzTyZU/https://s3.ifanr.com/wp-content/uploads/2024/03/GTC8.jpg!720)

除了电脑显卡，英伟达在平时很少会被我们感知，但身边许多产品的技术进步又总离不开它们，看完这篇 GTC 2024 的首发总结，或许你能对 AIGC 的浪潮有更明显的感知

昨晚 OpenAI CEO Sam Altman 在 X 发的一条推文或许正是时代的注脚：

> This is the most interesting year in human history, except for all future years  
> 这是人类历史上最有趣的一年，但会是未来最无趣的一年。

> 这是当今世界上生产中最先进的 GPU。

![](https://proxy-prod.omnivore-image-cache.app/739x421,s6ndF6VfP9Cd09iMADJaXEU1ZM5xFBOg3Ll8JcDAt1jE/https://s3.ifanr.com/wp-content/uploads/2024/03/GTC4.jpg!720)

发布会的主角，是「Blackwell B200」AI 芯片，黄仁勋称这颗芯片的名字来自数学家、博弈论家、概率论家 David Blackwell。

基于台积电的 4NP 工艺，Blackwell 架构下的计算芯片拥有 1040 亿个晶体管，比起上一代 GH100 GPU 上的 800 亿个晶体管，实现了又一次突破。

![](https://proxy-prod.omnivore-image-cache.app/739x421,sG8TbUREdj1_dpSBXa4LzOeQ03Dswm9xutQ1TzNWI-Ng/https://s3.ifanr.com/wp-content/uploads/2024/03/GTC7.jpg!720)

Blackwell B200 并不是传统意义上的单一 GPU，它由两个 Blackwell GPU + 一个 Grace CPU 芯片组合而成，并通过 10 TB/s NV-HBI（Nvidia 高带宽接口）连接，以确保每一颗芯片能够单独运行。

![](https://proxy-prod.omnivore-image-cache.app/1379x816,sX1Z8sHg44FCPpc33QcWMrKU-yId6fr77brIzlM_Xg74/https://s3.ifanr.com/wp-content/uploads/2024/03/GTC5.jpg!720)

因此，B200 实际上拥有 2080 亿个晶体管，能够提供高达 20 petaflops 的 FP4 算力，其中的两个 GPU 与单个 Grace CPU 相结合的 GB200，可以为 LLM（大语言模型）的推理提升 30 倍的工作效率。

GB200 的性能也将大幅提升，在具有 1750 亿个参数的 GPT-3 LLM 基准测试中，GB200 的性能是 H100 的 7 倍，而它的训练速度是 H100 的 4 倍。

![](https://proxy-prod.omnivore-image-cache.app/739x421,sZ1ufp0aPNXc_0dkdSJGXcUt7caVXN42LJ9ny58mPqUU/https://s3.ifanr.com/wp-content/uploads/2024/03/GTC3.jpg!720)

更重要的是，与 H100 相比，它可将成本和能耗降低 25 倍。

此前，英伟达的 AI 处理器 H100 尽管十分畅销，然而每块 H100 的峰值功耗高达 700 瓦，超过了普通美国家庭的平均功耗，专家预测，随着大量 H100 被部署，其总功耗将与一座美国大城市不相上下，甚至超过一些欧洲小国。

![](https://proxy-prod.omnivore-image-cache.app/800x548,syjIsLJ-Owb1ag4slxNW3a5X7Hdbd-Cd-Crsv56dco74/https://s3.ifanr.com/wp-content/uploads/2024/03/GTC9.jpg!720)

黄仁勋说，训练一个 1.8 万亿参数模型之前需要 8000 个 Hopper GPU 和 15 兆瓦的功率，如今 2000 个 Blackwell GPU 就可以做到这一点，而功耗仅为 4 兆瓦。

Blackwell B200 GPU 的彪悍性能，从能耗方面也能完美体现。采用了最新 NVLink 互联技术的 B200，支持相同的 8GPU 架构和 400GbE 网络交换机，在性能大幅提升的同时，可以做到与上一代 H100/H200 相同的峰值能耗（700W）。

![](https://proxy-prod.omnivore-image-cache.app/1865x975,sKGZJEswv_kHbfncx3_lCCGfPIOatf3cIJvArFF2hxTA/https://s3.ifanr.com/wp-content/uploads/2024/03/GTC13.jpg!720)

另外一点值得注意的是 FP4 算力。黄仁勋表示在过去的 8 年里，AI 算力提升了一千倍，其中最为关键的改进是第二代 Transformer 引擎，通过 FP4 算力使计算、带宽和模型大小得到了显著提升。

相较于 AI 常用的 FP8 算力，B200 的 2 个计算芯片让其性能达到了 H100 的 2.5 倍，每个 Blackwell 架构下的芯片算力要比上代 Hopper 芯片高出了 25%。

英伟达高级科学家 Jim Fan 称全新的 Blackwell B200 GPU 是「新的性能野兽。」

![](https://proxy-prod.omnivore-image-cache.app/587x594,scmGgJuutejS_pmGCJ_FP0y6_gDaJwUdfk3Xvfa3wK6U/https://s3.ifanr.com/wp-content/uploads/2024/03/GTC16.jpg!720)

B200 在单个架构内的计算能力超过 1 Exaflop，黄仁勋交付给 OpenAI 的第一台 DGX 性能是 0.17 Petaflops，GPT-4-1.8T 参数可以在 2000 台 Blackwell 上 90 天内完成训练。

毫不夸张地说，新的摩尔定律诞生了。

由于 Blackwell 有多种不同的变体可用，因此英伟达还提供了完整服务器节点的规格，主要有三个选项。

首先是最大、最强的 GB200 NVL72 系统，配置了 18 个 1U 服务器，每个服务器配置两个 GB200 超级芯片。该系统内提供了 72 片 B200 GPU，具有 1440Peta FLOPSde FP4 AI 推理性能，和 720 Peta FLOPS 的 FP8 AI 训练性能，并将采取液冷方案，一台 NVL72 可处理 27 万亿个参数模型（GPT-4 的最大参数不超过 1.7 万亿参数）。

![](https://proxy-prod.omnivore-image-cache.app/1865x1012,soOg5zBffDrYJOkHQmjKqK1UbVp0i_grIOB7ISnTFlkg/https://s3.ifanr.com/wp-content/uploads/2024/03/GTC12.jpg!720)

另外一个规格是 HGX B200，它基于在单个服务器节点中使用八个 B200 GPU 和一个 x86 CPU，每个 B200 GPU 可配置高达 1000W，并且 GPU 提供高达 18 petaflops 的 FP4 吞吐量，比 GB200 中的 GPU 慢 10%。

![](https://proxy-prod.omnivore-image-cache.app/800x450,s8hxZYQJPvnDI5QCuJt5LXyEUn--rnu_mctNn-4YtpBA/https://s3.ifanr.com/wp-content/uploads/2024/03/GTC14.jpg!720)

最后，英伟达还将推出 HGX B100，其大致规格与 HGX B200 相同，配备 x86 CPU 和 8 个 B100 GPU，只不过会与现有 HGX H100 基础设施直接兼容，并允许最快速地部署 Blackwell GPU，每个 GPU 的 TDP 限制为 700W。

![](https://proxy-prod.omnivore-image-cache.app/1184x566,s-591TJTbl-4_Rk-0kLeC_b3bRwzJNiOFfeyzLZdQTuQ/https://s3.ifanr.com/wp-content/uploads/2024/03/GTC2.jpg!720)

在此之前，英伟达通过 H100、H200 等 AI 芯片使其成为了一家价值数万亿美元的公司，并超越了亚马逊等头部公司，而今天发布的全新 Blackwell B200 GPU 和 GB200「超级芯片」很有可能会扩大其领先地位，甚至有望超越苹果。

### 软件定义一切的时代正在到来

2012 年，一小群研究人员发布了一个名为 AlexNet 的突破性图像识别系统，当时它在猫狗分类任务上的表现远超过了以往的方法，这使得它成为了深度学习和卷积神经网络（CNN）在图像识别领域潜力的一个标志性证明。

也正是借此看到 AI 的机遇后，黄仁勋决定全力押注 AI。有趣的是，以前是识别生成的图片到生成文字，而现在却是通过文字来生成图片。

![](https://proxy-prod.omnivore-image-cache.app/1264x712,sUWJvGSwCa05TSwsqQJIgkcEa0ASWmaJRVnLZs4JNHdY/https://s3.ifanr.com/wp-content/uploads/2024/03/1-7.jpg!720)

那么当生成式 AI 浪潮到来，我们能利用它做些什么呢？黄仁勋给出了一些标准答案。

传统的天气模型结合英伟达的气象模型 Cordiff，能够实现探索数百公里甚至数千公里面积范围的预报，提供诸如台风影响的侵袭范围，从而最大程度降低财产的损失。未来 Cordiff 也将向更多国家和地区开放。

生成式 AI 不仅可以通过数字化能力理解图像和音频，同理，也能凭借庞大的计算力扫描数十亿种化合物，从而筛选出新药。

![](https://proxy-prod.omnivore-image-cache.app/1264x712,sd5CqyKUqXVr96Gpa9TNAwb8BixXhmHzWLMZzAeRGjnI/https://s3.ifanr.com/wp-content/uploads/2024/03/2-12.jpg!720)

作为一家 AI 军火商，黄仁勋还介绍了专门辅助开发 AI 芯片的 NiMS 系统。在未来，你甚至有机会组建一个 AI 超级团队，将任务拆解为一连串子任务后，就能让不同的 AI 完成检索、优化软件等任务。

> 未来的设施、仓库、工厂建筑将由软件定义。

无论是人形机器人、自动驾驶的汽车、操纵手臂，这些自主机器人都需要软件层面的操作系统。例如，通过 AI 与 Omniverse 的结合，英伟达打造了一个占地 10 万平米的机器人仓库。

在这个物理精确的模拟环境中，100 个安装在天花板上的摄像机使用英伟达 Metropolis 软件和自动移动机器人（AMR）的路线规划功能，实时映射了仓库的所有活动。

![](https://proxy-prod.omnivore-image-cache.app/1264x712,sBKQ2I94Ld5_n8u4S5M9kJc3CTxR3UXkJPcAd_cdnZbs/https://s3.ifanr.com/wp-content/uploads/2024/03/3-13.jpg!720)

这些模拟还包括对 AI 代理的软件循环测试，以评估和优化系统对现实世界不可预测性的适应能力。

在模拟的一个场景中，AMR 在前往取货盘的途中遇到了一起事故，阻碍了其预定路线。Nvidia Metropolis 随即便能更新并发送了实时占用地图给控制系统，后者计算出了新的最优路径。

仓库操作员还可以通过自然语言向视觉模型提问，模型能够理解细节和活动，并提供即时反馈以改善运营效率。

![](https://proxy-prod.omnivore-image-cache.app/1280x779,s_9tVeLcuWIXm8XvkoAT_sx-0hZwck3n72IYZXETBipE/https://s3.ifanr.com/wp-content/uploads/2024/03/4-8.jpg!720)

值得一提的是，本次发布会还出现了苹果 Vision Pro 的身影。企业可以轻松地通过 Omniverse Cloud 将 3D 应用的交互式通用场景描述（OpenUSD）实时串流到 Vision Pro，帮助用户探索前所未有的虚拟世界。

![](https://proxy-prod.omnivore-image-cache.app/765x388,sfONo6SdlJ5Pve7zSTTGahjReSyoLH-ar6jNiE10N-jc/https://s3.ifanr.com/wp-content/uploads/2024/03/5-9.png!720)

发布会的结尾则是熟悉的机器人环节，正如黄仁勋所说，当他张开双手，与其他人形机器人站在一起的那一刻，此时「计算机图形学，物理学，人工智能的交叉点，这一切都在这一刻开始」。

![](https://proxy-prod.omnivore-image-cache.app/1264x712,sRSQbXHBgPadI3qNbEWYT7oy03GtJ_bDGYp-MAyjMX60/https://s3.ifanr.com/wp-content/uploads/2024/03/6-13.jpg!720)

▲ 小彩蛋

十年前 GTC，黄仁勋首次强调机器学习的重要性，在许多人还在把英伟达当作「游戏显卡」的制造商时，它们已经走在了 AI 变革的最前沿。

在被称为 AI 应用元年的 2024，英伟达早就用 AI 软硬件在众多领域为各行各业赋能：大语言模型、对话式 AI、边缘计算、大数据、自动驾驶、仿生机器人……

> 药物发现不是我们的专长，计算才是；制造汽车不是我们的专长，造汽车所需要的 AI 计算机才是。坦率地说，一家公司很难擅长所有这些事情，但我们非常擅长其中的人工智能计算部分。

相较于单一行业的佼佼者，英伟达更像是一个「幕后大佬」，只要谈到 AI，英伟达一定是绕不开的话题。

![](https://proxy-prod.omnivore-image-cache.app/1264x712,sSvulvIKRNUI5SAsj_oV6HduWGRHgKSqx3RzGSLABC8s/https://s3.ifanr.com/wp-content/uploads/2024/03/7-10.jpg!720)

就像老黄说的，英伟达已然是一家平台公司。

正是当年的超前部署、历史发展的大势所趋，让英伟达能在 AI 时代的开端，能够占据 AI 芯片市场 70% 以上的销售额，公司估值也在不久前超过 2 万亿美元。

或许这也是苹果纠结多年后放弃造车、并大力投入生成式 AI 的理由，无论是经济效益还是技术趋势，都太值得豪赌一把了。

在我们还在质疑「AI」有什么用的当下，英伟达用行动证明，AI 已经成为了新时代不可或缺的一部分。

作者：李超凡、肖凡博、莫崇宇

1 个人收藏

* ![头像](https://proxy-prod.omnivore-image-cache.app/0x0,sLJPqtIafREulX3s53gnHrXE4FAOtW2z5eUhHB8nipUk/https://media.ifanrusercontent.com/tavatar/3c/f5/3cf5053cea28261807b863458202c54763c67046.png)

---

