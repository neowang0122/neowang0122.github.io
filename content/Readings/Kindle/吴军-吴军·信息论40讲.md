---
dg-publish: true
kindle-sync:
  bookId: "33293"
  title: 吴军·信息论40讲
  author: 吴军
  highlightsCount: 374
---
# 吴军·信息论40讲
## Metadata
* Author: [[吴军]]

## Highlights
而信息论就是这半个世纪以来，人类对抗不确定性，最重要和有效的方法论。 — location: [7]() ^ref-3719

---
20 世纪初概率论和统计学的成熟，使人们得以把握随机性。在此基础上，1948 年，香农博士找到了不确定性和信息的关系，从此为人类找到了面对不确定性世界时的方法论，也就是利用信息消除不确定性。可以说，这是随后的半个多世纪里，特别是今天，最重要的方法论。 — location: [35]() ^ref-13476

---
世界上的知识，可以分为道和术两个层面，我们这门课讲的是道的层面的知识，它不会讲述任何具体的方法，比如信息的采集、处理或者传输的理论细节。这样，我们就能够把重点放在讲述用信息论指导做事的方法上，以便让我们能够在不断变化，而且充满不确定性的世界里把握住机会，立于不败之地。 — location: [52]() ^ref-46593

---
一门通俗信息论课程的想法——不讲细节，特别是理论的细节，只讲原理和应用，以便听众能够熟悉我们这个时代最适合的思维方式。 — location: [51]() ^ref-848

---
一信息产生：在面对大量信息时，排除噪音，提取利用有效信息，科学做决策的能力； — location: [59]() ^ref-34757

---
信息传播：向外界传递信息时，平衡分配有限资源，增加沟通带宽，放大影响力的能力； — location: [60]() ^ref-52753

---
信息应用：看懂信息应用的逻辑和通信发展的趋势，提前抓住新机遇的能力。 — location: [61]() ^ref-47614

---
一个人的思维方式和做事方法常常决定了一个人能够走多远，而在历史的任何时期，都有最适合时代的方法论。如今，面对不确定性和非连续变化，信息论所提供的方法，能成为解决今天各种困惑的工具。 世界上任何一个探索者都需要清楚三件事：我们现在的位置，我们的目标，以及通向目标的道路。 我们知道哲学是一门生活的艺术，它帮助我们认清自己，它回答了第一个问题。 至于每一个人的目标，我相信大家比我更清楚。 而第三件事其实是方法论或者说是理性的工具，也正是我想要给你的，相信大家有了信息论这个工具，就能更好地应对当下充满不确定性的世界，达成自己的目标。 清楚了这三件事，我们便不再需要焦虑，内心就得到安宁。 — location: [64]() ^ref-45290

---
二者皆 50%的可能性最让人头疼。而公众都知道的信息，其实是没有信息量的。 — location: [141]() ^ref-48524

---
用很少的信息驱动很大的能量，这也是今天交付给大家的第三个知识点。而这也是信息非常重要的原因。 — location: [155]() ^ref-62741

---
1.信息很重要，甚至比钱更重要，它能四两拨千斤。而信息作用的大小和信息量有关。 2.信息量和不确定性有关，大家都知道的事，就没有什么信息量了。 3.对一个未知系统（黑盒子）所作出的估计和真实情况的偏离，就是信息的损失，偏离越多损失越大。 此外，我们还提到了信息论的一个原则，不要把鸡蛋放在一个篮子中，这样可以避免因为信息缺失，而导致灾难性结果。 — location: [157]() ^ref-56743

---
“能量是世界固有的，是它诞生之初就存在的，那么信息从哪里来？” 信息和能量一样，都是宇宙本身固有的特性。 — location: [182]() ^ref-49420

---
从信息论上说，信息的可靠性就叫做置信度， — location: [186]() ^ref-26070

---
有时候有价值的论文并不需要啰里啰唆地写很长，它们里面的信息量很重要，正如我们上一讲讲到的，对于一件过去大家不知道的事情，现在知道了，信息量就大，对于一件大家基本上了解的事情，即使你的文章写得再长，信息量都有限。 — location: [200]() ^ref-4794

---
我过去多次讲，提出问题比解决问题更重要，因为提出问题的人，开创了一个重要的却是完全未知的领域，回答问题并且给出最初解答的人，由于通常只是在某种认识阶段上对未知的领域提供一些有限的信息，因此贡献有限，被认可的程度不高。 — location: [203]() ^ref-35982

---
第一，信息是宇宙本身固有的属性；第二，在一个领域的贡献大小，不在于你提供了多少材料，而在于提供了多少信息量。 — location: [211]() ^ref-17007

---
怎样利用信息论原理，做到信息传播的高效率，是我们这门课要讲的重要内容。 我有时会帮助一些做演讲的人做一些正式讲演前的指导，我给大家最多的建议就是，不要啰里啰唆地唠叨很长时间，要精简，要保证对方听懂自己最核心的想法，这就够了。 — location: [221]() ^ref-2808

---
大数据思维的一些例子， — location: [264]() ^ref-58828

---
第一类是解决人工智能问题，把那些过去看似需要人脑推理的问题，变成今天基于大数据的计算问题。 第二类是利用大数据，进行精准的服务。 第三类是动态调整我们做事情的策略。 第四类是发现原来不知道的规律。 — location: [266]() ^ref-43729

---
最成功的四类应用。 第一类是解决人工智能问题，把那些过去看似需要人脑推理的问题，变成今天基于大数据的计算问题。 第二类是利用大数据，进行精准的服务。 第三类是动态调整我们做事情的策略。 第四类是发现原来不知道的规律。 — location: [265]() ^ref-51648

---
世界上利用大数据解决的第一个智能型的问题是语音识别，接下来是机器翻译。 — location: [271]() ^ref-20888

---
到了 70 年代，康奈尔大学著名的信息论专家贾里尼克来到 IBM，负责该公司的语音识别项目。贾里尼克是一位天才，他从博士毕业到成为讲席教授，教科书的作者，也就是十年时间。 — location: [275]() ^ref-13029

---
他得以用信息论的思维方式来看待语音识别问题。他认为语音识别是一个通信问题。 — location: [282]() ^ref-23136

---
贾里尼克就用通信的编解码模型，以及有噪音的信道传输模型，构建了语 音识别的模型。但是这些模型里面有很多参数需要计算出来，这就要用到大量的数据，于是，贾里尼克就把上述问题又变成了数据处理的问题了。 — location: [286]() ^ref-25522

---
贾里尼克思想的本质，是利用数据（信息）消除不确定性，这就是香农信息论的本质，也是大数据思维的科学基础。 — location: [294]() ^ref-17251

---
今天给大家举了四类大数据思维应用在商业上的成功案例： 第一类是解决人工智能问题，是利用数据（信息）消除不确定性，这是香农信息论的本质，也是大数据思维的科学基础。 第二类是利用大数据进行精准服务，从中你可以看出一个商业趋势：公司从重研究方法到重数据收集的转变。 第三类是动态调整做事策略，足够多的数据可以帮助我们动态匹配最佳结果。 最后一类是利用大数据发现未知规律，这背后涉及互信息的理论，是我们后面课程的重点内容。 — location: [332]() ^ref-16183

---
充满不确定性的黑盒子就叫做“信息源”，它里面的不确定性叫做“信息熵”，而“信息”就是用来消除这些不确定性的（信息熵），所以搞清楚黑盒子里是怎么一回事，需要的“信息量”就等于黑盒子里的“信息熵”。 — location: [372]() ^ref-44531

---
“比特”是这样定义的：如果一个黑盒子中有 A 和 B 两种可能性，它们出现的概率相同，那么要搞清楚到底是 A 还是 B，所需要的信息量就是一比特。如果我们对这个黑盒子有一点知识，知道 A 的概率比 B 大，那么解密它们所需要的信息就不到一比特。 — location: [359]() ^ref-41941

---
要确定四选一问题的答案需要 2 比特信息， — location: [371]() ^ref-65207

---
一个系统中的状态数量，也就是可能性，越多，不确定性就越大；在状态数量保持不变时，如果各个状态的可能性相同，不确定性就很大；相反，如果个别状态容易发生，大部分状态都不可能发生，不确定性就小。 — location: [377]() ^ref-35477

---
永远不要听那些正确率总是 50%的专家的建议，因为那相当于什么都没说，没有提供能够减少“信息熵”的“信息量”。 — location: [392]() ^ref-21325

---
就是开赌局的从来不是拿自家的钱和你对赌，而是让你们彼此互相赌，他通过变相多收费盈利。 很多人会讲，我不参加赌局，不会被开赌局的人赚走钱。其实上述这类赌局在金融市场更多。 — location: [409]() ^ref-40207

---
要点总结◆──── 1.香农告诉大家，信息可以衡量，但不是用重要性，而是用信息量，单位是“比特”。 2.你可以把一个充满可能性的系统视为一个“信息源”，它里面的不确定性叫做“信息熵”，而“信息”就是用来消除这些不确定性的，所以搞清楚黑盒子里是怎么一回事，需要的“信息量”就等于黑盒子里的“信息熵”。 3.很多复杂交易背后其实都用到了信息的可度量性。 4.信息量的大小不在于长短，而在于开创多少新知。 — location: [426]() ^ref-19484

---
信息编码的复杂度通常和要传播的信息种类数量有关。早期人类了解和需要传播的信息是很少的，因此 — location: [449]() ^ref-5479

---
各种编码系统在数学上是等价的，我们可以为人类找一个自己方便使用的，也可以为计算机找一个它方便使用的。 但是要说明的是，由于它们是等价的，在一个编码系统中解决不了的问题，换一个系统同样解决不了。 — location: [483]() ^ref-15102

---
编码长度 ≥ 信息熵（信息量）/ 每一个码的信息量。 香农对此作出了严格的数学证明，他同时还证明，只要编码设计得足够巧妙，上面的等号是成立的，这就是著名的香农第一定律。 — location: [489]() ^ref-21177

---
1.我通过讲人类创造数字和文字语言的过程，告诉大家，其实它们都是人类用来消除信息不确定性的编码手段。各种编码系统，其实都是在编码复杂性和编码长度之间作平衡，它们在数学上是等价的； — location: [514]() ^ref-13453

---
2.由于它们是等价的，所以，在一个编码系统中解决不了的问题，换一个系统同样解决不了； 3.香农第一定律告诉我们，只要编码设计得足够巧妙，就可以找到最短编码。 — location: [516]() ^ref-35236

---
信息编码的第一个基本原则：“易识别”，应用在我们个人沟通中，也是如此。 — location: [544]() ^ref-34690

---
第二个信息编码的原则：有效性。如何组合信息，保证它高效传递，还能不违背第一条“易辨识”的原则。 — location: [560]() ^ref-28890

---
64 选 1 的题目，那么需要的信息量就是 log64，也就是 6 比特。 — location: [568]() ^ref-9253

---
说明：将一个十进制数除以二，得到的商再除以二，以此类推，直到商等于一或零时为止，然后依照倒序取除得的余数，即换算为二进制数的结果。比如32除以2，商是16，余数是0，然后再用商16除以2，得到余数0，以此类推，得到6个余数，再倒序排列，就是100000。要点是：除二取余，倒序排列。 — location: [570]() ^ref-36786

---
有效编码的思想在今天 IT 的产品性能比对测试中有直接的用途。我们在第 3 讲讲到大数据思维，其中很重要的一条就是采用大量用户反馈信息决定产品的设计和技术方案。 — location: [590]() ^ref-44861

---
有效的编码，其实就是完成从理论上的上限到现实中解决方案的桥梁。 — location: [587]() ^ref-29689

---
利用用户大数据评判 A、B 方案的好坏， — location: [594]() ^ref-13835

---
将各种不会发生冲突的实验用二进制进行编码，几组实验者，就可以同时进行几十个不同的实验。 — location: [599]() ^ref-27032

---
信息论是不少大学里通信专业研究生的必修课，学的人很多，但是绝大部分人学了以后也就扔一边了，少数人则在工作中刻意使用它，最后就做出了很多别人没有得到的成就。 因此学以致用比多学习更重要。 — location: [604]() ^ref-12935

---
默认 log 函数的底都是 2，也就是二进制 0 或 1 在每一位上的两种可能，需要多少位，就是多少个次方，也就是多少个比特的信息 — location: [621]() ^ref-52715

---
方法二：不等长度编码，如果出现概率高就短一些，概率低就长一些。 — location: [634]() ^ref-31741

---
这样的编码虽然大部分码的长度都超过了5，但是乘以出现概率后，平均码长只有 2，也就是说节省了60%的码长。如果利用这个原理进行数据压缩，可以在不损失任何信息的情况下压缩掉60%。 事实上，这种最短编码方法等于香农第一定律的继续，它最早是由 MIT 的教授哈夫曼发明的，因此也被称为“哈夫曼编码”。 — location: [637]() ^ref-63103

---
关于哈夫曼编码有三个要点值得一提： 1.如果你还记得第 5 讲的香农第一定律，一定知道编码长度是有个理论最小值的，从数学上可以证明哈夫曼的这种编码方法是最优化的。 2.哈夫曼编码从本质上讲，是将最宝贵的资源（最短的编码）给出现概率最大的信息。至于资源如何分配，哈夫曼给出了一个原则，也就是一条信息编码的长度和出现概率的对数成正比。 注：比如在上面的例子中，第一条消息出现的概率为 1/2，我们知道 1/2（以二为底）的对数等于-1，因此它的编码长度就是 1（即码 0）。最后两条消息出现的概率为 1/2^31 次方，取对数后等于-31，因此它们的编码长度就是 31。 — location: [641]() ^ref-47799

---
3.在现实生活中，很多信息的组合，比单独一条信息，其概率分布差异更大，因此对它们使用哈夫曼编码进行信息压缩，压缩比会更高。比如说，在汉语中，如果对汉字的频率进行统计，然后压缩，一篇文章通常能压缩掉 50%以上，但是如果按照词进行频率统计，再用哈夫曼编码压缩，可以压缩掉 70%以上。 — location: [650]() ^ref-25422

---
哈夫曼编码的原理，即通过每一次双倍砸钱（double down），把最多的钱投入到最容易成功的项目上。 — location: [657]() ^ref-43483

---
按照哈夫曼编码的原理，可以先把钱分成几部分逐步投入下去，每一次投资的公司呈指数减少，而金额倍增。具体操作方法如下： 第一轮，选择 100 家公司，每家投入 25 万美元，这样用掉 2500 万美元。 第二轮，假定有 1/3 的公司即 33 家表现较好，每家再投入 75 万美元左右，也用掉 2500 万美元。至于剩下了的 2/3 已经死掉或者不死不活的公司，千万不要救它们，更不要觉得便宜去抄底。 第三轮，假定 1/10 的公司，即 10 家表现较好，每家投入 250 万美元，再用掉 2500 万美元。  第四轮，假定 3%的公司，即 3 家表现较好，每家投入 800 万美元左右，用掉最后的 2500 万美元。 这样通常不会错失上市的那一家，而且还能投中很多被收购的企业。由于大部分资金集中到了最后能够被收购和上市的企业中，占股份的比例较高，这种投资的回报要远远高于前两种， — location: [673]() ^ref-6764

---
这个道理对个人来讲也是适用的。美国有名的私立学校哈克学校的前校长尼克诺夫博士讲，在孩子小时候，要让他们尝试各种兴趣爱好，但是最终他们要在一个点上实现突破，他将这比做用圆规画圆，一方面有一个扎得很深的中心，另一方面有足够广的很浅的覆盖面。 — location: [691]() ^ref-25921

---
今天的华为养了一个拥有几万人的庞大的预研部门，很多人觉得这是有了钱之后嘚瑟浪费，但是你可以把它看成是一个内部的大风投，每一个前期研究，都得到一定的发展机会，而投入的资源并不需要太多，最后能够进入到获得巨大资源攻坚阶段的项目，终究是少数。 — location: [689]() ^ref-47325

---
我在之前《Google 方法论》中介绍 Google 和 Facebook 等公司的管理方法时讲到，它们内部其实是一个大风投，各个项目一开始都有获得资源（主要是人力和财力）的可能性。 但是很快，通常是三个月到半年，类似的项目就要开始整合，资源开始集中到更有希望的项目上去。最后能够变成产品上市的，是少数项目，但是大量的资源投入在其中了。这样既不会失去新的机会，也不会浪费资源。 — location: [685]() ^ref-5040

---
一方面我从来不排斥尝试新东西，这样不会失去机会，我尝试过的各种事情远比外界知道的多，只是绝大部分失败了，我没有继续罢了，大家也就无从知晓了。 但是，另一方面对于花了一些精力，看样子做不成的事情，我是坚决做减法止损，这样可以把最多的资源投入到我擅长的，有兴趣的，可能也是成功率最高的事情上。这算是我对今天内容的总结。 — location: [696]() ^ref-52074

---
而简化的自然过程，就是矢量化的过程。 — location: [723]() ^ref-60614

---
学计算机的人知道，计算机中使用的字体有位图（bitmap）和矢量图两种。位图一经放大就会出现锯齿，而矢量图随便放大，都很清晰。 — location: [725]() ^ref-17547

---
为什么这种特殊的归类过程，我们称之为矢量化呢？因为当我们把杂乱无章的信息投射到两个维度之后，两个维度坐标可以决定平面上的一个矢量。 — location: [734]() ^ref-7452

---
根据应用场景会投射到多个维度中，这样的过程就被称为矢量化。 — location: [738]() ^ref-33859

---
随着罗马的扩张，征服了很多外国土地，吸纳了很多外国人，有些外国的人名和地名就无法表示了，于是罗马人在字母表中加入了 x，代表所有那些无法表示的音和词，这既是英语里包含 x 的单词特别少的原因，也是后来人们用 x 表示未知数的原因。 再后来拉丁文里的 i 被拆成了 i 和 j 两个字母，v 被拆成了 u,v,w 三个字母，最终就形成了今天英语的 26 个字母。 — location: [765]() ^ref-58570

---
在信息论中，一个更有普遍意义的问题就是，矢量化会带来多大的信息损失， — location: [783]() ^ref-5769

---
而在工程中大家要做的事就是，如何平衡便利性和信息上的损失。人在年轻的时候，总是会想两者兼而有之，学习了各种科学知识后，就知道这种事情在理论上是办不到的。 — location: [785]() ^ref-58400

---
在信息论中，我们采用一种叫做冗余度的概念对信息的这种“密集”和“稀疏”程度进行描述。冗余度是这样定义的： （信息的编码长度 - 一条信息的信息量）/ 信息的编码长度 — location: [828]() ^ref-40478

---
除了便于理解，冗余度的第二个好处是，在语言学上它消除了很多歧义性。 — location: [841]() ^ref-28016

---
但是我无论读书，还是学习，都会做类似于写卡片的工作，也就是说，把这一本厚厚的书的内容，变成薄薄的几页纸的东西，那些冗余的信息，就删除掉了。我有时讲，读书要不求甚解。这不是说不读懂，而是说要读出主线，将一些细节过滤掉。真到了需要寻找细节时，大不了回过头来再看看就好了。 — location: [879]() ^ref-14537

---
3.在我们脑子存储信息时，要进行压缩，这样脑子才记得住事情。 — location: [877]() ^ref-23639

---
我们介绍了冗余度带来的三个好处：易理解、消歧义和容错性。 但是信息冗余也带来了问题，一方面它造成信息存储和传输的浪费，另一方面它在有噪音的情况下，可能导致混淆。 — location: [884]() ^ref-3336

---
2.讲东西要有一致性，不要补充有可能和主要思想相矛盾的例子，或者和想法无关的冗余信息。 — location: [876]() ^ref-35185

---
1.讲东西时要通过加入一些看似是废话，但是实际上是从侧面诠释你的想法的句子，帮助对方理解你的意思。比如我常说“换句话说”，“比如说”，“从另一方面讲” 这样的话，这就是利用信息的冗余便于大家理解。 — location: [874]() ^ref-21804

---
在很多时候，我们直接得到一种信息，或者原封不动地保留一条信息并不容易，但是却可以从等价的信息中导出所要的信息。当然，这样倒手一次的操作需要一个桥梁，让原有的信息和等价信息一一对应。在信息科学中，最著名的桥梁就是傅立叶变换了。 傅立叶是十九世纪法国的数学家，他发现任何周期性的函数（信号）都等同于一些三角函数的线性组合。下面这张图，就是周期性函数的样子，也就是说它们的波形都是重复的。 — location: [909]() ^ref-45206

---
但是由于它具有周期性，我们就有可能利用这种周期性来进行信息压缩。而对于这一类波动信号，信息压缩的基本原理大致如下： 1．找到这种周期性信号的等价信息； 2．对等价信息进行压缩； 3．如果要使用原来的信号，通过压缩后的等价信息复原原来的信号。 这里面的关键，是找到等价信息。 — location: [917]() ^ref-6484

---
19 世纪初，法国数学家傅立叶发现所有的周期性信号都可以用频率和振幅不同的正弦函数叠加而成，也就是说周期性信号里面所包含的信息和若干正弦函数的频率、振幅信息完全等价，这种变换被称为傅立叶变换。 如果利用傅立叶变换，可以将 100 年里温度变化的信息用大致 20 根频率和振幅不同的正弦曲线叠加而成。也就是说，100 年里 3 万多个温度样点里的信息，基本上就等价于 20 个频率数据和 20 个振幅数据，这样一来信息就被压缩了近百倍。 — location: [926]() ^ref-51183

---
那么图像又是怎么压缩的呢？它们看上去不像是有周期性振动的波形啊。这其实只是我们在宏观上看一幅图，但是如果我们用放大镜把图放得特别大，看到的就是一个个像素，而且相邻的像素之间颜色和灰度的变化会是相对连续的。利用这个特性，人们发明了一种被称为“离散余弦变换”的数学工具，也称为 DCT。 DCT 可以被认为是傅立叶变换的延伸，只不过它没有使用正弦波，而是采用了下面图中所示的 64 个基本灰度模板，任何照片都可以用这些模板组合而成。当然，对于彩色图片需要用带有红绿蓝三原色的彩色模板。这样一幅图片，就变成了一组数字，这些数字是模板中相应的模块的权重。我们经常使用的 JPEG 格式的图像，就是这么生成的。 — location: [937]() ^ref-39976

---
很多时候，一种原始的信息，它们虽然里面有很多冗余成分，但是很难直接压缩掉。但我们可以将它们转化为容易压缩的等价的信息，再进行压缩，然后进行存储和传输。在使用和接收到被压缩的等价信息后，我们先解压，再恢复回原来的信息。 — location: [946]() ^ref-38657

---
很多相同形式的内容放到一起，还能进行更有效的压缩。之前有读者问我，在 Google 上什么东西都能够查到，难道它保存了互联网的所有的内容？这听起来难以置信。其实 Google 还真这么做了，只不过它在向大众服务时，把所有网页中的文字顺序打乱了，它按照每一个关键词在网页中出现的位置重新整理了互联网的内容。这样不仅方便查找，而且能够压缩信息，节省存储空间。这样当你查找时，它不仅能够告诉你，你要找的内容在哪里，还能够根据每一个词出现的位置，恢复出原来的网页展现给你。 — location: [949]() ^ref-51846

---
善用等价信息，是我们这个年代每一个人都必须掌握的工作技巧，这是我们这讲最希望你记住的一个知识点。比如说我们无法看清人体内部的情况，但是我们知道人体内有很多水分，水里有氢原子，它的电子在旋转中形成一个个微小的磁针，我们在人体外面施加磁场，就可以把水分子里的小磁针方向给排顺了，然后我们加入一个能够和水中氢原子共振的脉冲，就可以把人体氢原子振动的信息取出来。由于人体各个部分水的分布不一样，我们通过各个部分氢原子振动的信息，就可以把人的结构画出来。这就是核磁共振的原理。因此核磁共振就是利用了等价信息。 — location: [954]() ^ref-48980

---
就是视频的压缩比要远比图片的高很多。 大家的这个观察是完全正确的，它们通常会相差两个数量级，也就是说 JPEG 图片能压缩 10 倍基本上也看不出损失，而 MPEG 视频能压缩近千倍，肉眼也分辨不出来是压缩过的。 — location: [972]() ^ref-31579

---
视频压缩时，利用了信息的相关性，能够采用所谓的增量编码，而单一一张图片中，不具有太多的相关性可以利用。 所谓利用相关性进行压缩编码，简单来说就是如果两个信息“长得很像”，只要保留一个，对另一个，只要保留它们的差异，然后进行微调就行了。 — location: [976]() ^ref-8409

---
在解码时，我们先解出第一个，然后解出后面的增量，再根据上一个的数值和当前的增量，恢复出一个个原来的信息。 今天对于视频的压缩，用的就是上述原理。我们知道一般的视频一秒钟有 30 帧，高清的是 60 帧，4K 的是 120 帧（甚至 240 帧）。每一帧视频之间的差距其实极小。 我们对第一帧视频（也被称为主帧）进行全画面编码，对于这一帧的压缩比，其实不会太高。 但是对后面每一帧的视频，只要针对它们和上一帧的差异进行编码即可，这样除了主帧外，后面的每一帧的视频，其实编码的长度非常短，视频文件就显得比较小。我们上一讲说到的 Google 搜索所用的索引，其实也用到了前后相关性进行压缩。 — location: [996]() ^ref-36021

---
当我们把信息冗余都挤掉后，编码长度非常短时，容错的性能就会下降。 你过去看影碟可能有这样的体会，当光盘被划了一道，它就经常跳盘，这就是因为视频的压缩是前后相关的，中间坏了一点，很多帧的视频就都看不了了。 为了防止这样编码造成的累积误差，也为了防止中间有一点点信息损失，后面的视频统统打不开，所以，每过若干帧，我们就要重新产生一个主帧，以免错误会传递太远。 — location: [1015]() ^ref-10799

---
信息的前后相关性，其实是信息本身固有的特征。或者说，绝大多数时候，我们这个世界的变化是渐进的，而不是完全随机的。 — location: [1019]() ^ref-30084

---
有些人看不起总在修修补补的做法，觉得缺乏革命性，但是从信息论的角度讲，保守主义的做法成本最低。 — location: [1023]() ^ref-25890

---
保守主义的做事态度，它的好处其实是由我们这个世界渐变的特征决定的。因此，在绝大多数时候，我们不需要推倒重来，只需要对变化进行一些修补就好了。 — location: [1021]() ^ref-39688

---
如果想一次完成巨大的突变，常常会因为牵扯的利益太多，最后总是搁浅，永远改不了，结果反而是不进步。 — location: [1034]() ^ref-54563

---
善用信息前后的相关性，对于后面的信息做增量编码，达到大幅度压缩信息冗余的目的。 其次，我们把这种信息处理的方式，和保守主义的做事方法作了一个对比。所谓保守主义，其实就是坚持总体原则不变，不断作微调，达到渐进改变的目的。这样做，比每一次都推倒重来，或者干脆达不成一致，其实效率反而高，因为我们的世界在绝大多数时候都是渐变的。 — location: [1038]() ^ref-47529

---
香农第一定律。香农指出，任何编码的长度都不会小于信息熵，也就是通常会大于等于信息熵，当然最理想的就是能等于。 如果编码长度太短，小于信息熵，就会出现损失信息的现象。 — location: [1058]() ^ref-62759

---
在压缩信息时，如果想要无损，就不能逾越香农给的这个边界。 也就是说，如果一张图片里面有 10K 的信息，你再怎么压，也不会比它小，否则就会损失信息。 理解了这一点以后，我们就知道无论是语音，还是图像、视频，都有两类的压缩方式，一类就是无损压缩。比如我们昨天说的通过傅里叶变换和离散余弦变换将音频和图像信息变成频率信息，再用类似哈夫曼编码进行压缩，这是不会丢失信息的。 另一类是要丢失一部分信息的，也被称为有损压缩。 — location: [1061]() ^ref-51841

---
事实上我们今天对于音频、图像和视频的压缩，绝大多数情况都是有损的压缩。而有损压缩最关键的是要清楚如何保证因为压缩而丢失的信息不影响我们对信息的理解呢？这就需要平衡压缩比和信息失真度之间的关系。 所谓失真度，其实通俗来说，就是压缩前、压缩后的两串信息的差的平方。 — location: [1067]() ^ref-8903

---
那么到底该压缩多少倍呢？接下来我就要为你介绍，压缩比和失真率平衡原则。在进行信息压缩之前，明确压缩的目的非常重要， — location: [1079]() ^ref-19018

---
世界上很多时候没有最好的技术方案，只能根据场景找到合适的，因此做事的目的性很重要。这是第一个原则。 — location: [1085]() ^ref-52447

---
很多时候，我们都是在接受了某个失真度的情况下（也就是在上图中横着切一刀），然后再去尽可能找到好的压缩比。 世界上很多时候没有最好的技术方案，只能根据场景找到合适的，因此做事的目的性很重要。这是第一个原则。 我们还知道信息的作用是消除不确定性，那么反过来，丢失了一部分信息，一定会增加不确定性。用的信息少，永远不可能做得和原来一样好，这是第二个原则， — location: [1084]() ^ref-59632

---
不久前，有一个 YC 的创业团队，介绍他们如何只利用别人 1/1000 的数据就可以进行深度学习的训练。有些投资人问我是否值得投资。我就对他们讲，丢失了 1000 倍的信息，不要指望做出来的东西和以前一样好。 至于如何平衡数据量和效果的关系，就看矛盾的主要方面在哪一方了。如果说过去没有数据，牺牲掉一点性能，也就罢了。 今天世界上最不缺的就是数据，在最近的三年里，全世界产生的数据，比三年前到有文字以来人类产生的数据的总和还多。在这种情况下，节省数据是一条错误的努力方向，这家公司不值得投资。 — location: [1088]() ^ref-28515

---
因为应用的场景不同，才有了各种压缩算法。 — location: [1098]() ^ref-56461

---
高比例的信息压缩到底是压缩掉了什么信息？ 简单地讲，就是压缩掉了高频信息。 — location: [1099]() ^ref-1690

---
我们在生活中有句谚语，叫做“枪打出头鸟”，其实在信息压缩中，总是遵守这个 原则的，任何与众不同的东西，总是先被压缩掉，因为对那些与众不同的东西做编码，占用的空间相对太多。 — location: [1106]() ^ref-18901

---
思考题：我们身边有很多朋友，都是无损音乐、无损电影的爱好者，从听觉和观感上说说真的有那么大的区别吗？有没有其他影响因素呢？ — location: [1122]() ^ref-23976

---
信息的压缩分为有损的和无损的两种。对于无损的压缩，原先的信息能够完全复原，但是通常压缩比不会太高，因为它存在一个极限，就是香农第一定律给的信息熵的极限。对于有损的压缩，信息复原后，会出现一定程度的失真。 通常失真率和压缩比直接相关，压缩比越大，失真率越高。采用什么样的压缩方法，压缩到何种程度，通常要看具体的应用场景。在信息处理这个领域，常常不存在所谓的标准答案和最佳答案，只有针对某个场景的好的答案，而一切都是妥协的结果。 — location: [1115]() ^ref-26183

---
生活中你可能有这样的经历，面临决策时，知道的信息越多，反而越是扰乱了你的思路。反复权衡，最后，干脆就瞎选了一个，如果这是人生的重大决策，很可能会追悔莫及。 这一讲，我想告诉你当面对的信息很多时，如何利用和组合信息，提高自己的决策水平。 — location: [1129]() ^ref-62553

---
首先，和能量不同，相同的信息使用两次，不会产生两倍的效果。 — location: [1137]() ^ref-42462

---
在利用多种信息消除不确定时，所采用的信息是正交的（垂直的）时候，效果最好。 — location: [1148]() ^ref-43002

---
什么是垂直的信息呢？我们不妨看两个例子。第一个例子是语音识别。语音识别问题其实可以被看成是一个 N 选一的问题，就如同猜测世界杯足球赛冠军那样。 比如说汉语里大约有 1260 个左右的拼音读音，对每个音节的识别就是 1260 选 1 的问题。要消除这其中的不确定性，用到的最有效的信息是两类，第一类是所谓语音的信息，也就是说每一个读音和各种语音之间的相关信息。 第二类是语言信息，也就是一种读音在上下文中出现的可能性。这两种信息就是正交的。 我们在前面讲了，任何一种信息都可以对应到某个空间中的一个矢量，如果你把上述两种信息在空间中画出来，就会发现它们之间的夹角是 90 度，也就是说两种信息是正交的。 李开复当年在卡耐基-梅隆大学做了一个实验，如果只采用语音信息，要进行语音识别的难度相当于 1000 选 1，如果同时采用了语言信息，难度则下降到 20 选 1。 — location: [1164]() ^ref-39669

---
名片识别是印刷体识别中不是很困难的一个任务，但是它对准确率的要求极高。 今天市面上大部分的软件识别率在 98%左右，这其实已经很高了。但是总有 2%左右的错误会发生的话，还是让人有点烦，因为总得手工更正。如果遇到懒人不检查就直接放进通信录，有时会搞错对方的电话或者邮箱。 以前大家解决这个问题的思路比较单一，总是想着提高图像的识别率，虽然各种办法都想了，总是有些情况难以通过图像识别解决。 2012 年，加州大学洛杉矶分校的一位华裔教授通过大数据的方法解决了这个问题。 她能够将名片识别的准确率提高到 99.9%。 她是怎么做的呢？说起来非常简单，就是把互联网上能找到的各个单位的信息找到，然后用那些公开的信息验证图像识别的结果。 比如某个人的公司的总机电话是 738 5546，即便名片上 3 和 8，5 和 6 印得不清楚，只要识别对这家公司，和她之前在互联网上找的数据一比对，就可以纠正过来。 — location: [1174]() ^ref-47683

---
如果做检查，你做了一遍 X 光透视，又做了一遍 CT 扫描，最后还做了一次核磁共振，这三种信息基本上是一个维度的。核磁共振发现不了的问题，前两种基本上也没有用。 这就是为什么很多人容易上当的一个原因，就是他们不善于选用正交的信息进行交叉验证（ — location: [1193]() ^ref-19019

---
很多人觉得他也注意了不同媒体的信息，而不是只信一家之言，但是他忘记了今天很多媒体的信息都是相互抄的，也就是说一种信息多次使用而已。 第二个原则是，避免反复使用相互嵌套或者相互包含的信息，即使它们来自不同的来源，因为那些信息即便不完全相同，但是可能一个覆盖了另一个，或者相似性太高。 很多人申请工作，简历中提供的都是相互覆盖的信息。比如最重要的两段工作经验本身已经证明专业能力了，还罗列了一大堆无关紧要的工作经历，以及可有可无的专业证书。这些对别人了解自己不会有更多的帮助。 — location: [1196]() ^ref-5247

---
至于在多种信息源中，如何选取几种最重要而且彼此尽可能正交的信息呢？在信息处理中常常有两个方法，一个是不断叠加，另一个是不断删除。 — location: [1205]() ^ref-33093

---
我们假定有十种信息，需要选出三种，使其组合起来是最有效的。我们先对它们单独评估，列出对于解决我们的问题的有效性，并且从大到小排序，然后把排在第一位的作为基准。 第二步，是在第一种信息已经使用的基础上，对剩下的九种重新评估，再重新排序，选出这次排序最高的。 第三步类似于第二步。这样可以不断选择下去。这种做法衡量的不是每一种信息单独的有效性，而是找到它们组合的有效性。 — location: [1208]() ^ref-2250

---
衡量两条信息之间相关性的新工具：互信息。 — location: [1228]() ^ref-37913

---
相关不是因果，其实世界上大多数联系都是相关联系，而非因果联系。相关的联系可以强，可以弱，但弱相关其实没有什么意义，我们需要寻找和利用的是强相关性。 — location: [1229]() ^ref-17033

---
两件事情同时发生了，它的概率就是P(XY)，被称为“这两个随机变量的联合概率分布”。 — location: [1258]() ^ref-31761

---
如果 X 和 Y 基本上无关，它们的计算结果，也就是互信息就近乎为零。如果相关，它们的互信息就非常大，你可以把互信息简单地理解为相关性。 — location: [1263]() ^ref-23279

---
我们假定，股市的涨跌是个随机变量，用 X 表示，对于它的全部的不确定性，就是 X 概率分布所对应的信息熵，通常用 H（X）这个符号来表示。 如果你得到了一些内部消息，这些消息我们用 Y 来表示，那么股市对于你的不确定性就是 Y 条件下，X 概率分布的信息熵了，通常用 H（X|Y）表示，它被称为条件熵， Y 是条件。 也就是说，在别人眼里，股市的不确定性是 H（X），而在你眼里，因为有了信息 Y，因此它的不确定性变成了 H（X|Y）。 — location: [1334]() ^ref-28141

---
在信息论中可以证明，H（X|Y）永远比 H（X）小，或者相等，即 H （X|Y）≤ H（X）。 — location: [1341]() ^ref-41562

---
今天股市的不确定性其实已经不再是 H（X）了，而是在这些信息条件下的 H（X|Y1，Y2，Y3，……，YN），也就是在 Y1，Y2，Y3，……，一直到 YN 所有信息都使用后的条件熵。 — location: [1354]() ^ref-33869

---
我们不妨假定今天大家使用过的关于股市的各种技术指标分别是 Y1，Y2，Y3，……，YN，有 N 种。 今天股市的不确定性其实已经不再是 H（X）了，而是在这些信息条件下的 H（X|Y1，Y2，Y3，……，YN），也就是在 Y1，Y2，Y3，……，一直到 YN 所有信息都使用后的条件熵。 这时，你再将其中的某个指数，比如 Y5 重复使用，不会得到任何更好的结果。这也就是我常说的，靠画 K 线炒股挣不到钱的原因，因为它不过是众人所知的某个 Y。事实上，专业投资人没有靠画 K 线投资的。 当然，如果你有幸发现了一种新的和股市变化有关的信息，我们假设是 YM，它不在 Y1，Y2，……，YN 中，那么恭喜你，你有可能挣到钱。 这就是当年彼得·林奇在发现 PEG 这个信息后挣到钱的原因（关于彼得·林奇的故事，大家可以回顾《Google 方法论》第 55 封来信）。 当然，你还必须像彼得·林奇那样心里能够装得下事情，不要出去乱说。因为一旦 YM 这个信息被别人知道，成为公众信息，你就再也挣不到钱了。 正是因为这个原因，真正能够通过投资股票挣钱的人，是不会告诉你所谓投资秘诀的。而在电视上开讲座讲投资的，反而是自己挣不到钱的。 — location: [1353]() ^ref-8583

---
信息增益（Information Gain，简称 IG）的概念。 我们还是回到了解股市变化（对应随机变量 X）这个话题，在没有任何信息的情况下，它的不确定性是 H（X）。在有了 Y1 这个有用信息后，它的不确定性变成了条件熵H（X|Y1），我们前面说了，它比 H（X）有所减少。 那么 Y1 所带来的信息增益就是 H（X）-H（X|Y1），我们写作 IG（Y1）。 事实上具体到这个特殊的情况，IG 就是 X 和 Y 之间的互信息，这个值越大，说明消除的不确定性越大，X 和 Y 越具有相关性。 — location: [1366]() ^ref-51701

---
先说说一条信息的价值，它取决于这条信息对未知系统所带来的信息增益。两条信息，先出现的，价值更大，第二条价值就小，在数学上可以证明这一点。 — location: [1385]() ^ref-57183

---
在一项课题的研究中，最初的几篇论文，即便绝对水平不是最高，但是通常提供的信息增益最大，因此影响力也最大。越往后，信息增益就越来越少，影响力自然就少。 在学术界，大家评估一个人的科研水平，主要是他所发表的论文的两个指标，一个是引用的数量，另一个是所登载期刊的影响因子。 其中后者是整个期刊一段时间内发表的所有论文的引用数总和（不是直接计算的，来自不同期刊的引用会有不同的加权）除以论文数，也是引用数量的间接度量。 因此，论文的重要性几乎就等于引用数，而引用数几乎无一例外地和信息增量相关。 当你说出一个别人不知道的事情时，就会被大量引用，很快就成了学术权威。如果总是做别人已经解决得差不多的课题，做得再好，在学术界也没有影响力。 对于媒体报道，独家报道受关注的程度，远远高于凑热闹围观。所以，第一个发稿的，影响力要远远大于后面跟踪报道的。 — location: [1388]() ^ref-44754

---
对于个人，也是如此。第一个说出看法的，常常就成为了意见领袖，跟着发表看法的，大家其实记不住。这时，如果还想引人注意，就要提供之前谈到的正交的信息，也就是说和别人已经提供的信息都不相关的。 很多人喜欢发表与众不同的意见，其实是有道理的，因为标新立异的观点，才有可能提供之前大家不了解的信息，当然那些观点本身需要有证据支持，符合逻辑。 — location: [1398]() ^ref-52258

---
置信度就是我这一讲要教给你的知识点，它可以帮你衡量一个信息到底是否可靠。 — location: [1422]() ^ref-46649

---
那么什么是置信度（Confidence Level）？ 我们不妨再看这样一个简单的例子，你扔了 14 次的钢镚，有 8 次正面朝上，6 次背面朝上，你有多大的把握说钢镚不均匀，正面朝上的概率更大，这个把握就是置信度。 衡量置信度的方法有很多，有一种被称为“T-测试”（ 也叫 T 检验）的方法，它可以告诉我们在看到某种看似有偏差的现象时，有多大的可能性可以判断这种偏差是因为随机性造成的，而非真正存在偏差。 — location: [1439]() ^ref-23495

---
怎么才能够提高置信度呢？通常的办法就是要增加所统计的样本的数量。 — location: [1449]() ^ref-37200

---
人们在对待信息时通常犯的一个错误，就是忽视它的置信度，以至于我们把完全随机的事情，当成必然的事情。 — location: [1459]() ^ref-51173

---
那么置信度要达到什么水平才算是可靠呢？在工程上，包括在药物试验上，通常要求达到 95%以上。 — location: [1466]() ^ref-43229

---
当我们普罗大众还在为机器取得了智能，会不会反抗人类发愁时，其实已经被那些智能程序控制了。 不信的话，就看看今天有多少人自从有了微信后生活的习惯就改变了，有了今日头条后就失去了主动寻找新闻的能力，甚至失去了判别新闻真伪的能力，有了淘宝以后，又有多少人买了一堆没用的便宜货。 — location: [1486]() ^ref-7577

---
我们要介绍的代价函数被称为库尔贝勒交叉熵（K-L divergence 也叫 KL 散度）。从这个名称可以看出，它和熵有关。库尔贝勒交叉熵讨论的是在信息误判时的损失。它的思想是这样的： 我们用 X 代表一个随机事件，它发生的各种可能性有一个概率分布，我们用 P（X）表示，比如说盟军登陆地点的两种可能性是，诺曼底=0.7，加莱=0.3，我们就写成 P（X）=（0.7，0.3）。 如果登陆地点的可能性有 5 个，我们就写成（0.5，0.2, 0.1 ,0.05, 0.15）,分别表示这五个地点的可能性，总之这些概率的和都是 1。 当然，由于德军不知道盟军真实的意图，它只能猜，这就有可能出现偏差，我们 不妨假设它猜的结果是 Q（X），通常 Q（X）不会正好等于 P（X），比如是（0.3，0.7），正好把两个概率猜反了。 那么这时候它因为信息偏差带来的损失是多少呢？库尔贝勒交叉熵给出了这样一个公式： — location: [1509]() ^ref-62471

---
也就是说当你预测的概率分布和真实情况完全一致时，损失是零。 — location: [1530]() ^ref-14810

---
5.在信息论中，任何硬性的决定（hard decision）都要损失信息。 — location: [1562]() ^ref-41283

---
像前两年一位声誉很差的创业者动不动呼吁大家“all in”一样。那样的损失可能是巨大的，而且是补不回来的。 — location: [1563]() ^ref-56875

---
今天做人工智能的人都有这样一个经验，在走到最后一步之前，最好多保留一些可能性，哪怕将那些可能性的权重设得非常低，而不要很早就硬性地作决定，因为在硬性决定后失去的信息是永远也补不回来的。 — location: [1565]() ^ref-27827

---
我在谈到教育时，常常讲在本科以前，要进行通识教育，不要在一棵树上吊死，就是要避免过早开始硬性决定。我常常提倡变色龙精神，也是要避免一旦押宝押错了得到不可逆转的灾难。 — location: [1567]() ^ref-43069

---
当然，对于那些可能性不大的事情，在有所防范的同时，不要均匀分配力量，因为这种做法成本也很高，我们在上一条已经分析了。 — location: [1569]() ^ref-4678

---
至于该分配多少资源给那些虽然没有发生，却不能排除可能性的事情，早在上个世纪 50 年代，图灵的学生古德就提出了一种很实用的方法，被称为古德-图灵估计（Good-Turing Estimate），它的原则是从所有预见到的事情中拿出很少一些资源，分配给没有预见到的事情。 — location: [1570]() ^ref-50602

---
那么误导人的信息都有哪些特征呢？ — location: [1591]() ^ref-4064

---
首先，刻意要引起你注意的人，常常会用耸人听闻的信息打动你，他们也知道那样的信息提供的信息量最大。因此，对于那些看似颠覆了你长期认知的所谓的“新知”，你要特别小心。 — location: [1592]() ^ref-16484

---
这一类消息基本上就是耸人听闻，如果你信了，然后就会心慌，难免作出错误的操作，最后损失的是你自己。那么怎样判断这样耸人听闻的信息是否真的有价值呢？我给你提供三个方法，分别是： 1.将它们放在更大的时空来考量，因为更大的时空提供了基本的信息量，而最近的消息，某一篇报道，某一个人的观点，某一本书的内容，就算信息准确，提供的也只是增量信息。 — location: [1597]() ^ref-7941

---
2.要看信息的一致性。今天标题党最大的特征就是标题和内容不一致。信息的一致性是信息本来的特征，但是人为地加入了很多虚假信息后，就不一致了，标题党便是如此。 — location: [1606]() ^ref-45651

---
3.对于从一大堆信息中抽取的信息，要看它们的失真率。我们在前面讲语音压缩和图像压缩时说过，压缩过的信息和原来的信息相比，要尽可能避免失真，为此，只能过滤高频的信息，也就是不太经常出现，高出正常频率的信息，而不是相反。 那些故意误导人的信息则相反，它们把背景的低频信号过滤掉，保留个别高频信号，这就如同一张图片中蓝天上有一只鸟，那些人把背景的风景都过滤掉了，把那只鸟刻意留下来。然后他们刻意渲染——整个风景就是一只鸟，这样的信息过滤后，失真率是极高的。 — location: [1614]() ^ref-40832

---
误导人的信息的第二个特征是没有出处，或者只有一个无法验证的出处，几乎所有的和阴谋论相关的信息都有这个特点。 — location: [1633]() ^ref-24712

---
听《页岩革命》 — location: [1647]() ^ref-16107

---
最好、最重要的资源要用于那些出现最频繁的事情，这样分配资源最有效，其背后的原理是香农第一定律和霍夫曼编码。 不要将相关性当成因果关系。弱相关性对我们做事情没什么帮助，而对于强相关性，要搞清楚谁可能是因，谁可能是果，切忌因果倒置。 我们很多时候，要直接获得某种信息是很困难的，因此可以通过获得等价信息，得到同样的效果。 我们日常遇到的大部分事情，都是渐变的，因此通过增量改进，要比推倒重来效率高，这就如同对增量压缩，可以比静态压缩高很多一样。 由于我们遇到的信息很多，一个比较高效率表示信息的方法是矢量化，也就是将很多维度的信息映射到我们关心的几个维度。我们用到的例子是：文字的演变就是矢量化的结果。 — location: [1649]() ^ref-32908

---
信息熵，它说明信息量和不确定性的关系。 冗余度，任何信息中都有冗余，去除冗余是今天信息处理的一项重要工作，但是，有时冗余又有它的好处，它可以避免出错。 不同信息的正交性：我们常常说的互补，其实就是某种意义上的信息正交。同一种信息用好几遍，效果不如使用两种正交的信息。不仅信息如此，打造一个团队也是如此。 — location: [1659]() ^ref-44353

---
所谓期权，就是一种在未来能够以某个价格进行证券买卖的合约。比如说今天的石油是 60 美元一桶，在一年时间内买石油的期权可以这样定义： 1.乙方卖给甲方一种期权，有效期是一年，在这一年内甲方都可以按照60美元一桶的价格随时买进石油，不论当时的价格是多少。 2.如果一年内石油的价格没有达到60美元，甲方不需要对乙方尽任何义务。 3.一年过后，期权合同到期，乙方不再对甲方有任何义务。 这样的合约听起来是甲方稳赚不赔，因为如果石油价格上涨比 60 美元高，那么甲方就可以选择行使合约中的权利，还是以每桶 60 美元的价格购买石油，然后再转手在市场上卖出挣钱。如果石油的价格下跌，甲方什么都不用做，这个合约就当没有存在。 这么看来，好处都让甲方赚了，乙方当然不会免费为甲方提供这种合约，它会收取一个双方认为合适的价格，按照今天石油期权的价格，在油价每桶 60 美元时锁定一年的期权要买的话，需要花 8.3 美元左右。 当然，乙方还可以调整预期价格，比如把 60 美元的预期提高到 65 美元。这样一来，一方面，在未来的一年里石油价格上升到 65 美元的可能性要比 60 美元小，因为幅度太大了。另一方面，如果油价上涨，甲方按照 65 美元行权，利润也显然要比按 60 美元购买低。因此，甲方肯定不会再出 8.3 美元来买这个期权，根据石油市场实际期权的行情，65 美元的期权价格大约是 5.5 美元左右。 因为甲方一开始花钱买了期权，它将来的买卖就有成本，不是无本万利的了。对于买了 60 美元期权的人来讲，在一年内，如果石油的价格不能超过 68.3 美元，即 60 美元行权价格加上 8.3 美元的成本，它就会赔钱。 在油价超过 68.3 美元之后，每涨 1 美元，它就赚 1 美元，涨 10 美元，就赚 10 美元。 假如你特别看好油价上涨，花 8.3 美元买了 60 美元行权价的期权，如果油价涨到了 100 美元，你就用 8.3 美元的投入，换得了 100-68.3=31.7 美元的利润，利润率接近 400%。如果你直接买石油存着，投入 60 美元挣了 40 美元的利润，利润率只有 67%。 因此你可以看出期权其实是一种投资杠杆，它可以在有限损失的情况下增加自己回报的比例。当然期权投资大概率也是会亏损的，如果行权的价格越高，一旦成功，利润率就越高，但是亏钱的可能性也就越大。 对于期权投资，你可以认为甲方在支付一定费用的情况下，希望以较小的概率获得很高的利润率。对于乙方来讲，如果一年的时间过去了，石油的价格控制在 68.3 美元以下，它就谢天谢地把对方的钱赚到手了。 好，你明白了期权是怎么一回事，那么问题来了。万一石油的价格疯涨，乙方赔不出那么多钱，是不是就会倾家荡产呢？那么你要是高盛，会怎么做呢？你就需要反过来想问题了。 我们不妨想想谁手上有大量的石油，不怕油价上涨，而且希望油价上涨呢？你可能会想到是石油公司。没错，就是它们。 假如你是石油公司的老板，今天 60 美元一桶的价格出售是可以接受的，如果油价下跌了，你就不得不降低产量，以免以过低的价格卖掉太多的原油。这样你就没有了收入，但是如果这时有人讲，以每桶 8.3 美元的价格白给你钱，不论将来的油价高与低，你自然会非常高兴。 当然，提供这样好条件的人加了一个附加条件，如果油价上涨，他需要从你手里以 60 美元的价钱买油，你为了维持利润的稳定，可能会答应。就这样，高盛就找到将来能够提供原油的一方。 那么什么人最喜欢花钱买石油的期权呢？你可能会觉得是赌徒，其实还真不是，主要是那些需要大量使用能源的客户，比如航空公司，它们害怕油价暴涨，于是就愿意花钱买期权锁定油价。好了，既然双方都有各自完全相反的需求，高盛就会做一种结构化的投资产品，同时卖给双方，它在定价时会略作小的调整，比如它把期权的价格从 8.3 美元提高到 8.5 美元，把付给石油公司的费用降到 8.0 美元，中间的差价就是它的了。 那么你会想，石油公司和航空公司能否直接进行这种交易，绕过高盛呢？几乎不可能，因为这种一对一谈判的成本比付给高盛利润更贵。更重要的是，石油公司和航空公司都未必能够对未来油价波动的风险达成一致的看法。 今天之所以花了很多的时间来讲结构化的投资产品，还是为了说明信息的作用。高盛在这个游戏中是信息的提供者，只不过它没有直接卖信息，而是把它想办法和钱联系了起来，通过金融产品挣钱。 — location: [1680]() ^ref-56487

---
压缩和过滤是两回事。压缩是指通过优化的信息编码，用更小的编码长度（或者存储空间）表达同样多的信息，而过滤是根据自己特定的需求，保留自己认为有用的信息，滤除自己用不到的。 — location: [1726]() ^ref-10208

---
为了便于你理解它们的区别，我们可以从这样几个角度来看： 首先，无损的压缩是没有过滤的，因为所有的信息都保留下来了。 其次，有损压缩时，肯定是过滤掉一些信息，这个过滤的原则是让信息量尽可能地不减少。但是一般性的信息过滤，原则就是保留自己要用到的，而非信息量。 — location: [1727]() ^ref-31370

---
如果你是一家公司的人事经理，年底时要设计一个对员工进行评估的方案，利用矢量化的原理，怎样设计方案比较好呢？ 吴军 不同企业衡量人的标准不同。但是有三点是共同的： 这个人过去一年的绝对贡献的多少。当然在衡量贡献时，要考虑他的职级，贡献要和职级相一致。 这个人的成长，能力的提升。特别是在前一次考核中，希望他提高和改进的地方，他是否改进提高了。 完成贡献的过程，是否是通过团队合作完成的，还是通过抢同伴功劳完成的。 在完成任务时，是帮助了其他人，还是对整个组织机构的发展没有帮助。 — location: [1750]() ^ref-55407

---
著名收藏家马未都先生有一次在电视节目中和北大一个教授争论历史是否有真相。那一次马先生其实是有备而来，他一开始引导对方进入自己准备好的战场，然后引导对方讲出破绽，最后拿出自己的证据反击。 对方显然是没有准备，其实有几次自圆其说的机会都因为慌乱而抓不住。大家可以在网上找一下那段视频，那是一个很好的辩论和说服人的案例。 — location: [1767]() ^ref-62767

---
马先生认为有大势，比如“分久必合，合久必分”，但是细节的真相有七成都不准确。 同时他指出，正确的历史观比历史细节更为重要。这种讲话的方式也是非常值得学习的，因为我们不能一味地语出惊人，而要讲清楚自己的观点。 一看自己研究的领域被说成找不到真相，那位历史教授就急了，说历史当然有真相，而且言下之意，历史学家就是要找真相。人在任何场合，特别是和别人辩论时都不能急，一急就被对方拉入自己的主场了。 — location: [1774]() ^ref-26439

---
信号和噪音的比例达到一个什么程度，就能恢复出有用的信息来呢？这件事没有一个绝对的阈值，超过那个阈值就能恢复信息，不到就恢复不了，而是根据信号和噪音的比例，也就是我们要说的信噪比，在不同程度上能够恢复一定的信息。 — location: [1802]() ^ref-18667

---
在信息论中，噪音有特殊的含义，它可以是嘈杂的信号和声音，但又不完全相同，也可以是其他的干扰。它有下面三个特点： 未知，而且通常是随机的，也就是说难以预测。我们在生活中有这样的经验，如果你在房间里和别人谈话，有背景音乐让你觉得谈话听不清，你关了音乐即可，很确定。但是对于那些不知道来源，或者你关不掉的嗡嗡声，你就很烦。 不含有用信息。 — location: [1809]() ^ref-53526

---
噪音和信息不是绝对的，要看场景。你开车时发动机的声音就是噪音，但是在检查汽车工作状态时，那种嗡嗡声可能就是信息了。 — location: [1816]() ^ref-40066

---
噪音的出现使得信息的捕获、存储、传输和处理会受到影响。因此，我们要想准确获得信息，信息本身的幅度（也就是能量）相比噪音需要足够高。 — location: [1818]() ^ref-49304

---
关于信号和噪音的关系，你还需要知道两点，这两点可以帮你： 首先，它们是一对孪生子，总是相伴存在的。 — location: [1829]() ^ref-29328

---
因此，考察和判断一个人是否有处理问题的能力，不是考察他在纯粹无噪音的条件下的能力，而是要考察他能否在有噪音的情况下，依然把信息找出来，处理好。 — location: [1831]() ^ref-2247

---
要通过过滤噪音，提高信噪比。 — location: [1859]() ^ref-53014

---
噪音通常可以根据产生的原因以及表现形式作如下的分类： 1.能够找到噪音来源的 vs 不清楚来源的。 — location: [1860]() ^ref-5174

---
2.有规律的噪音 vs 随机的噪音，固定频率的噪音 vs 白噪音。 — location: [1869]() ^ref-40434

---
利用计算机如何去除噪音的， — location: [1874]() ^ref-26922

---
第一个常用的方法就是利用信息的冗余。 — location: [1875]() ^ref-38355

---
增加一个专门接收发动机噪音的麦克风即可。 — location: [1878]() ^ref-42405

---
类似的，如果一个领导在大会场作报告，在不同角度安装几个麦克风即可（它们通常也被称为麦克风阵列），通过对比几个麦克风收到的语音，就可以判断哪些是信号，哪些是噪音。这种方法，从本质上讲，利用了信息的冗余度，也就是说，利用多余的信息，减少误差。 — location: [1879]() ^ref-24791

---
第二个方法就是换一个角度看问题。 — location: [1884]() ^ref-29384

---
比如说一个剧组在拍外景，有一堆鸟在叽叽喳喳叫，那些就是噪音。但是这种噪音其实很容易过滤掉，因为使用我们前面说的傅里叶变换可以将所有的音频信号变成频率信号，鸟的叫声在特定的频率上，只要将那个频率的信号过滤掉就可以了。 — location: [1888]() ^ref-58572

---
香农研究信息论，就源于往语音中加入白噪音。 — location: [1893]() ^ref-58574

---
最后香农证实，这种想法是可行的，因为噪音分布在各个频率，任何算法都无法过滤掉。但这有一个前提，就是对方不可能知道你产生白噪音的算法，否则他们可以复制这种白噪音，然后从信号噪音相混的信息中将噪音滤除。 — location: [1903]() ^ref-32818

---
如果你只从一个信息源了解信息，你其实很难判断所获得的是噪音还是信号。如果你从多个信息源了解信息，虽然它们各自都有噪音，但是由于报道的角度不同，很多噪音彼此可以抵消掉，获得的则是信息，或者说是信噪比很高的信息。 — location: [1914]() ^ref-24289

---
我在《Google 方法论》中讲到过，最可贵的意见不是所谓客观的，而是真正反映自己想法的主观的意见。因为那种看似唯一客观的理论，其实是有偏差的，当一个企业，只有领导一个人的意见时，那些原本不大的噪音就被放大，以至于会淹没信号。 — location: [1918]() ^ref-11644

---
相反，如果每一个人都把自己主观的意见说出来，虽然每一个人有偏见，也就是说噪音，但是合在一起我们就得到了大众想法的轮廓。 — location: [1920]() ^ref-11257

---
如果你反过来思考去利用噪音，想将一些信息隐藏在噪音中不被别人发现，最好的办法就是制造毫无规律的白噪音。 — location: [1929]() ^ref-24444

---
如果想让盗号者过滤不掉噪音，就要在语音的各个频率加入随机的噪音，也就是白噪音。后来他们这么做了，果然盗号的成功率就降低了很多。 — location: [1937]() ^ref-51170

---
我们这一模块是围绕信息传输这个主题展开的，而传输信息就需要一个信道，比如我们讲话时，从声带到空气到耳蜗，就形成一个真实的信道。 — location: [1948]() ^ref-17909

---
当信息传输所用的信道一旦固定，能承载的信息量是有限的。香农给出了对于信道的量化度量，也被称为信道的容量， — location: [1965]() ^ref-15799

---
使用“带宽” — location: [1966]() ^ref-44832

---
我们先来看一个具体的例子：我们人正常通话，需要多宽的带宽？ 我们人讲话的频率通常在 300～3400 赫兹（Hz）之间，也就是说我们声音的音频一秒钟振动 300～3400 次。振动 300 次的是低音，振动 3400 次的是高音。我们在前面讲到，任何周期性信号，都可以变成很多不同频率正弦波（或者余弦波）的叠加，这在信息上是等价的。 于是，我们可以把人讲话的语音，等价成从 300 赫兹、301 赫兹、302 赫兹……一直到 4000 赫兹的正弦波的叠加。在数学上任何一个频率的正弦波，都是由两个变量确定的。于是这 3100 根曲线就对应了 6200 个变量。 在工程上我们会把频率的范围放大一点，放大到 1～4000 赫兹，于是 1 秒钟的语音就需要用 4000 条正弦曲线，即 8000 个变量来描述。 我们再假定每个变量用 8 比特信息编码，于是传递我们说话语音的带宽就需要能每秒钟传递 8000x8=64K 比特信息，这就是语音通话所需要的信道的宽度。事实上，这也是我们使用的长途电话的标准带宽。 — location: [1967]() ^ref-60141

---
不仅电话线的带宽有限，给定任何频率范围的电磁波，所能够承载的信息都是有限的。比如很多人家里使用 2.4G 的 Wi-Fi 信号上网。如果我们限制频率的范围从 2.4G （千兆赫兹）到 2.401G 之间，带宽有多宽呢？ 这中间的频率范围是 0.001G（千兆赫兹），也就是 1M（1 兆）字节左右，大约是每秒钟传输 8M（8 兆）比特，因此你的带宽就这么点儿。 — location: [1976]() ^ref-3885

---
香农进一步指出，信道的容量，决定了有效的传输率，这就是信息论中有名的香农第二定律， — location: [1990]() ^ref-52555

---
首先，我们要清楚信息的传播是有成本的，其成本就源于信道的容量。 — location: [1992]() ^ref-9464

---
第二，我们讲了某一个范围的无线电波，所能承载的信息是有限的，因此无线通信的效率其实永远赶不上有线电缆/光缆，因为有线的传输信号是封闭在通信线路里面的，从理论上讲你可以无限制地在地下埋通信线路。但是空中的频率是共享的，在一定区域内，你占了 2.4～2.401G 之间的带宽，别人就用不了了。 — location: [1999]() ^ref-46317

---
第三，量化度量这件事很重要。我们今天举了一个例子，语音传输的带宽是怎么计算出来的，它可能读起来有点枯燥，但是我想通过这个例子来说明寻找我们做事情边界的方法，就是估算一下它们的理论极限。 — location: [2010]() ^ref-29668

---
了解做事情的边界，在边界内尽可能把事情做好，不仅在通信上是这样，在生活的方方面面都是如此。 — location: [2014]() ^ref-36278

---
在没有信道容量这个概念之前，人类在通信上走了很多的弯路，把精力浪费在实现根本不可能实现的事情上。这和过去人们寻找长生不老药，发明永动机很相似。 了解做事情的边界，在边界内尽可能把事情做好，不仅在通信上是这样，在生活的方方面面都是如此。 — location: [2012]() ^ref-20791

---
要点总结◆──── 1.信息传输需要信道，信道就像是公路，它对信息的“运载量”是有上限的。 2.信道是可以量化度量的，它的容量也被称为带宽，带宽决定了传输效率，有线通信的效率通常是高于无线通信的。 — location: [2016]() ^ref-64250

---
如果我们只有一个很窄的信道，也就是说信道容量 C 非常小，却想传输非常多的信息怎么办？唯一的办法就是延长传输的时间，也就是降低传输率。 — location: [2027]() ^ref-55386

---
香农第二定律。 如果我们只有一个很窄的信道，也就是说信道容量 C 非常小，却想传输非常多的信息怎么办？唯一的办法就是延长传输的时间，也就是降低传输率。 — location: [2026]() ^ref-865

---
在信息论中传输率 R 的严格定义是单位时间（通常是秒）传输多少比特的信息。 — location: [2028]() ^ref-50837

---
香农发现，信息通道的传输率 R，是无论如何无法超越信道容量 C 的，即 R≤C。接下来香农还讲，总能找到一种编码方式，使得传输率 R 无限接近信道容量 C，同时保证传输不出任何错误。 至于怎样找到这样的编码，香农没有讲，他给出了一个原则。但是，如果谁要试图超越信道容量传输信息，不论你怎样编码，出错的概率都是 100%。 — location: [2035]() ^ref-57804

---
我要给一些家长两个建议：第一个建议，根据孩子的潜质，决定他所学的内容。客观地讲，绝大部分孩子都不是数学学霸，不适合搞奥数，甚至不适合花太多时间做难题，或者比别人学更多内容。 — location: [2076]() ^ref-60177

---
第二个建议，选择学校，要选择一个适合自己的。不要一心往学霸的圈子里扎。 — location: [2083]() ^ref-14918

---
3.男女朋友和夫妻之间的关系和沟通。 我在《态度》中讲，做男女朋友，两情相悦就好。真要是走入婚姻，最好双方三观一致。从信息论的角度看，所谓三观一致，就是两个人对世界的看法的互信息很高，这样两个人沟通信道的容量很大，丈夫说件事，妻子马上理解了，反之亦然。 如果两个人三观完全不同，对同一件事的看法完全不同，互信息接近于零，讨论起事情来，鸡同鸭讲。一开始那股兴奋劲头一过，矛盾是难以避免的。 — location: [2091]() ^ref-63747

---
1.我们讲了香农第二定律，重点强调了永远不要试图超越信道容量传输信息，因为那样的效果等于零。 2.我们再次强调了在边界里做事情的重要性，只是这一回，我们是通过量力而行来说明的。如果先天的信道容量不足，唯一的方法就是降低速度。 — location: [2100]() ^ref-12299

---
信息时代的企业到底要不要扁平化管理。这一讲的内容可以帮助我们从管理和商业上进一步理解香农第二定律。 扁平化的管理，顾名思义，就是管理的层级要足够少。 — location: [2109]() ^ref-50739

---
首先是中间六七层都是冗余人员，使得企业的成本剧增，另一方面，使得上下沟通的带宽变得非常窄。 我们知道带宽等于一收一发两端的互信息，这东西是随着信息传递次数衰减的。 — location: [2117]() ^ref-4595

---
我们再看一下另一种极端情况，就是一个老板下面有上百个直接的汇报者。这看似是绝对的扁平，而且管理者的意图可以直达每一个汇报者，但是这样的管理其实效率同样很低，因为管理者自身通信的带宽是有限的，他要传递的信息量又太大。 根据香农第二定律，他只有两个结果，一个是降低自己的信息传输率，也就是说延长信息交流的时间，比如把每周和下属进行一次的交流，延长到每个月一次，这样的结果无非是，下面真出现什么问题，他根本没法察觉。 第二个结果就是将大量的信息硬往不宽的信道里塞，整天晕头转向，其结果是完全失真，信息沟通的效果还不如前一种。 还有一种虚假的扁平化管理，就是虽然在汇报关系上，底层员工可以直接向高层领导汇报，但是层级设置过于分明，部门的边界过于明显，你想约领导的时间他永远没空，你想和旁边部门沟通，你的领导会觉得你不忠，这种扁平化就没有意义了。 — location: [2124]() ^ref-41103

---
上级对下级具有过大的人事权，从招聘、考核评估到提升无不由上级说了算，因此下级会过分看重直接领导的态度，而不是公司的利益。上级也会把下级员工看成自己的私产，并且为了提升自己在公司的地位，不断扩大自己下属的人数。 同时，上级还对内部调动的下级进行打压，每次都将最差的考核评分给予那些希望流动的员工，使得这些员工因为具有了不良的业绩考核记录而难以提升。 — location: [2137]() ^ref-14230

---
上面说的管理方式，即使在汇报关系上再扁平，也起不到信息沟通顺畅的目的。因为各个层级之间，一旦分出了三六九等，信息再往下一层层传递时，就难免人为地根据自己的目的，“截流”一些信息。下属往上汇报时，完全可以报喜不报忧，甚至把丧事当喜事办，因为第一级的管理者无法绕过第二级的中间层向第三级的员工了解真实情况。 类似的，上级向下级传递企业的精神时，中间任何一个环节都可以随意夹杂私货进去。我观察一些企业，发现有些总监让员工做的事情，完全不是公司希望的，而是他的私活。 在 Google 就出现过原本是半个人工作量的活，被一位总监安排了三个全职员工去做，当然这位总监也往里掺杂了很多私活。所幸的是，Google 的各个项目是公开透明的，越级沟通也被允许，因此这样的事情通常可以很快被纠正。 但绝大部分企业发现和纠正这种问题的时间非常长。因为三六九等的职级和部门之间的壁垒将人与人通信的带宽变得非常窄，信息传输率就非常低，同样一个信息传递出去的时间自然长，当然收集信息也变得困难。 — location: [2141]() ^ref-22109

---
所以，扁平化管理的本质就是对香农第二定律的应用，保证一定带宽内的沟通效率或者利用科技提高带宽。其实除了管理，市场推广也是一种应用，市场推广的本质，也是增加对外沟通的带宽。 — location: [2158]() ^ref-42977

---
扁平化管理流行于信息时代，是有它的原因的。这一方面是因为信息量太大，在管理上需要更多的带宽，另一方面是新的通信手段增加了带宽。 而扁平化管理从本质上讲，使得整个公司内部信息交流的带宽比过去有了质的提升，基于这样的带宽，对内合作可以变得更顺畅，对外能有更强的市场适应性。 所以，扁平化管理的本质就是对香农第二定律的应用，保证一定带宽内的沟通效率或者利用科技提高带宽。其实除了管理，市场推广也是一种应用，市场推广的本质，也是增加对外沟通的带宽。 — location: [2155]() ^ref-34199

---
互联网的出现不仅进一步扩展了带宽，而且让带宽的成本大幅度下降。这样浙江的小商品不仅能够很快卖到全国，而且不出几年就能卖到世界的各个角落。这就是利用了互联网这个廉价大容量传输渠道的结果。 从本质上讲，阿里巴巴所做的事情，就是拓宽了商家和消费者之间信息交流的带宽。这便是互联网思维，这种思维方式，是符合香农第二定律的。实际上，香农第二定律描述了自然界本身所固有的规律性，这也是它很容易应用于通信之外的原因。 — location: [2168]() ^ref-529

---
信道的容量，也就是带宽，是由双方的互信息决定的，在商业上，它就是双方的信任。卖家传递的信息，和买家认可的信息一致，两种信息之间的互信息就高，带宽就大，生意就能做成。 相反，如果卖家吹得天花乱坠，买家不认可，互信息就为零，两者之间就没有沟通的带宽，生意就做不下去。中国早期失败的电商代表 8848 就没有能够让买卖双方在它的平台上产生信任，因此生意就做不下去。 因此，当我们说互联网思维时，不要老想着把东西放到网上，就是互联网思维了。 互联网的本质是通信工具，通信里面自有它的规律，比如香农第二定律。做事情的时候符合了规律就做得顺利。 — location: [2174]() ^ref-9039

---
当然，在互联网时代，除了信任，不信任也可以通过互联网来传播。 — location: [2181]() ^ref-36499

---
这位车主就是利用互联网思维让商家的负面信息迅速传播。 当然，我想更进一步告诉你的是，车主能够得到大家的支持，是因为她的行为引起了大家的共鸣。所谓共鸣，其实就是产生了很高的互信息，也就是大家对汽车经销商不合理的所作所为，都有共识。 — location: [2183]() ^ref-57063

---
要点总结◆──── 1.我们从多个角度讲述了扁平化管理，互联网思维和香农第二定律的关系。拓展带宽是今天我们所有人都需要做的事情。 2.我们特别强调了带宽是由通信双方的互信息决定的，这在人际交流中就是信任。 3.利用互联网的带宽，既可以传播正面信息，也可以传播负面信息，而后者无形中起到了社会监督的作用。 — location: [2186]() ^ref-65391

---
如果我们采用正向思维，就会把工作做得更细致一点，试图不出现错误来解决问题。比如多检查检查线路，通信线路屏蔽做得好一点；在通信时说话慢一点，发音标准一点。 这样的努力不能说没有用，但一来使得成本剧增，二来依然有一些问题无法解决，因为出错是人的天性，而干扰无处不在。 — location: [2202]() ^ref-63442

---
因此，从根本上解决传输过程中信息错误的办法，就是在信息传输编码时，考虑到错误必然存在，然后通过巧妙的编码解决那些问题。这就是在信息传输中的逆向思维。具体到通信中，就是通过巧妙的信道编码保证有了错误能够自动纠错。 信息纠错的前提是要有信息冗余。如果一条信息已经被压缩得一点冗余都没有了，它容错的能力就是零，更不要谈纠错的可能性了。 — location: [2208]() ^ref-45494

---
一个最简单的信息纠错的方式就是重复传输的信息。 — location: [2215]() ^ref-50196

---
我们先从一个古老的故事，看看如何检验信息传输正确与否。古代犹太人一直是靠手抄《圣经》将它代代相传的，今天你去以色列，依然能买到很多手抄的《圣经》。抄写的过程是一个信息传播的过程，因此错误便在所难免。 虽然说犹太人做事很认真，而且在抄写《圣经》时，要虔诚并且打起十二分精神，尤其是每写到“上帝”（God 和 Lord）这个词时要去洗手祈祷，但是抄写错误还是难以避免。 于是犹太人发明了一种有效发现抄写错误的方法，他们把每一个希伯来字母对应于一个数字，这样每行文字加起来便得到一个特殊的数字，同样，对于每一列也是这样处理。 当犹太学者抄完一页《圣经》时，他们需要把每行每列的文字加起来，看看新的校验码是否和原文的相同。如果中间有一个词抄错了，比如在第五行、第六个词，那么第五行和第六列的校验码就和原文中的不同了，于是就可以定位错误发生的位置，然后进行修改。 — location: [2221]() ^ref-35055

---
在这个二进制序列中，任何一个 0 — location: [2231]() ^ref-56145

---
今天计算机里最简单的信息校验使用的就是上述原理。我们还是以上面的二进制 10011101 为例来说明。 在这个二进制序列中，任何一个 0 或者 1 发生了传输错误，我们都无法判断是否有错误发生。但是，如果我们将它从 8 位二进制扩展到 9 位，第 9 位就是所谓的奇偶校验位，记录这个八进制到底是奇数个 1 还是偶数个 1。如果在传输时，错了一位，1 的数量就对不上了，这样我们就知道出了传输的错误。这就是奇偶校验的原理。 在上述方法中，如果错了两位，那就检验不出来了，但是这一种情况不多见。90% 几的传输错误是能够发现的，不能发现的错误不到 10%。 接下来我们从信息冗余的角度对它作一个分析，它其实多用了 1 个比特的信息，也就是 1/8 的信息冗余，这样信息编码的长度就略有增加。 当然，这种方法只能发现错误，不能纠正错误，因为错误可能出现在任何一位上。 — location: [2230]() ^ref-43594

---
我们需要想个办法，如果发现传输出错时，能够确定出错的位置，那么我们就可以纠正错误了。我们回顾一下古代犹太人在抄书时定位错误的方法，他们采用横竖两个维度交叉实现。 1940 年，贝尔实验室的科学家海明（Hamming，也被翻译成汉明）设计了一种原理和上述方法类似的纠错的编码方式。 他将一个很多位的二进制数投射到几个维度，然后在每一个维度进行奇偶校验，如果有错，就可以定位出错位置。这种编码后来被命名为海明码，它在今天计算机中被广泛使用。 海明码要增加编码的冗余信息，如果纠正一个 8 位 2 进制中的 1 位错误，就需要增加 5 个校验位，这就是成本。这比简单将信息传输三遍已经有效得多了。事实上，海明码的纠错效率接近了信息论给出的最优值。 今天依然有一些科学家在研究纠错编码，其数学基础主要是数论和近世代数。从这里面我们可以看出数学和信息科学之间的关系。如果我们再换一个角度来看信息纠错的问题，合理的编码如果太密集，就不容易纠错，如果让合理的编码距离拉大，就容易发现错误。 — location: [2239]() ^ref-25313

---
如果我们要求正确的编码必须是个、十、百三位数都一样，那么 0—999 只有 10 个正确的编码，即 000、111，一直到 999。这时正确编码之间的距离至少为 111，距离很大，就不容易出错。 如果我们不断增加合法编码之间的距离，我们的传输就变得越来越可靠，但是这样就要浪费很多信息。因此，有效的纠错编码实际上是在平衡编码的效率和纠错的可靠性。 — location: [2250]() ^ref-24726

---
我们不妨看这样一个例子。假如 0—999 这 1000 个数字，每一个都被认为是正确编码，正确编码之间的间隔只有 1，比如 87 和 86 是正确编码，它们的差距就是 1。这样稍微错一点就出错了。 如果我们要求正确的编码必须是个、十、百三位数都一样，那么 0—999 只有 10 个正确的编码，即 000、111，一直到 999。这时正确编码之间的距离至少为 111，距离很大，就不容易出错。 如果我们不断增加合法编码之间的距离，我们的传输就变得越来越可靠，但是这样就要浪费很多信息。因此，有效的纠错编码实际上是在平衡编码的效率和纠错的可靠性。在这方面，最极端的情况可能是我们自身 DNA 的编码了。 在上个世纪 80 年代之前，研究基因遗传的科学家和研究信息的科学家鲜有交集，因此前者发现 DNA 中很多碱基似乎毫无用处，因为它们根本不和任何功能对应。 今天你依然能读到这样的观点，主要是采用了几十年前的说法。但是后来随着人们对 DNA 的进一步了解，认识到两件事： 1.一些原本不知道对应什么功能的碱基，现在找到了它们的功能。 2.那些多余的DNA并非真的没有用，而是对于防止基因之间在复制的时候因为一个错误而引起一连串的错误很有帮助，你可以认为它们是基因之间的防火墙。甚至有人认为它们可能起到了纠错的功能。事实上，人的基因也是通过信息冗余起到了容错和纠错的效果。 — location: [2249]() ^ref-15387

---
要点总结◆──── 1.不要高估自己的仔细，以及自己通过努力做到最仔细后，能够达到的效果。不确定性是我们这个世界自然的属性。因此，在解决任何问题之前，都要考虑到世界的不完美和不确定性。这就是所谓的预则立，不预则废。 2.在信息的传输过程中总是不免要发生错误的，要想避免出错，就要增加一点信息冗余。增加的信息冗余越多，检验甚至纠正错误的能力就越强。当然，并非简单增加冗余就能查错纠错，人的水平的高低，就在于是否有效利用资源解决了更多的问题。 上帝给每一个人一天24小时，谁也不会多，谁也不会少，只是有些人利用得比其他人更好罢了。 3.有一些自然存在的，看似没用的信息，先不要下结论说它们没有用，在了解清楚之后，你可能会惊叹于大自然的美妙之处。 — location: [2261]() ^ref-32285

---
金庸小说中的韦小宝谎话连篇，但居然有不少人信，很多人就觉得这是金庸瞎编的。但是从信息论的角度来分析一下，这个现象背后还是有一些道理的。我们先来看看韦小宝这个人的行为。 韦小宝说谎的第一个要诀是：说话九句真，一句假。由于有九句是真话，因此大家对他有一个基本信任，否则要是 100%讲假话那就没人信了。 韦小宝的这个做法，就给对方出了一个难题，就是要不要信他的话？如果完全不相信，可能错失一两次机会，当然如果相信也可能被骗有损失。 当然，稍微谨慎一点的人，会想办法从侧面验证韦小宝说话的真假，比如康熙的信息渠道多，经常能识破他的谎话。但是并非任何时候人们都有机会来验证，比如他通知兄弟们逃跑，那时就没有时间去验证，要么信他，要么不信。 这在其实就利用了信息论密码传输中的一个实用性原则，也就是保证一定的时间内密码有效就可以，比如我们认定比特币协议是安全的，其前提条件是，以现有的计算能力，我们无法在有限的时间里破解它。 同样的，由于无法在短时间里验证韦小宝话的真假，因此大家就要算一算，到底是收益大还是损失大。因为他 9 句真 1 句假，让人感觉可能还是收益大，于是很多人就信了。 韦小宝说谎的第二个要诀，就是同样的理由不用两次，这就符合加密中一次性密码永远无法破译的原则。 此外，韦小宝在传递信息的时候，无意中还使用了加密最基本的原则，就是第三方截获加密信息后，不会获得比先前更多的信息。 — location: [2277]() ^ref-8205

---
从信息论的角度出发，谈谈加密的本质。 假如我们有一个原始信息 I（大写的 i），我们对它进行编码，变成 C，C 是所有人都可以读懂的，因此我们称之为明文。当然传输明文 C 是极不安全的，因此我们就对它进行加密，得到密文 E，而使用的密码则是 K。 — location: [2294]() ^ref-58342

---

从信息论的角度出发，谈谈加密的本质。 假如我们有一个原始信息 I（大写的 i），我们对它进行编码，变成 C，C 是所有人都可以读懂的，因此我们称之为明文。当然传输明文 C 是极不安全的，因此我们就对它进行加密，得到密文 E，而使用的密码则是 K。 加密的目的是什么呢？当敌方获得密文 E 之后，对明文 C 的知晓程度不会增加。 — location: [2294]() ^ref-20636

---
在信息论中我们采用的是信息熵 H 来衡量对方的知晓程度，或者反过来说，对方对这个信息的不确定程度。 — location: [2298]() ^ref-31027

---
因此，加密的原则必须是，当对方收到由密码写的密文后，无法降低任何不确定性。 — location: [2302]() ^ref-58686

---
那么怎样才能让密码在最大程度上做到信息不泄密呢？从上述原理可以看出，就是要将原本有规律的信息，变成看似毫无规律，随机分布的编码。这时候，无论敌方怎么处理收到的密码，获得的信息都近乎为零。 但是，做到将原本有规律的信息随机化这件事，说起来容易做起来难，因为它不是真的随机的，而是伪随机的，是让敌方觉得是随机，而我方其实知道背后的算法或编码原则。如果说真的随机，我方自己也读不出原来的信息了。 — location: [2304]() ^ref-38785

---
那么是否有永远无法破解的加密呢？有的，那就是使用一次的加密密码。 — location: [2315]() ^ref-15730

---
为什么重复使用的密码不安全。 我们可以把加密的过程看成是这样的：明文+密码=密文。 在加密的过程中如果给定明文和密码，你一定能得到唯一的密文；但是对于破密的人来讲，这个过程的逆过程非常困难，也就是说给你最后的密文，你是无法倒推出明文和密码的。 这 — location: [2317]() ^ref-8125

---
那么破密是怎么进行的呢？从原理上讲，如果一个密码重复使用，某些明文和密文的对应恰好又不小心被泄露了，对方就可能倒推出密码，于是整个密码系统都被破解。虽然在密码破译之前很难找到明文和密文的对应，使得密码在一段时间里是安全的，但是对方可以设计圈套，获得这种对应。 — location: [2321]() ^ref-1268

---
但是，如果密码只用一次，就不会有这个问题，以后的加密不会因为一次失误泄露而被破解。 — location: [2329]() ^ref-8615

---
比如，二战时在中途岛海战之前，美军截获的日军密电经常出现 AF 这样一个地名，应该是太平洋的某个岛屿，但是美军无从知道是哪个。于是，美军就逐个发布与自己控制的岛屿有关的假新闻。 当美军发出“中途岛供水系统坏了”这条假新闻后，从截获的日军情报中又看到含有 AF 的电文（日军的情报内容是 AF 供水出了问题），美军就断定中途岛就是 AF。事实证明美军判断正确，于是在那里成功地伏击了日本联合舰队，并一举扭转了太平洋战争的战局。 — location: [2324]() ^ref-6041

---
我们说量子通信是安全的，就是因为它是使用一次性密码。 — location: [2330]() ^ref-3549

---
保护隐私的一个很好的办法，就是将隐私埋藏在随机的噪音中。 — location: [2337]() ^ref-54747

---
如果你想让人知道你的观点，就要明确表述。反之，你的表述就应该让对方得不到任何信息量，但也不要误导别人。 比如对方问你是否愿意支持他竞选学生会主席，你不想支持他，又不好明说。该怎么办呢？ 如果他一开始对此的期望值是 7 成支持，你说出去的话，还应该让他维持这个期望值。如果你让他觉得是十成支持，回头你又不支持，这是误导他，过后他会翻脸。 反之，你发表你的看法后，让他觉得是三成支持，这是比较明确地表达了你的否定态度，他当场就会不高兴。如果你说了一大堆的话，维持了他事先的想法，这其实没有传递出任何的信息，是最不得罪人的做法。 — location: [2343]() ^ref-22371

---
1.密码的精髓在于，对方拿到你的密文，得不到额外的信息。要让对方获得了密文后，也无法减少你传递的信息的不确定性。 2.保护自己隐私的办法也在于此。如果你不想给对方提供任何信息，最好的办法就是让他对你的猜测在得到你的信息前后不产生任何变化。 3.一次性密码最安全。虽然我们不能做到每次通信都更换密码，但是至少能够做到不同网站使用不同密码。当然，如果你要给人一个委婉推却的借口，最好每次找一个不同的理由。 — location: [2350]() ^ref-50673

---
设备要能通信还需要让它们都遵守一套大家都认可的信息编码规范，这就是通信标准，这就如同发电报有标准的电报码一样。没有标准，彼此就没法沟通，是鸡同鸭讲。 — location: [2367]() ^ref-9651

---
通信的标准中有两部分最重要，一个是对信息的发送和接收的描述，比如打电话时大家的电话号码；二是对信息编码的方式，比如文字就是对信息的一种编码。 — location: [2369]() ^ref-12469

---
好的信息编码能保证信息的传输率尽可能高，接近信道的容量。在移动通信的发展过程中，每隔十多年，就会出现新一代的通信标准。当然，谁掌握了标准，谁就掌握了行业的制高点。 — location: [2370]() ^ref-22832

---
从技术上讲，1G 是模拟电路的，2G 是数字电路的。 从外观上看，2G 的手机比 1G 小很多，更省电，而且收发短信方便。 为什么 2G 的手机小？因为数字电路可以把更多的数字芯片集成起来，用一个专用芯片就取代了过去上百个芯片。而在摩尔定律的影响下，这种技术进步的叠加效应更明显，就越做越小。 于是 2G 取代 1G 就成为了历史的必然，诺基亚是那个时代的领航者。如果我们沿用《科技史纲 60 讲》中衡量技术进步的标尺来衡量，从 1G 到 2G，单位能量处理信息的能力提高了百倍。 — location: [2375]() ^ref-45074

---
2G 的手机只能打电话发短信，上网很困难。3G 的通信标准将信息的传输率提高了一个数量级，这是一个飞跃，它使得移动互联网得以实现，从此手机打电话的功能降到了次要的位置，而数据通信，也就是上网，成为了主要功能。 但是，从 1G 到 3G 都存在一个大问题，那就是上网用的移动通信的网络和原有打电话用的通信网络虽然能够彼此融合，但是却彼此独立。 今天的人回过头来看这件事会觉得有点荒唐，但是如果我们了解了当时移动通信和以 AT&T 为代表的传统电信公司是多么地水火不容，就不难理解这一点了。 这就使得独立的移动网络就无法受益于网络技术的快速进步。2G 和 3G 时代用手机打一个电话实际上经过的物理路径很长。 — location: [2381]() ^ref-51100

---
一方面基站和基站之间的通信效率并不高，使得上网速度快不起来；另一方面，由于在2G时代为了适合当时移动通信的特点，手机端到端的通信要经过好几级的转发。手机信号送到基站后，要经过基带单元（BBU）、无线网络控制器（RNC），才能到核心网，然后再从核心网到RNC、BBU，最后送到基站，基站再与接收者通信。 因此，由于 3G 的系统是半吊子的，虽然标称的网速很高，但是实际网速并不快。于是 4G 很快出现了。 — location: [2389]() ^ref-2742

---
4G 有什么革命性的进步呢？有人说是网速快。但这是结果，不是原因。4G 一方面使用了扁平的网络结构，减少了端到端通信时信息转发的次数，同时增加了基站之间光纤的带宽。 更重要的是，它同时利用了互联网和电信网络的技术进步，这两种技术的融合才使得 4G 的速度比 3G 快很多。你可以认为，到了 4G，电信的网络已经统一了，但是它和互联网还没有完全统一，你先记住这个事实。 虽然在 4G 时代从理论上讲移动通信的网速可以变得很快，你今天能够想到的所有应用都是够快的。但是，如果很多人同时上网，它不仅不够快，甚至连不进去。 2018 年我在杭州开全国计算机大会，参会者近万，在会场上无论是 4G 还是 Wi-Fi 都不大管用，你如果拍一张照片想在朋友圈中分享，那么能否分享成功，全靠运气。这一方面是因为总的网速不够快，另一方面是很多人要同时和基站通信，基站成为了瓶颈。 比如一个基站覆盖半径一公里的范围（基站之间的距离通常在 2～3 公里），通常这方圆一公里范围内的人不会同时上网，因此分给每个上网的人的带宽是够用的，但是当大家都要发照片时，总的传输率超过了信道的总的带宽，根据香农第二定律，出错率是 100%，于是大家都传递不了信息了。 — location: [2393]() ^ref-13281

---
公平地讲，4G 对于我们目前的上网需求绝大部分时候是足够了，但是在未来我们有很多智能设备，它们也要同时上网，就会出现像前面说的那种“会场拥堵”的问题。 那么怎么解决这个问题呢？有人会想到继续增加带宽。这是一种自然而然，颇为合理的想法。虽然在 4G 的基础上增加 2～3 倍的带宽并非难事，但如果想增加 1～2 个数量级就办不到了。 那一方面要求基站的功率增加很多，这在城市里完全不可行，因为基站周围会因为电磁波辐射太强而变得很不安全。另一方面，要想增加带宽，就要增加通信的频率范围，无线通信的频率无法向下扩展，只能向上扩展，也就是让无线电波的频率增加。 我们知道无线电波的频率越高，它绕过障碍物的能力就越差，比如说它高到可见光的频率时，你随便用张纸，用块布就能挡住它。因此在城市里高楼会严重影响通信。 那么怎么办呢？最简单的办法就是在提高通信频率的同时，把基站建得非常密，这样在你的附近就有基站，它不会被建筑物所阻拦。 基于上述想法，5G 的概念就被提出来了。5G 是如何进行无线通信的呢？如果我们说 4G 是一公里的范围建一个基站，负责这方圆一公里范围内的手机和基站的通信，那么 5G 则是在百米的范围内建基站（今天的方案是基站距离平均在 200～300 米左右），负责半径为一百多米范围内的通信。 — location: [2404]() ^ref-39118

---
手机和基站的距离缩短，会带来三个好处。 首先是建筑物干扰的问题得到解决，这是显而易见的。 其次是更少的人分享带宽。我们假定方圆一公里范围里的人口是1万人，那么方圆百米范围内就会下降到100人。这样每个人能够分到的带宽就可以增加两个数量级。 最后，由于基站的通信范围可以从1公里减少到100米，功率可以降低两个数量级，这样，在基站周围电磁波辐射也会大大降低，我们生活的环境反而变得安全了。 当 5G 的基站密集到两三百米甚至不到一百米一个的时候，我们家里是否还需要安装 Wi-Fi 呢？或许不需要了，Wi-Fi 或许会消失，或者会退居次要的地位。这样，就将互联网和通信网络融合成一个网络了，这无疑将是一次通信的革命。 — location: [2416]() ^ref-58102

---
总结一下从 1G 到 5G 的革命性变化。 1G的诞生。 从1G到2G，是从模拟电路到数字电路，由于采用了专用集成电路，单位能量传输和处理信息的能力提高了两个数量级。 从2G到3G，实现了从语音通信到数据通信的飞跃。 从3G到4G，实现了移动通信网络和传统电信网络的融合，将云计算等互联网技术用于了移动通信，使得不同区域之间的流量能够动态平衡，大大地提高了带宽的使用率。 从 4G 到 5G，可以实现移动互联网和有线的互联网的彻底融合。当然，万物互联才会成为可能。需要指出的是，由于网络基站的密度非常高，每一个基站的功率非常小，因此单位能耗传递信息的效率会进一步大幅度提高。 — location: [2423]() ^ref-58429

---
首先，如果基站的距离缩短到 200～300 米，单位面积的基站密度比 4G 就要增加 100 倍，这是一个巨大的国家级的基础架构建设，因此从事基础架构建设的企业都是受益者。你或许已经听到这样的消息，5G 的传闻一出，制造电线杆子企业的股票已经开始疯涨了。 其次，任何致力于将各种网络融合的努力都是顺势而为，任何试图搭建一个独立的，单纯基于无线技术的努力都是逆流而动。几个月前，一些国家决策部门的领导问我，以现在的技术再开发类似于铱星的通信系统，是否可行？我说完全没有必要，因为那是逆流而动。从 1G 到 5G，将各种网络融合是一个大趋势。 — location: [2431]() ^ref-4851

---
半个多世纪以来移动通信的发展历程。对于这段技术发展的历史，你只要记住四个要点即可： 1.单位能量的信息传输率越来越高； 2.网络不断融合； 3.设备的辐射越来越小； 4.每一代都会有新的主导型公司出现，1G是摩托罗拉，2G是诺基亚，3G、4G是苹果、谷歌和高通，5G是华为。 — location: [2444]() ^ref-6311

---
5G 的一个应用，是让多个设备长期同时上网，而 IoT 恰好可以利用 5G 移动通信的这个成果。 — location: [2464]() ^ref-58092

---
第一代互联网从本质上讲是计算机和计算机的联网。互联网诞生于 1969 年几台计算机服务器的联网。虽然后来它不断扩大，并且演化成个人的电脑通过服务器彼此相连，但依然是机器和机器相连。 每一个使用互联网的人，只有坐到计算机前，甚至在登录互联网之后，才算连到网上。当我们离开计算机，比如下班开车或者坐地铁，我们就离开了互联网。直到你吃完晚饭，做完家务事，再坐回到计算机旁边，才算又和互联网相连了。 第二代互联网是我们今天使用的移动互联网。它从形式上讲是移动设备，主要是手机，通过空中的无线电信号相连，但是从本质上讲它是人和人的相连。我们加一个微信好友，扫一个商家的二维码，不是为了让你的手机能够连接上对方那台手机或者服务器，而是要随时找手机背后的那个人。 — location: [2469]() ^ref-20824

---
1.万物互联之后，联网设备的总数会极大地提高。 从第一代互联网，即 PC 的互联网到第二代互联网，即移动互联网，上网的设备数量增加了半个数量级，即 3 倍左右，从 10 亿增加到今天的 30 亿。而到了万物互联的时代，联网的设备数量最保守地估计，也有 500 亿，比今天增加了一个多数量级。 更重要的是，我们人也会成为万物互联的一个节点。最后这一点非常重要，它可以非常有效地预防疾病。 — location: [2479]() ^ref-22930

---
2.这么多设备来了，就带来了那个问题。首先是上网的带宽不够了，这就让 5G 成为必需品。其次是为 500 亿个设备经常更换电池显然不太现实，这就要求 IoT 设备采用比今天移动设备功率更低的芯片，最好很多设备终身（比如 10 年）不需要更换电池，这就会导致新一代半导体公司的兴起。 3.万物互联形成的市场规模，要比前两代互联网大得多。 2018 年，全世界互联网企业的收入是 4000 多亿美元，这里面既有 PC 互联网的收入，也有移动互联网的收入，也就是说，第一代互联网的收入远低于这个水平。 但是同时期，通信产业的收入却是 4 万亿美元左右，几乎高出了一个数量级。虽然这里有传统电信的存量，但是有很大一部分来自于移动互联网。这说明移动互联网的市场规模比第一代互联网大得多，几乎大出了一个数量级。 到了万物互联，也就是第三代互联网的时代，这么多的设备连入到网络中，形成的经济规模是极为可观的。 — location: [2483]() ^ref-29839

---
最保守地估计，到 2030 年，应该能够让今天电信市场规模扩大一倍，即从目前的 4 万亿美元左右达到 7 万亿～8 万亿美元，甚至更多。要知道今天日本的 GDP 才 4 万多亿美元，如果说增加出一个日本 GDP 的产业，那么商机是多么地巨大不言而喻。 巨大的商机并不等于每一个人都能获得同等的受益机会，那么谁有可能从万物互联中受益呢？为了看清楚这一点，我们不妨看看第一代和第二代互联网的产业结构。 在第一代互联网时期，最重要的设备就是 PC 机和服务器，当时互联网本身的那点收入相比设备的收入小得可怜。而谁是那时候设备的受益者呢？不是生产计算机的惠普、戴尔和联想，而是控制这个产业绕不过去的两个环节，微软和英特尔。 — location: [2491]() ^ref-61353

---
因此那个时代也被称为 Wintel 时代，即（微软的）Windows，加上英特尔（的处理器）。在 PC 互联网时代，你可以自由地选择计算机、打印机、硬盘或者应用软件，甚至可以选择通过哪家公司上网，但是微软和英特尔的两个环境绕不过去。 — location: [2498]() ^ref-57270

---
到了第二代互联网时期，最大的受益者无疑是控制操作系统的 Google 和控制处理器的 ARM。你可以购买不同的手机，选用不同的屏幕，还可以选择不同的移动运营商，但是 Google 和 ARM 这两环是绕不过去的。 — location: [2500]() ^ref-30265

---
这里面有一个小问题，为什么微软和英特尔在第二代互联网时期就失去控制力了呢？因为它们的操作系统和处理器太耗电，不符合提高单位能量处理更多信息的发展趋势。 — location: [2502]() ^ref-10870

---
到了第三代互联网，即万物互联的时代，情况也是如此，谁控制了处理器和操作系统，就会是最大的受益者。 — location: [2504]() ^ref-8866

---
我们在前面讲了新一代的 IoT 芯片的能耗必须足够低，今天用于手机的芯片都达不到这个要求。这就给诞生新的半导体公司提供了发展空间。接下来，还是需要有一个合适的操作系统，将这么多设备管理好，这个目前还没有。 — location: [2505]() ^ref-53817

---
要点小结◆──── 互联网经历了两代，IoT也就是万物互联可以算是第三代。 每一代互联网比上一代，从设备的数量和市场的规模，都会有巨大的增长，这是未来的机会所在。 每一代互联网都有掌握产业链的龙头公司，从PC时代的英特尔和微软，再到今天的ARM和Google，以及未来掌握核心芯片、操作系统和通信标准的公司。 由于大公司改变基因是几乎不可能的事情，因此在IoT产业链的各个环节会出现一批新的公司，从操作系统、处理器，到设备和配件。很多人觉得自己错过了加入到小米等企业发财的机会，但是不用着急，在万物互联逐渐发展的过程中，还会有新的小米出现。我时常讲，亘古而长青的昨天，永远是过去，也永远会再来，就是这个道理。 从能量的角度讲，每一代互联网都是以更少的能量传输和处理更多的信息，这一点是未来发展的方向。大家可以根据这个规律判断哪一家企业契合IoT的发展。 — location: [2519]() ^ref-10936

---
如果你是一个学生，如何利用 IoT 提高学习成绩？如果你是一个上班族，如何利用 IoT 节省时间？ — location: [2529]() ^ref-24664

---
历史的轮廓其实讲的是另一回事，各种历史事件，各方面的作用形成一种合力，影响了历史的进程，中间有很多细节的因素，并非所有的细节因素都能搞清楚，有些即使能够搞清楚，成本也很高。但是，这些因素加在一起，轮廓是清晰的。 — location: [2549]() ^ref-50543

---
吴老师，用2G和4G手机，来比喻个人信道的潜力大小，令我深有感触。对于学渣来说，只能通过降低传输率来接受信息，也就是不断地终生学习，弥补知识。但是，如果我们想拓宽自己认知的信道，有可能吗？请吴老师给予指点。 我们现实中带宽一定是有边界的，个人用哪些方法可以更好地拓宽带宽？ 吴军 这个问题很大，答案也是因人而异的。简单地讲，有这样三个原则可以供大家参考： 在年轻的时候，或者事业刚开始起步的时候，以增加技能为改进的核心，以融入社会为基础。 有了足够的专业技能，对社会有了了解之后，以增加见识为改进核心，以提供价值为目标。 再往后，以洞察大势为核心，以理解多元文化为基础。 — location: [2589]() ^ref-18009

---
当然，最后，不论走到什么高度，都要常怀敬畏之心，在边界里做事情。 — location: [2596]() ^ref-19599

---
核心的内容是香农第二定律，当然，我们大部分人是把它用在人与人的沟通中，而非真正去做通信的产品。 在这个模块一开始，我们先介绍了噪音，以及它对通信的影响。我们特别强调了噪音是我们这个世界的固有特征，不要指望存在没有噪音的信息，也不要指望不受噪音干扰的传输。 我们在真实的世界里做事情，就要有一个世界不完美的假设，然后练就在不完美的世界里尽可能做好事情的本领。 — location: [2599]() ^ref-64641

---
承认各种噪音的存在，争取在有噪音的情况下，准确传递信息。 由于有噪音的存在，信息传递的速率就要受到影响。而香农在研究信息论时，就是以噪音信道为前提假设的。他关于信息传输的核心，是他的第二定律。这个定律说的是这样一件事，信息的传输速率不可能超过信道的容量。因此，如果我们在人与人的沟通中想要变得顺畅，就必须想办法增加信道容量，否则信息的传输就会很快遇到瓶颈。 — location: [2607]() ^ref-5276

---
另一方面，如果信道容量有限，最好的做法是降低信息的传输率，以便保证信息的传输依然能够持续，而不是急于一次传输太多的信息，因为那样一来，出错的概率为 100%，什么信息也传递不下去了。 那么信道的容量（或者说带宽）又是由什么决定的呢？香农讲了，它取决于发送和接收方彼此之间的互信息。 — location: [2611]() ^ref-8985

---
鉴于信息传输的这个特点，我们在与他人的沟通中应当注意这样几个要点： 1.如果我们需要经过他人传递信息，比如你要托人向领导带个话，要特别挑选那些带话不走样的人，而并非简单地和你关系好的人。所谓带话不走样，就是指你讲的话，和他理解的意思之间互信息很大，而他向领导表述出来的意思，和领导的理解，互信息也很大。 很多人喜欢找自己熟的人带话，这当然没有错，因为毕竟面对熟人，你讲话可以比较随意，但是决定那些话能否让他带不取决于你们是否熟，而取决于他作为信道的能力。而这个能力在今天的生人社会里，其实非常有价值。 — location: [2615]() ^ref-17781

---
连接比拥有更重要，那些能够带话的人，就是连接所在，你如果具备了这个能力，在一个机构中就显得特别有价值。 为了增加信息沟通的带宽，我们常常还需要准备好多个信道，以便万一某些信道受阻后，信息还能有效地传递出去。我们常常讲“人脉”这个词，人脉其实就是信道。 所谓人脉宽，就是指我们有能力很快地把这种信息收集进来，或者传递出去。 — location: [2621]() ^ref-50856

---
2.在表达意思时，一定要看听众是谁，用不同的方式去表达。表达的速率，取决于听众接受的能力。采用有针对性的方式，是为了增加你和听众之间的互信息。控制速率，是为了保证信息传输的速率不超过信道的容量，这样可以不出错。 我们经常在职场上看到一些人对所有人说话都是同一种方式，同一种语言，他们还标榜自己率真，其实这种人信息传递的效果很差，因为他们和听众之间互信息很低。 类似的，你还会看到一些人表述信息时像竹筒倒豆子一样都倾泻出去，他们恨不能将自己所知在最短的时间里都告诉对方。这种时候，他们信息传播的速度已经超过了信道容量，对方接收的信息一定有错。 选择学校，要选择一个适合自己的，不用一心往学霸的圈子里扎。很多家长觉得，孩子和学习好的学生们在一起，自己也会被带好，这一点完全没有错。但是，好的学生，可以是学习态度好的，学习方法好的，未必需要是脑瓜极好的学霸。 一个资质中等的学生，和一群接受能力极强的学霸在一起，未必有多大的收益，因为在那个环境中，老师教得会很快，内容也会比较深，大部分学生接受起来没问题，想方设法挤进那个群体的学生会很痛苦。 — location: [2624]() ^ref-5930

---
3.从上一点出发，也给家长们一个建议。由于两代人之间的代沟是客观现实，也就是说家长和孩子之间的互信息通常难以达到最大，因此和孩子沟通要么需要非常慢，非常有耐心，要么家长自己想办法增加和孩子之间的互信息，也就是说增加带宽。 我出版了《态度》一书，也就是给孩子的家书之后，很多人问我为什么要给孩子写信（其实是邮件），而不打电话说。原因是读信件是一个慢速接收信息的过程，这样能将信息的传输率控制在我和他们通信带宽以内，保证想法的传递不失真。 — location: [2638]() ^ref-25734

---
4.在男女朋友之间和夫妻之间的沟通上，要在对等的条件下进行。有些人觉得，我条件好，你条件差，你跟着我高攀了；或者我条件差，对方条件好，我一定要迁就他（她）。 这样的关系很难长时间稳定，因为这样的话他们对很多问题的看法完全不同，互信息近乎为零，彼此沟通的信道太窄。 俞敏洪老师讲过很多次，夫妻双方关系出现问题通常是因为，双方在认知上的差距逐渐地越来越大，以至于无法沟通。所谓认知的差距大，就是信息论所说的信道太窄。 — location: [2645]() ^ref-48204

---
我们在前面的课程中说了扁平化管理的好处。我们考察一个机构的管理结构是否合理，应该看信息能否有效传递，而并非绝对层级的多少。层级本身是手段，不是目的，信息的有效传递，以及合作的达成，才是目的。 我们在课程中列举了很多虚假的扁平化管理，它们表现为层级过于分明，部门的边界过于明显，每一个中层干部都是关键节点，能够阻拦上下级的沟通。 我们还举了一个例子，说明一些管理层级看似非常平的单位，其实并不是真正的扁平化管理。当一个领导的直接下属有几百人时，他就是信息传递的瓶颈，原本可以做到的并行管理，反而变成了串行的。 — location: [2650]() ^ref-4434

---
并非所有的互联网企业作为中介的作用都一样，只有那些能够建立起商家和买家之间彼此信任的网站，才有商业价值。因为只有信任存在，商家和买家之间才有互信息可言，才存在所谓的带宽。 在这个模块的最后，我们谈到了 5G 的内容，特别谈了技术的发展和它的特点。我们特别强调了从 1G 到 5G，除了单位能耗信息的传输率越来越高，网络也是越来越融合，而不是自成一体。 这样做有什么好处呢？因为统一的网络可以让信息传递的路径变短，从而变相拓宽带宽。而网络的统一，在技术上则体现为通信协议的一致性。 不仅在通信中有网络融合的问题，在一个机构中也有。很多单位里有小团体，它们就好比相互之间信道很窄的子网络。如果小团体发展得太强大，单位从整体上就会变得比较虚弱，甚至名存实亡。 而打破小团体界限最有效的办法，就是大家认可一个相同的内部通信协议，这种通信协议，就是企业文化和行为规范。如果大家都按照企业整体的行为规范进行交流和合作，而不是小团体自身的规矩做事，整个机构就成为了一个有机的整体。 因此，一个企业好的创始人和 CEO，会把树立企业文化和制定行为规范作为首要任务，而不是事必亲躬地做每一件事情。 — location: [2658]() ^ref-12136

---
在我们的生活中，绝大部分时候，一个维度的信息是很难消除所有不确定性的，而解决这个问题最好的办法，不是把那个维度的信息搞得更准确，而是要用其它维度的信息进行交叉验证。 — location: [2687]() ^ref-10899

---
交叉验证是我们每一个人必须掌握的做事方法，它可以让很多难题迎刃而解。在中国的历史学界，王国维的地位极为崇高，因为他开创了历史研究的新时代。 在王国维之前，几乎所有的学者在治学时，都是采用考据和集注的方式，也就是说通过研究史料来还原历史，然后写上自己的看法，后面的学者再从前面学者的注释中得到启发，继续研究。 由于溯源之后，大家其实使用的都是相同源头的信息，即便各自有各自的看法，也很难还原历史的真相。很多时候，甚至成了以讹传讹。 王国维先生治学的方法则不同，他通过考古（比如研究新挖掘出来的甲骨文）来发现新的史实，然后用考古得到的信息和文献记载中的信息进行交叉验证，也就是“二重证据法”，如果它们能得到相同的结论，说明是可信的，否则存疑。 — location: [2693]() ^ref-15618

---
我在《智能时代》一书中花了很多篇幅来解释“大数据”和“大量数据”其实是两回事，前者是多维度的，后者可能只是数据的体量大，并不等于信息多。 — location: [2720]() ^ref-15891

---
信息的等价性条件其实是很严格的。如果我们说 Y 等价于 X，那么从 Y 就能完全推导出原本需要 X 才能得到的信息。信息的等价性和信息的相关性不同，找相关性的要求要宽松得多。 — location: [2780]() ^ref-62647

---
相关的信息有用，但是不像等价的信息那么具有确定性。 — location: [2783]() ^ref-21834

---
比如，我们说气象云图的形状分布，空气的气压、湿度和下雨有关，那只是有关，我们无法从前面几条信息完全确定是否下雨。这就是相关性，而非等价性。相关的信息有用，但是不像等价的信息那么具有确定性。 — location: [2782]() ^ref-58190

---
─◆要点总结◆──── 很多时候我们无法直接获取某种信息，于是我们提供了一个使用等价信息解决问题的方法。 — location: [2820]() ^ref-45283

---
等价信息和相关信息不同，后者的要求宽松得多，但是可靠性也差很多，因此采用不同信息源的信息进行交叉验证是必要的。 — location: [2823]() ^ref-27630

---
人类的活动会留下痕迹，无论是物理的真实痕迹，还是写作等习惯，它们可以几乎准确无误地还原我们自身的很多信息。因此在大数据时代，要保护隐私其实很难。 在过去，有些信息的跟踪和处理成本较高，但是有了人工智能，这件事也很容易，比如我所说的确认一部作品的作者。 — location: [2825]() ^ref-29700

---
首先，大数据要求数据量大，这一点大家没有疑问。数据量小一定不符合大数据的原则。至于数据量多大合适，我们在前面介绍了置信度的概念，数据至少要大到让统计的结果具有非常高的置信度。 — location: [2847]() ^ref-60546

---
其次，大数据需要具有多维度的特征，而且各个维度最好是正交的。 — location: [2849]() ^ref-17571

---
大数据第三个重要特征，是数据的完备性，它在过去常常被人忽略，因为人类过去使用数据，都是采用抽样的办法来获取，根本不可能做到完备。抽样统计有一个问题，就是总有 5%左右的小概率事件覆盖不到，如果最后运气不好，正好落在那 5%，统计的方法就失去作用了。 今天情况就不同了，因为收集数据的设备无所不在，我们也在有意无意向它输送数据，因此获得完备的信息完全可能，这样一来就堵住了采用数据作预测的死角。 — location: [2865]() ^ref-53804

---
大数据的4个明显的特征，即数据量大、多维度、完备性和在一些场景下的实时性。我们特别强调了光是数据量大还不能构成大数据，因为它可能无法得出有效的统计规律，而多维度的特征则让我们可以交叉验证信息，提高准确性。 大数据的威力大家都看到了，那么可能有人要问，有了大数据，我原来从事的行业是否会消失？其实大部分行业不会很快消失，但是可能会以另一种形式出现。而具有行业知识的人要做的，就是用所谓的领域知识建立起不同维度之间信息的桥梁。 当大数据维度非常多之后，就会出现矛盾。 — location: [2884]() ^ref-37954

---
消除数据之间的矛盾，也需要领域知识。因此在一个行业里从业很长时间，具有专业知识的人，不仅不会被大数据取代，而且有可能利用好大数据，在事业上更上一层楼。在未来的时代，有三类企业会受益于大数据。 — location: [2893]() ^ref-24299

---
说到大数据，就不得不说说它的英文名称 Big Data。不知道你有没有想过，它为什么叫 Big Data，而不叫 Large Data，或者叫 Vast Data、Huge Data，等等？Large、vast 和 huge 都是指体量大，在程度上，后二者可以看成是 very large 的意思，比 large 更大。 但是，Big 和它们的差别却在于它是强调相对抽象意义上的大，而并非具体的。 比如说，“Large Table”常常表示一张桌子尺寸很大，而如果说“Big Table”并不强调尺寸，只是要强调已经称得上大了，比较抽象。因此，仔细推敲 Big Data 这种说法，我们不得不承认它非常准确，最重要的是它传递了一种信息——大数据是一种思维方式的改变。 — location: [2909]() ^ref-6435

---
量变会带来质变，那常常是在一个维度上说的，而今天我们说大数据思维，已经超出了这一层含义，是一种全新的思维方式和做事情的方法。 今天大部分人所理解的大数据，是从大量的、看似杂乱无章的数据点，总结出原来找不到的相关性。在这个过程中各种数据如同百川入海一般汇聚到一起。 — location: [2915]() ^ref-25455

---
我们需要强调的是，大数据思维和过去通过大量数据验证一件事还是有区别的。那就是由于这些数据在产生和收集时是没有特定目的的，因此怎样使用它们，则需要视特定的应用而定。 比如 Google 趋势这个产品就用到了大数据，由于收集数据事先没有目的性，从这些数据中能够得到什么结果事先也不知晓，这让它发现了很多过去没有想到的规律。 — location: [2919]() ^ref-32275

---
相比过去那种从病理出发分析原因，再寻找和研制药物的正向过程，今天这种做法其实是先有了结果，再反推原因，是一种逆向的做法，但是正是因为有了足够的数据支持，它无疑会比较快。不事先作假定，从大数据出发先得到结论，再分析原因，这是大数据思维的第二层。 — location: [2936]() ^ref-26093

---
为了便于你理解第二个方向的信息流动，我不妨给你讲一个我亲身经历的例子。硅谷地区的一个连续创业者，我们不妨称之为 D 先生吧，他在一次创业中挣到了第一桶金，于是在几年前大数据比较热门时，他又开始了新的一次创业。他发现，在美国一半小型服务企业，特别是餐馆、酒吧等，寿命不超过五年，很多不超过 18 个月。于是他花了一年的时间，调查了美国酒吧行业的情况。D 先生发现，酒吧之所以经营不下去，除了一般所说的经营不善，更重要的是大约 23%的酒都被酒保们偷喝了。 那么酒保们是如何偷喝掉将近 1/4 的酒的呢？D 先生讲，其实很简单，主要是酒保们趁老板不在的时候偷喝酒，或者给熟人朋友免费的和超量的酒饮。由于每一次的交易的损失都非常小，不易察觉，因此在过去，酒吧的老板平时必须盯得紧一点，如果有事离开一会儿，只好认倒霉。 开过小餐馆的人都会有这样的经验，自己是否在店里看着，对营业额的影响特别大，因此做这种餐饮买卖的人特别辛苦，稍微不注意就开始亏损。 D 先生针对酒吧老板的这些麻烦，利用大数据和 IoT 设计了一套解决方案。他把酒吧的酒架改造了，装上了可以测量重量的传感器，以及无源的射频识别芯片（RFID）的读写器，然后再在每个酒瓶上贴上一个 RFID 的芯片。 这样，哪一瓶酒在什么时候动过，倾倒了多少酒都会记录下来，并且和每一次的交易匹配上。每一笔交易，酒吧的老板都可以用平板电脑查询，因此即使出门办事也可以了解自己酒吧经营的每一个细节。 D 先生对酒吧的改造带来了一个额外的好处，就是积累了不同酒吧，长时间经营的数据。在这些数据的基础上，他可以为酒吧的主人提供一些简单的数据分析。我把他提供的服务概括起来，包括这样三方面： 首先，每一家酒吧自己过去经营情况的统计数据，这有助于酒吧的主人全面了解经营情况。在过去，像酒吧这样传统的行业，业主其实除了知道每月收入多少钱，主要几项的开销是多少，对经营是缺乏全面了解的。至于哪种酒卖得好，什么时候卖得好，全凭经验和自己是否上心，没有什么分析。D 先生提供的数据分析让这些酒吧老板首先对自己的酒吧有了准确的了解。 第二项服务是，提供每一家酒吧异常情况的预警。比如 D 先生可以提示酒吧老板某一天该酒吧的经营情况和平时相比非常反常，这样就可以引起酒吧老板的注意，找到原因。在过去，比如某个周五晚上的收入比前后几个周五少了 20%，老板们一般会认为是正常浮动，也无法去一一检查库存是否和销售对得上。有了 D 先生提供的数据服务，这些问题都能及时发现。 除此之外，第三个服务是各家酒吧数据的收集和分析，D 先生会提供这个行业宏观的数据给酒吧老板们参考。比如从春天到夏天，旧金山市整体上酒吧营业额在上升，如果某个特定酒吧的销售额没有增长，那么说明它可能有问题。 再比如，D 先生还可以提供各种不同酒的销售变化趋势，比如从春天到夏天，啤酒的销量上升比葡萄酒快，而烈酒的销售平缓等等。这样有助于酒吧老板们改善经营。 2013 年，D 先生从硅谷几家风险投资基金获得了融资。利用大数据在准确把控宏观规律的同时，精确到每一个细节，这是大数据思维的第三层。 大数据思维的第四个层次，是通过几个维度的强相关性，替代过去的因果关系。 — location: [2943]() ^ref-56490

---
有了互联网，广告就可以发挥自身的灵活性，成为能够触及更多的受众，成本较低的互联网广告，使得小商家受益。于是电子商务得到了发展。 假如你是一个做电商的，你会怎么利用互联网来打广告呢？那么多种互联网广告，哪种效果最好呢？具体到哪家媒体或者网站上去做呢？ 我们先说一下结论， Google 的搜索广告优于 Facebook 的个性化展示广告，后者优于一般的展示广告。 — location: [2996]() ^ref-45207

---
先说 Google 的搜索广告，它是和 Google 的引擎相伴随的。Google 的搜索引擎中收录了大约几十亿个常用的网页和上千亿个其它网页，当然它还有近千万的广告主以及几千万种广告。为了聚焦，我们只关注它几十亿个（我们假定为 40 亿）常用网页和几千万种广告。 如果我们要从 40 亿个网页中找出自己最需要的那一个网页来，需要多少信息呢？如果每一个网页大家查找的频率相同，那么从 40 亿中选 1，需要 log（40 亿）=32 比特的信息。 但实际上，有些网页大家查找得越频繁，是你想要的那个网页的概率越大，所以根据这个频率计算信息熵，其实不需要 32 比特。我们假设，需要大约一半信息，即 16 比特就够了。 另外，我们还考虑到用户的浏览器所使用的语言，比如英语最广泛，那么划定范围又小了一些，又可以节约一些所需信息，这时候我们估计大约需要 12 比特信息。 好，这时候，你在搜索框里输入的关键词，能减少这 12 比特的信息熵吗？要知道，在英语里，一个表达意思的英语单词，（即排除 the，a，is 等使用太频繁，但没有鉴别力的单词）平均大约只有 6～8 比特信息。 因此，你如果用两个关键词，通常可以保证你所要找的内容排在第一位。当然，这几个关键词所提供的信息最好是正交的， — location: [3001]() ^ref-57838

---
对于中文，情况也是差不多。一个汉语的两字词，大约有 8～10 比特的信息，于是你用两个两字词，在 Google 上基本上可以确定那个你唯一要找到的网页。 理解了搜索的信息论原理之后，我们现在转换一下身份，假定自己是广告主，要投放广告了，看看怎样利用用户在搜索时提供的信息找到广告的受众。要知道，广告是一种商业信息，虽然它和钱相关，但是如果我们不考虑内容，只看信息量，它和网页搜索没什么差别。 在中国，Google 和百度广告主的数量在几十万到百万这个量级，但实际上，很多广告主把预算花光了后，就不再及时续费了，此外还有一些广告主的广告质量很差，点击率不高，我们也暂时不考虑。 于是，我们假设有 12 万广告主要做广告，要想让用户从中把你这一家商店选出来，信息熵（不确定性）是 17 比特。 如果你不清楚任何用户的需求，那么只好随机做展示广告。在历史上，展示广告效果从来都不好，原因就在于它无法消除不确定性，在这里就是 17 比特的信息熵没法消除。因为展示的广告和读者的意图无关，读者偶尔的点击也只是好奇和不小心。 据京东主管广告的负责人颜伟鹏先生介绍，在门户网站上做展示广告，获得一个用户的成本可以高达 10000 元以上，做那种广告完全得不偿失。 — location: [3013]() ^ref-47775

---
那么搜索广告的效果怎么样呢？由于用户在搜索时提供了信息，表达了他这一次搜索的目的，因此，广告就好做了。 如果我们还是假设用户搜索的关键词是两个词，每个词平均两个汉字，通常这两个词提供的信息是正交的，根据汉字词平均的信息量，这两个词大约提供了 16～20 比特的信息，基本可以消除 17 比特的信息熵。 对 Google 来说，已经可以确定该显示哪一个广告了。也就是说广告和用户的需求其实完全匹配了。 这样，广告的效果就好很多，当然搜索广告也因此收费高很多。Google 通常可以做到 30 美元，甚至 50 美元以上的 RPM，百度也能做到 100 人民币左右的 RPM。 这比之前传统的展示广告高出了大约两个数量级。虽然广告的收入并非和不确定性的减少呈指数相关，但是，如果你作为广告主知道用户的意图再进行服务，效果也要好得多。 那么，你可能还会说，我能不能做一些个性化广告以及和内容相关的广告？很遗憾，个性化服务会带来的好处并没有人们想象的多，这里面根本的原因是，人的差异远没有我们想象的大。关于个性化，我们可以理解成我们自身的喜好，和大众平均值的差别。 如果我们把自己日常关心的事情放到 10 个维度中来考虑，每一个维度有一个权重，十个维度放在一起，就是一个关注度的概率分布。 我们假设 P=（P1，P2, ……, P10)。类似的，我们假设大众在这十个维度上的关注度的概率分布是 Q=（Q1，Q2, ……, Q10)。那么所谓个性化的差异，就是 P 和 Q 这两个概率分布的交叉熵 KL（P，Q）。 那么这个交叉熵有多大呢？如果是考虑十个维度，其实并不大，根据我们在 Google 和腾讯使用了大量的数据计算，它不到一比特。 这也就是说，中国人所说的“性相近，习相远”是对的，因为人的本性差不多。但是如果考虑的维度比较多，比如细到 100 维，这个数值就要大一些了，大约在 1～2 比特之间。 1～2 比特信息虽然比不上搜索时用户自己输入的信息那么多，但是对于改进广告系统还是有用的。这其实是 Facebook 的广告效果比当年雅虎等门户网站好的原因之一。 — location: [3026]() ^ref-50957

---
为什么我说之一呢？因为光靠那 1～2 比特的信息，Facebook 完全不可能做到今天的市场规模，它的广告系统另有玄机，那就是利用了承载广告页面本身的内容信息，以及社交网络的网络效应。 我们先说说利用承载广告页面本身内容信息的作用。如果我们在一个介绍金融的网页中放一个薯片的广告，效果恐怕好不了，但是如果放一个高端旅游的广告，效果就会好一些。这就是所谓的和内容相关的广告。 至于社交网络的网络效应，用我们一句俗话讲，就是“近朱者赤，近墨者黑”。你周围圈子是什么人，你就被划分成什么人，他们点击什么广告，你就被推送什么广告。 — location: [3045]() ^ref-53653

---
搜索广告使用了用户提供的 10 多比特的信息，而个性化广告其实只能利用 1～2 比特信息。但是后者的效果也比门户网站的广告要好。 因为如果说 Google 的广告效果主要是因为用户主动告知自己的目的而极大地得到提高，那么 Facebook 广告系统的效果则是通过几个隐含的信息叠加式改进的。 后者虽然每一类信息的效果有限，但是由于使用的信息彼此是正交的，它们的效果可以叠加，几种主要信息在一起，效果就比传统门户网站的展示广告好了很多。 那有没有其他效果很好的广告投放办法呢？在互联网的世界里，还有第三类广告系统，那就是电商平台上的广告系统，它以亚马逊和阿里巴巴为代表。 这类广告系统，实际上直接使用了用户过去的购买行为信息，甚至可以预测上一次购买的消费品是否已经用完。因此对用户信息的把控是极为准确的，它的效果也非常好。 — location: [3051]() ^ref-55267

---
1. Google 的广告系统利用的是用户主动输入的信息，它最为有效，因为任何时候，人总是喜欢买东西，不喜欢被卖东西。任何推送都比不上用户主动的请求更有效。 2. 我们介绍了个性化服务的本质，就是寻找每一个人和整个群体在喜好上的差异程度，我们可以用交叉熵来定量衡量它。维度分得越细，个性化特点越突出。但是，人对各种东西喜好的差异比我们通常想的要小很多。 今天有很多不重视底层技术和信息理论的创业者，天真地以为自己做了点个性化的事情，就可以对现有的行业竞争者取得碾压性的优势，这只是他们自己的想象。“化学之父”拉瓦锡讲，不使用天平衡量就得不到真理。 类似的，Google 一直强调，没有数据就得不出任何结论，道理是相通的。在信息时代，为什么我们要了解信息论最基本的原理？就是要能够判断做事情的方向是否正确，以免像一些公司那样，死都不知道是怎么死的。 3.我们看到了使用正交、可叠加信息的作用。这才是 Facebook 成功的根本原因。 4.我们与其说是大数据帮助亚马逊和阿里巴巴了解我们的意图，不如说我们自己直接将自己的需求放到了亚马逊和阿里巴巴里面。它们的成功还揭示了一个规律，就是离达成交易的环节越短，广告的效果越有效。 根据我们在 Google 的研究，发现人从了解到一些商业信息到最后达成购买并付费是一个非常长的过程。开始先看到一些普通的信息，如果他真感兴趣，会向周围朋友去了解，然后会去做一些研究，包括看看使用者的点评，再随后是搜索比价，最后才达成购买。 大部分媒体，包括门户网站上的信息，只是提供普通信息，它们离购买最远，因此广告的效果最差。社交网络的信息和 Google 搜索的信息属于第二、第三阶段的，离购买越来越近，广告的效果也就越来越好，电商上的属于最后一环，效果最好。我在很多场合讲，做人做事要直截了当，效果最好，不要拐弯抹角，就是这个道理。 — location: [3060]() ^ref-4346

---
很多人问我，为什么要学一点像数学或者信息论这种看似在生活中用不到的通识课程？我的回答是，那些从一个个具体案例中抽象出来的数学概念、原理和方法，是我们透过纷繁复杂的表象，认识问题本质的基本功。 — location: [3084]() ^ref-14309

---
当我们要进入一个之前一无所知的领域时，它们会给我们带来一些最基本的原则，和最有价值的经验。 信息论在一定程度上，可以让我们的生活有一个基准，遇事能够找出大致的方向。 — location: [3087]() ^ref-51919

---
标准普尔 500 指数几乎每年都把表现不好的企业从指数中淘汰掉，换进那些表现好的。因此那些表现不好的企业你就永远看不到了，这其实反映了幸存者的偏差。 这也是巴菲特等很多投资大佬，一直推荐大家购买美国标准普尔 500 或者道琼斯指数基金的重要原因，因为它其实是用了幸存者偏差占到了便宜。更有意义的是，美国股市通过对表现不好的企业强制退市，允许做空股票，彻底将表现不好的企业清除出股市。如果一个股市没有强制退市制度，就难以有长期良好的表现，那种股市的指数基金表现好不了。 — location: [3140]() ^ref-25110

---
◆要点总结◆──── 首先，我们从理论上分析了幸存者偏差，并且用它来分析了股市，最后给大家的结论就是要购买那种不断淘汰坏企业的股市上的指数基金。此外，在工作中，大家也要不断淘汰不好的项目，在生活中要止损。这样就可以利用幸存者偏差将利益最大化。 — location: [3156]() ^ref-16252

---
｜奥卡姆剃刀法则：最简单的往往是最有效的 — location: [3171]() ^ref-53959

---
奥卡姆剃刀法则（Occam's Razor 或者 Ockham's Razor）看似和信息论没有太多交集，但是托马斯∙科弗在信息论的教科书中用信息论解释了奥卡姆剃刀法则，在我上学时，给了我很大的启发，希望这讲内容也能帮大家理解并利用好这个法则。 — location: [3172]() ^ref-32667

---
奥卡姆剃刀法则，又被称为“简约之法则”，它是由 14 世纪圣方济各会修道士奥 卡姆（英格兰的一个地方）的威廉（William of Occam）提出来的，他说过这样一段话： “切勿浪费较多东西，去做‘用较少的东西，同样可以做好的事情’。” 这句话用信息论来解释，就是如果关于同一个问题有许多种理论，每一种都能作出同样（准确）的预测，那么应该挑选其中使用假定最少的理论。 — location: [3174]() ^ref-30473

---
如果能够得到同样好的结论，假设 越少越好，或者说条件越少越好。奥卡姆剃刀法则在当时最流行的解释是“若无必要，勿增实体”（拉丁文是：Non sunt multiplicanda entia sine necessitate）。西方历代大学问家，都将奥卡姆剃刀法则作为自己治学的行为准则。 牛津大学第一任校长罗伯特·格罗斯泰斯特讲：“在其他情况相同时，需求更少的更好、更有价值……一个普适的规律比特定的规律更好，因为它从更少的假定出发产生知识。就像在自然科学中，最好的部分不需要前提假设，其次是需要较少前提假设的。” 托马斯·阿奎纳也说过类似的话，他的大意是，用较少定则推导出来的结论，使用的次数较多。科学领域的集大成者牛顿则说：“我们需要承认，自然事物各种现象的真实而有效的原因，除了它自身以外再无须其他，所以，对于同样的自然现象，我们必须尽可能地归于同一原因。”这些都体现出他们对这个看似简单准则的认同。 — location: [3190]() ^ref-61122

---
要消除不确定性，就要使用信息。 — location: [3202]() ^ref-37472

---
奥卡姆剃刀法则不仅有科学根据，在实践中也被不断地验证。 首先，我们说说为什么简单的解释通常是正确的。这里面有两个原因，一个是世界本身的规律在形式上并不复杂，虽然通常找到这样简单规律的过程极为复杂。在历史上各个时代，最高深的物理学理论，从形式上讲都不复杂，从牛顿力学，到爱因斯坦的相对论，到今天物理学的标准模型。 牛顿在《自然哲学的数学原理》一书中讲了四条法则，其中的法则一就是“除那些真实而已足够说明其现象者外，不必去寻找自然界事物的其它原因”。只不过，看似简单的，却非常准确的解释其实很难找到，而看似复杂的，似是而非的解释反而找起来容易一些。 — location: [3216]() ^ref-5704

---
其次，过于复杂的描述常常是骗局，因为骗局只有被包装得很复杂才不容易被识破。2008—2009 年金融危机前，有人向巴菲特推销金融衍生品，巴菲特看了他们的说明书后，断然拒绝了，理由是那说明书之所以要写成厚厚几百页没人看得懂的东西，里面多半藏了不可告人的事情。 — location: [3222]() ^ref-5944

---
我最初接触到奥卡姆剃刀法则是多年前在美国上学期间，是在科弗的教科书中读到的。后来我专门了解了它的背景，觉得里面体现了智慧。我自己对它的体会有这样三点： 1.做减法。 很多时候，我们生怕自己错过一些机会，于是做了很多其实对目标结果不再有帮助的事情。 比如年轻人头几回在大会上作报告时，常常喜欢尽可能多地把自己的工作讲出来。 这样不仅无法在规定的时间里讲完，而且由于传递出的信息其实有很大的重复性，接收者并不因为耐着性子听完了就获得更多的认同。讲东西如此，做事情也是如此，并非做得越多，效果就越好。 — location: [3225]() ^ref-17969

---
2.不要制造伪需求。很多看似很重要的事情，其实是伪需求。我在《硅谷来信》中评论过无人超市是否需要，我讲其实超市有没有人并不重要，重要的是顾客是否能够以最便宜的价格，最短的排队时间买到自己需要的日用品。至于可有可无的奢侈品的销售，更是需要推销的了。 — location: [3231]() ^ref-40245

---
3.要提高自己寻找基函数的能力。 我们说的做减法，不是把有用的信息剪掉，而是设法只保留少量的，等同于全部信息的有效信息，这就是数学上所说的基函数。 比如说，投资的原则有很多很多，但是真正称得上是基函数的其实很少，比如巴 菲特和芒格的价值投资，马尔基尔的定投指数基金等等就是。而其它一些所谓的秘诀，什么低买高卖，追涨杀跌，则不是。 — location: [3239]() ^ref-65311

---
最有效的原则就是所谓的最大熵原理。这也是我在信息论领域的主要研究方向。 — location: [3260]() ^ref-54763

---
当我们需要对一个随机事件的概率分布进行预测时，我们的预测应当满足全部已知的条件，而对未知的情况不要作任何主观假设。 — location: [3280]() ^ref-53425

---
我们在第一个骰子的问题上，得不到任何已知条件，因此我们不能有任何主观假设，猜每一个面朝上的概率是 1/6 就可以了。 但是，当我给大家看了做过手脚的骰子，大家就得到了部分信息，所以在第二次作预测时，大家首先要保证预测符合已知的信息，也就是说 5 点和它所对应的 2 点朝上的概率应该分别是 2/5 和 0。 但是对于任何的未知，依然不能作任何主观的假设，于是大家在其他四个面朝上的概率上，均匀分配剩下的概率，猜 3/20 就可以了。 如果我们按照上述的方法，去建立一个概率的模型，可以证明这样的概率模型会使得熵，也就是不确定性，达到最大值，因此这种模型被称为“最大熵模型”，而相应的，建立模型的原则就被称为最大熵原理。 最大熵原理也可以用老子的智慧从另一个角度诠释一下，那就是“过犹不及”。我们学了信息论，知道信息是用来消除信息熵，也就是不确定性的。 — location: [3281]() ^ref-48043

---
如果我们自作主张地想进一步降低信息熵，作了很多主观的假设，作出来的预测反而不准确了，我们在前面学了，不准确的预测风险是极大的。 — location: [3292]() ^ref-63742

---
最大熵模型在技术上有什么好处，或者相对其它技术有什么优势呢？ 首先，它显然和我们所有已知的信息相符合，因为我们的模型就是用已知信息搭建起来的。 其次，这样的模型最光滑。光滑在数学上是一个什么概念？你可以理解为它不会遇到黑天鹅事件，方方面面都考虑得很周全。最大熵模型光滑的原因，在于我们对于未知的信息，没有作任何的主观猜测，就可以保证结果能覆盖所有的可能性，不会有所遗漏。 我们还是以那个做了手脚的骰子为例来说明。我们只知道两件事，五点朝上的概率大约是 2/5，两点朝上的概率大约是零，对于另外四个面的概率不知道。 这时候你可以赌，比如赌三点朝上的概率为 1/3，四点朝上的概率为零。你或许会赌对，又或许会赌错，但是长期看下来，这样赌的风险很大，因为不符合概率上的计算结果。 因此，我们可以认为，一个光滑的模型，可以让预测的风险最小。而最大熵原则恰好满足这一点。 我们在投资时常常说这样一句话，不要把所有的鸡蛋放在一个篮子里，其实就是最大熵原理的一个朴素的说法，因为当我们遇到不确定性时，就要保留各种可能性，而不要随便作主观的假设。 — location: [3293]() ^ref-2156

---
最大熵模型用数学推理的办法解决了整个问题，它无法同时满足两个矛盾的先决条件，会自动地在这两个条件中找到一个中间点，保证信息的损失最小。可以讲，最大熵模型在形式上是最漂亮、最完美的统计模型，在效果上也是最好、最安全的模型。 — location: [3306]() ^ref-28382

---
对于最大熵的原理，每一个人都应该记住以下三个结论： 1.如果你获得了全部的信息，事情就是确定的了，就不要用概率模型进行预测了。 所以，最大熵模型的应用场景是你获得了一部分确信的信息，但是没有获得全部的时候。这时你要保证所建立的模型满足所有的经验，同时对不确定的因素有一个相对准确的估计。 — location: [3317]() ^ref-21998

---
2.在没有得到信息之前，不要作任何主观假设。这一点对投资非常重要。很多人觉得股市连续涨了半年就一定会下跌，或者下跌了半年就一定会涨，这些都是主观的假设。 — location: [3321]() ^ref-31359

---
我们在前面介绍投资时讲过，要想获得投资最大的收益，就需要将钱长期放在一个健康的股市中。事实上时机你是把握不住的，而时间是你的朋友。很多人对所谓时机的判断，都是主观的，其实是一种投机行为。 — location: [3322]() ^ref-62097

---
3.不要把鸡蛋放在一个篮子里，而要让凡事变得“平滑”，因为按照最大熵的原理，这样做风险最小。 此外，透过最大熵模型，我还想表述一个事实，那就是形式上简单的东西，获得它未必容易，在数学上漂亮，形式简单，但是实现起来反而难度很大。 我上节课讲到奥卡姆剃刀法则时说简单的方法常常最有效，可能会有人将简单和初级、低水平划等号。形式上简单的东西未必初级，相反，要把道理总结得简单易懂，自己需要有深刻的理解，在科学上，要得到形式简单的规律，反而要做更多的工作。 — location: [3324]() ^ref-57810

---
我在课程《科技史纲 60 讲》和《全球科技通史》这本书中用能量和信息两条主线来解释近万年的人类科技成就，有读者问，信息和能量之间是否有十分明确的、本质的联系呢？ 其实是有的，我们今天就从物理学假说开始，说说它们的联系，这个假说被称为 “麦克斯韦的妖（Maxwell's demon）”。 — location: [3338]() ^ref-30742

---
热力学第二定律不仅告诉我们热机做功的效率会很有限，而且预示了一个非常沮丧的结果，那就是宇宙最终所有地方的温度都会趋同，这就是所谓的“热寂说”。 热寂说想起来就很可怕，未来的宇宙会是死气沉沉的。 — location: [3354]() ^ref-2242

---
能否有个方式，让熵增加的过程逆转呢？ 于是麦克斯韦就假想了一种情形。当两个联通的容器中冷、热空气混合，也就是熵比较大时，他在两个联通的容器之间安排了一个妖怪把门，这个妖怪能探测并控制单个分子的运动。 如果它看到一个速度快的分子从右往左运动，它就让它过去，同样，如果它看到一个慢分子从左往右运动，它也让它过去。但是反过来，它会严格把门，不让分子经过。 左图的是妖怪允许慢分子（红色）从左往右通过，右图是快分子（蓝色）都到了左边，慢分子都到了右边。 那么如果有这样一个妖怪存在，经过一段时间，左边的分子速度越来越快，温度就升高了，右边的分子速度越来越慢，温度就降低了。这样它让原本熵最大的冷热空气混合的无序状态，扭转为有序状态了。 再往后，由于一个容器温度高，另一个温度低，就可以利用温差驱动热机做功了，然后再让妖怪重复熵减的过程，如此循环。这样就造出了一个（第二类）永动机。 麦克斯韦假想的这种情形显然在现实中发生不了，但怎样才能从理论上证明这样一个妖怪不可能存在，却不是一件容易的事情。 我们回想一下麦克斯韦的妖怪工作的过程，它需要先测量分子运动的速度，也就是说需要获取信息，它需要不断的信息输入才能降低热力学上的熵。我们知道信息的输入可以降低一个黑盒子里的信息熵，现在它也可以降低热力学上的熵。 但是，这时麦克斯韦所假定的两个容器，本身已经不再是封闭系统了。也就是说，麦克斯韦想象的系统并非克劳修斯总结热力学第二定律所说的系统。这样麦克斯韦的妖和热力学第二定律就不矛盾了。 — location: [3357]() ^ref-2804

---
接下来的问题是，测量分子运动速度这件事是否需要能量，或者更广义地说，在物理上，测量这件事是否需要能量？答案也是肯定的。我们知道在物理学里有一个测不准原理，也就是说我们“观察”这个动作本身是会改变物质状态的。 霍金在《大设计》一书中介绍这个原理时讲，在微观世界里，当我们测量时，哪怕两个光子照在原子上，它的状态都会改变。也就是说，信息的获取本身需要能量。 也就是说，这个（第二类）永动机确实没有直接消耗什么能量，但是它消耗的是信息，麦克斯韦的妖把信息转化成了能量，或者说通过提高信息熵，降低了热力学的熵。这样算下来，总的熵并没有减少。 这里顺带说一句，在信息科学中也有一个类似于测不准原理的不确定原理，也就是说频率的误差和时域的误差不可能同时变小，这和物理学是一致的。 — location: [3373]() ^ref-15587

---
接下来我们来讲讲热力学第二定律和麦克斯韦的妖同信息时代管理的关系。 在信息时代，你会发现一个现象，一个开放的、包容多元文化的社会，容易催生出伟大的公司。而一个封闭保守的地区，发展就缓慢。 这个现象很好解释。根据热力学第二定律，一个封闭的系统永远朝着熵增加（也就是越来越无序）的方向发展，一定会越变越糟糕。而要扭转这种局面，唯一的办法就是从外界引入负熵。 — location: [3381]() ^ref-50816

---
对于一个地区、一个组织也是如此。它只有成为一个开放的系统，会引入负熵，才有可能让系统通过与外界的交换变得更加有序，也就是朝着越来越好的方向发展。 世界上最有经济活力的地区可能要数硅谷地区了，它成功的一个重要原因，就是因为它自身是一个开放的系统，不断地从世界各地引入新的人才，不断地丰富本已很多元的文化，才能在整体上蒸蒸日上。 — location: [3387]() ^ref-42388

---
相反，一个封闭的社会，如果闭门造车，最终那里的人会变得同质化，整个环境就会变得死气沉沉。我一直非常强调工作地点，反对年轻人贪图安逸，跑到生活成本低的三四线城市去，因为那些地方是相对封闭的系统。 一个地区也好，机构也罢，从外面引入负熵有两种办法，一种是直接与外界进行人的交换，另一种则是接受外面新的思想。前者可以被看成是引入负的能量熵，后者则是引入负的信息熵。 — location: [3393]() ^ref-10557

---
对于个人来讲，什么算是引入负熵呢？那就是行万里路，读万卷书。这两句话当然是比喻，第一件事是指自己走出去和别人接触，我把它等同于在能量上引入负熵。第二件事是指接受新的信息，引入负的信息熵。 我有时听一些朋友讲，我太忙，没时间走出去，没时间学习，或者我太内向，不善于和别人打交道。对此我想说的是，每个人都有自己的困难，但是世界自有安排，不会因为谁困难就照顾谁。不管什么原因，一个人一旦封闭起来，他就离无序的状态不远了。 — location: [3410]() ^ref-46894

---
─◆要点总结◆──── 1.我们介绍了热力学第二定律，并且通过介绍麦克斯韦的妖讲述了信息和能量二者的关系。我们还通过物理学的测不准原理和信息科学中的不确定原理，说明了二者的相关性。 2.任何一个封闭系统都是越变越无序的，要想变得有序，就要引入负熵，即能量和信息。对地区，对企业都是如此。 3.对人来讲，引入负熵的方法就是行万里路，读万卷书。 — location: [3415]() ^ref-22730

---
从事计算机科学的工作，第一步是将我们这个世界的现实问题变成一个数学问题，这就是计算机科学家们做的事情，第二步就是将数学问题重新描述一下，变成计算机能够处理的问题，这就是计算机工程师的工作，这个重新描述的过程，其实就是把人的自然语言变成计算机程序语言。 — location: [3430]() ^ref-2026

---
对于绝大部分计算机科学家来讲，他们不需要自己真的去设计制造计算机，而是做好现实问题到计算机问题的转化。 — location: [3434]() ^ref-54182

---
在信息论的应用中，情况也大致如此。我们很多人所做的工作，就是将工作中的问题，变成信息的收集、传输、综合、存储和处理的问题。我们绝大多数人不需要知道上述信息技术的细节，但是需要知道如何把自己领域中的问题，描述成一个信息处理的问题。 — location: [3435]() ^ref-63281

---
首先，我们讲述了验证信息的方法，并且给出了一个比较高效的做法，就是交叉验证。人们通常习惯于在自己熟悉的维度中往深里挖，往细了挖，但是这样的做法到后来成本很高，准确性有限。从另一个维度进行交叉验证的效果则好很多。 — location: [3454]() ^ref-54225

---
第二，我们谈到了在信息不可获得时，如何利用等价信息获得相应的效果。当然，在使用等价信息时，要注意不要把相关信息都当作等价信息了。 — location: [3457]() ^ref-44460

---
第三，我们剖析了大数据思维的底层逻辑。虽然今天很多人拿着大数据思维当作新的概念炒，以至于已经被炒得有点烂了，但是如果我们理解了它的本质，就知道它其实是一种全新的思维方式，我们可以通过这样四个层面，对它一层层地深入理解： 第一层：百川入海，从各种枝末细节得到规律； 第二层：逆向思维，先有结论，再找原因； 第三层：洞察枝末，通过宏观规律对比细节，找到差异发现问题； 第四层：相关联系，通过多个维度的强相关性，找到因果关系作决定。 第四，我们介绍了奥卡姆剃刀法则，即简约之法则，它的原意是“切勿浪费较多东西，去做‘用较少的东西，同样可以做好的事情’”。 发现简约的法制，并加以很好的利用，应该是我们日常做事的准则。 接下来，我们介绍了最大熵原则。这个信息论的原则可以从几个角度来理解。人们把它理解为，不要把鸡蛋放在一个篮子里，而要让凡事变得“平滑”，这是没有问题的。 — location: [3458]() ^ref-6581

---
但是，在课程中，我们还强调了这个原则的另一面，那就是在没有得到信息之前，不要作任何主观假设。这一点对投资非常重要。 很多人觉得股市连续涨了半年就一定会下跌，或者下跌了半年就一定会涨，这些都是主观的假设。事实上时机你是把握不住的，而时间是你的朋友。很多人对所谓时机的判断，都是主观的，其实是一种投机行为。 — location: [3468]() ^ref-56405

---
从信息论的视角看，未来科技发展的趋势是什么？当然我可以先告诉你结论，这个趋势就是：以更少的能量，传输、处理和存储更多的信息。 — location: [3490]() ^ref-25639

---
似乎更早发明无线电的特斯拉为什么失败了？原因很简单，他把无线电用错了方向。 无线电这件事，简单地讲就是一个相互转化的电场和磁场，电场的变化产生变化的磁场，磁场的变化又产生变化的电场，于是它们就往远处传播了。这种无线电可以做两件事，传递能量或者传递信息。 先说说传递能量。如果在某一处有一个线圈，放到变化的电场中，线圈就产生电流，于是能量就传输了。这就是今天无线充电的原理。 — location: [3503]() ^ref-8777

---
无线充电的一个特点，那就是输电的功率很小，距离很近。为什么距离远不了呢？因为电磁波辐射到远方衰弱得特别快。如果我们让电磁波往四周辐射，在辐射源 10 米附近的强度，只有一米附近的强度的 1/100，100 米以外的强度，只剩下万分之一了。因此不能距离很远。 为什么功率不能很大呢？因为被充电设备获得的能量占本身辐射出总能量的很少一部分，剩下的都辐射到空间了，太大的功率会伤害到我们。 — location: [3511]() ^ref-22558

---
马可尼用无线电传递信息，而传递信息不需要太高的能量，于是马可尼成功了，名利双收，不仅得了诺贝尔奖，而且还创立了 RCA 公司，该公司在很长时间里是世界上最大的收音机、无线广播和电视机公司。 那么为什么用无线电传递信息能传得较远呢？因为信息可以叠加在无线电波（也被称为载波）上传输，在接收时，只要信噪比足够高，就能复原出信号，不需要在接收端具有太高的能量。 — location: [3519]() ^ref-36970

---
不过顺便说一句，即使是无线传输信息，比有线传输，带宽也低很多，低好几个数量级。只不过我们对此不敏感罢了。类似的，无线充电，以手机或者电动牙刷为例，其实也比有线的低很多。 那么能否用无线的方式大功率传输能量呢？其实变电站的变压器早就做到这一点了，但是变压器有个大磁圈，把电磁场限制在周围不往远处辐射（辐射不超过 5%）而已。但是远距离无线输电，是不可能有一个大磁圈的。 — location: [3524]() ^ref-62413

---
信息处理的问题是数学问题，让计算机处理自然语言也是数学问题，不是我们通常理解的语言学问题。 在香农之前，人们一直没有把信息量和信息的含义，这两件事之间的区别和联系搞清楚。即便是在香农之后，很多人理解的让计算机处理自然语言，依然是模仿人的思维方式，去找信息里的意义。 按照那种思路，处理语言就要精通语言。但是后来计算机处理信息其实是从信息论出发，而非语言。这也就是为什么贾里尼克开玩笑讲，他每解雇一位语言学家，他的语音识别系统的错误率就降低 1%的原因。 语言是承载信息的工具，或者说是一种编码方法，而背后的信息才是最重要的。 从天底下大部分语言背后挖掘信息的数学模型，都是相通的。 不仅我不懂韩语，能够做韩文的处理，Google 过去负责机器翻译的奥科不懂中文，照样是世界上中英翻译做得最好的科学家。实际上，从事自然语言处理这个领域的工作，数学基础不够很难成事，了解语言只是锦上添花。 — location: [3578]() ^ref-11670

---
首先，如果能够去一家有数据、有技术的公司当然好，这就如同 30 年前大家喜欢去银行工作一样。但是要注意，如果你去那种公司却做了和数据、技术无关的工作，那就是另一回事了。这就如同你去高盛就是要做交易，而不是 HR，去清华，应该是当老师，而不是厨师。 对于某些专业的人来讲，他们未来的工作场所未必是大数据的公司，因此也不要勉强往里面挤，因为挤进去后，成为那个公司人员金字塔最底端的人，就没有意思了。 其次，怎样才能进有数据、有技术的公司？很多人讲，我们刚毕业，没有经验，人家凭什么要我们？其实像阿里巴巴和腾讯这样的企业每年都有很多校招，而且还会解决户口，只要自己基础不错，还是有机会的。反倒是毕业几年后换工作时，解决户口反而难了。 最后，判断一个公司是否应该待下去，是看自己能否在那家公司里不断有机会成长进步，如果那家公司不错，给你的机会并不好，而且你也看不到通过自己的提高能够获得机会，也不用太留恋。 — location: [3593]() ^ref-1041

---
与信息论几乎同时诞生的交叉学科还有两个，即控制论和系统论，它们被称为“（老）三论”。 这些理论不仅在通信和控制等学术领域有非常重要的地位，而且对管理学和社会学有着深远的影响。 事实上，在书店里，你在管理类的专柜中看到的和“三论”有关的书，甚至会超过你在信息专柜中看到的。 — location: [3654]() ^ref-6897

---
二战时，维纳周围很多美国人都上前线为国效力去了，作为一名科学家，维纳留在了后方，但是他（和很多科学家）总觉得自己该为战争做点什么。于是，他就开始研究火炮控制问题。 在此之前，火炮的设定都是人为进行的，一旦对设定的计算完成，打出去的炮弹落在哪里就看运气了。如果没有打中目标，接下来的调整就看经验了，无法根据之前命中与否的结果，自动调整火炮的设计方位和仰角。 维纳在二战之前对通信理论和系统反馈已经有了深入的思考，他决定用他的理论改进火炮，这最终促成了控制论的诞生，当然这样改进后的火炮准确性大增。 — location: [3675]() ^ref-21825

---
控制论的本质可以概括为下面三个要点。 首先，维纳突破了牛顿的绝对时间观。 什么是绝对时间观呢？在牛顿等人看来，时间是绝对恒定的物理量，比如昨天的一小时和今天的一小时是一样的，昨天出去玩了一小时没有做作业，今天多花一小时补上就可以了。 维纳采用了法国哲学家柏格森的时间观，即 Duree 这样一个概念，中文被译为“绵延”，意思是说，时间不是静态和片面的，事物发展的过程不能简单拆成一个个独立的因果关系。 比如昨天浪费了一小时，今天多花了一小时做作业，就少了一小时的休息，就可能造成第二天听课效果不好，因此浪费一小时和没有浪费一小时的人，其实已经不是同一个人了。 如果我们把这种观点应用到企业管理上，那么工厂主强制员工在某一天加班一小时，未必能够多生产出通常一小时生产的产品，因为多加班一小时的员工们已经不是原本的员工了。由于事物发展的过程前后高度耦合，也就是紧密咬合，没有空余。所以，我们在做事情时，就要考虑它的连带影响。 — location: [3681]() ^ref-57019

---
其次，任何系统（可以是我们人体系统、股市、商业环境、产业链，等等）在外界环境刺激（也称为输入）下必然作出反应（也称为输出），然后反过来影响系统本身，这一点很重要。维纳就是根据这个理论改进火炮的。 — location: [3691]() ^ref-8181

---
这一点，也可以很好地帮助我们理解资本市场。比如如果大家都觉得一种股票有利可图，大量购买，就会瞬间抬高股价，于是，炒股的人并不能赚到预想的收益。这便是市场的有效性。 — location: [3693]() ^ref-39364

---
为了维持一个系统的稳定，或者为了对它进行优化，可以将它对刺激的反应反馈回系统中，这最终可以让系统产生一个自我调节的机制。 — location: [3697]() ^ref-29202

---
在管理上，一个组织为了保证计划的实现，就要不断地对计划进行监控和调整，以防止偏差继续扩大。 — location: [3703]() ^ref-49529

---
所幸的是，就在冯·布劳恩等人研究火箭的同时，卡尔曼改进了维纳的控制理论，提出了著名的卡尔曼滤波，可以让火箭随时动态调整方向，这样才保证了它最终准确着陆。对比 V-2 和土星五号，可以看出确定的机械思维和不断调整的控制论思维两种方法论的差异，前者是对未来作一种尽可能确定的预测，后者则是根据变化不断进行调整。 我经常讲，在当今这个时代，我们要轻预测，重反应，其背后的科学原理就是控制论。 — location: [3713]() ^ref-20447

---
很多成功的企业，它们最终做成的事情和创始人最初的想法相差十万八千里呢，因为环境和市场在不断变化。一个好的创始人需要是变色龙，他能不断应对环境变化作出调整，而不是一开始就把摊子铺得很大。 — location: [3723]() ^ref-9632

---
1.我们介绍了控制论的由来和它的应用，以及它的三个本质要点，即突破了传统的绝对时间观，利用反馈对系统进行控制，以及利用反馈让系统稳定。 — location: [3726]() ^ref-36857

---
首先，一个有生命的系统和非生命的系统是不同的。前者是一个开放的系统，需要和外界进行物质、能量或者信息的交换。后者为了其稳定性，需要和外界隔绝，才能保持其独立性， — location: [3740]() ^ref-64453

---
贝塔朗菲和其他系统论的奠基人主要的观点如下。 — location: [3739]() ^ref-4990

---
一般认为，1948 年奥地利生物学家贝塔朗菲出版的《生命问题》一书，标志着系统论的问世。虽然系统论最初源于对生物系统的研究，但是它适用于各种组织和整个社会。贝塔朗菲和其他系统论的奠基人主要的观点如下。 — location: [3738]() ^ref-1304

---
其次，根据热力学第二定律，一个封闭系统总是朝着熵增加的方向变化的，即从有序变为无序。 — location: [3742]() ^ref-24902

---
特别需要强调的是，对于一个复杂的系统，比如我们的生命体，或者一个公司、一个组织，一旦它成为了一个封闭系统，一定是越变越糟糕。相反，对于一个开放的系统，因为可以和周围进行物质、能量和信息交换，有可能引入所谓的“负熵”，这样就会让这个系统变得更有序。 — location: [3744]() ^ref-29841

---
最后，贝塔朗菲认为，对于一个有生命的系统，其功能并不等于每一个局部功能的总和，或者说将每一个局部研究清楚了，不等于整个系统研究清楚了。 — location: [3750]() ^ref-43465

---
系统论的思想对我们有什么启示呢？这里我不妨分享一下我的体会。 首先要想办法做到整体大于部分之和。 我们知道，在机械思维中的“整体总是能够分解成局部，局部可以再合成为整体”。 — location: [3757]() ^ref-48668

---
我的第二点体会是，当上帝关上一扇门时，他可能同时给你打开了另一扇窗。这句话是美国盲人女作家海伦·凯勒说的。什么意思呢？在一个有机的系统中，很多功能是可以相互替代的，因此不会因为某一个缺损，而使得整个系统瘫痪。 — location: [3787]() ^ref-52790

---
我的第三个体会涉及到利用系统论改进做事方法，毕竟我们光发现问题还不够，还需要有行动指南。我把它们总结成四点： 1.整体。任何局部的改进，都需要放回到整体中去考察。 2.综合。iPhone是一个很好的例子。 3.科学。在分析问题时必须要遵循科学方法，而不是简单的经验，因为只有这样才能获得可重复的成功。 — location: [3802]() ^ref-58270

---
4.发展。系统工程不仅要求在空间上，作整体考虑，还需要在时间上考虑一件事情的影响力，然后决定做不做。 — location: [3808]() ^ref-40644

---
我讲东西其实讲技术本身，不是最终目的，这只是一个手段，或者说这是我建造通向这个目的的一个桥梁。目的是我讲述一个它的底层逻辑，这样你学到以后，可以自己来分析一些技术，对当下的一些观点有自己的看法，很容易判断哪个是对的，哪个是不对的，哪个是投资的机会，或者说你自己的创业机会，哪个是一个永远实现不了的情怀。 — location: [3825]() ^ref-42022

---
讲 5G 这个东西，其实我一直和 IoT 连着讲，因为这两件事分不开。 — location: [3830]() ^ref-21295

---
为什么叫超级智能？就是我们今天所说的人工智能+IoT。 人工智能是怎么获得的？或者我有时候喜欢叫机器智能。我在书里头写了，它是大数据+摩尔定律+数学模型。和人的智能有什么差别？很重要的一个特别大的差别在于，人工智能是一个网络的智能，而我们人的智能是个体的智能。 世界上有些生物是有网络智能的，比如说蚂蚁，每个单个的智能很弱，但是组合在一起就很强。人工智能具有这个特点。 — location: [3834]() ^ref-10304

---
第一代互联网到了第二代互联网，是人和人联网，不是简单地用你的移动终端取代了固定线路的这样一个 PC 机，而是人和人的联网。在 PC 机时代，如果你下班离开了计算机，你就离开了互联网，坐地铁或者打车回家，你就不在互联网上。 但是在第二代互联网的时候你随时在互联网上， — location: [3863]() ^ref-19756

---
手机和计算机不是本质，人和机器是本质。 这带来一个什么结果呢？因为我们随时要联网，所以它不是那根线在联网，而是空中的频带在联网。所以，这时 1G、2G 的移动通信网络不够用了，3G、4G 就起来了，这个逻辑关系要清楚。 那么谁控制了第二代互联网？有很多家企业都很发达，都很受益，待会我会讲。但是真正起决定作用的主要有两家，一个是谷歌的安卓，一个是 arm 的处理器，跟第一代格局完全一样。 — location: [3867]() ^ref-9293

---
你今天用一个英特尔的处理器，你的手机可能两小时就没电了。英特尔不是没有想过做一个针对移动设备的处理器，但它做失败了，因为它原来的复杂指令系统架构，不适合我们这种低能耗的这样一个设备。 — location: [3873]() ^ref-55445

---
所以从这里头你可以看到，当下其实在过去的几十年里都是这样，就是科技发展的一个很本质的规律，就是什么呢？要用更少的能量处理传输和存储更多的信息。 — location: [3875]() ^ref-2921

---
这里阐释了两个道理，一个就是能量和信息的关系；第二个，实际上不仅仅是这件事，很多事情都是新一代起来的时候，我们需要新的公司，当平稳发展起来的时候，你拿巨无霸企业是毫无办法的。只有当时代变化的时候，你可以很顺利地就赢了它。这不是什么弯道超车的问题，你不需要弯道超车，因为它自然就落后了。 — location: [3878]() ^ref-13217

---
每一代互联网的发展不是一个简单的重复，而是市场扩大。我在《见识》这本书里讲，商业的本质是让大家花越来越多的钱，不是替大家省钱。市场越做越小就没有意义了，要把市场越做越大。 在第一代互联网，PC 互联网的时候，最高的出货量是在 2011 年，每天一百万台计算机的出货量。一年有 3.65 亿台到头了，然后就一直往下走。 而在手机的互联网时代，这个出货量是多少呢？到现在，每年超过十个亿，还在往上走。当然有人说这两年可能会开始饱和，我估计如果 5G 起来，它又不饱和了。不管怎么说，就算一年十个亿，也是那个的三倍，就是从数量级来讲，大了半个数量级。 设备的保有量，以后计算机新的买了旧的扔了，有多少设备在网上？从大概 10 个亿到 30 多个亿，虽然说有 50 亿个手机，但是有些手机是不用的。 — location: [3882]() ^ref-35633

---
所以这个体量也大了半个数量级，更关键的是什么呢？一开始虽然你感觉手机很便宜，今天一部稍微好点的手机，甭管华为还是苹果，比电脑一点也不便宜。说明什么呢？他想尽了办法让你花越来越多的钱，这是一个从第一代互联网到第二代互联网，是一个做得非常好的商业。 我们有些商业是越做越没钱，那不是一个好商业，所以这是一个。 好了，体量也大了，所以从这个往下推讲第三代互联网 IoT 的时候，你可能会得到一个结论。 首先，会有一批新的企业诞生，尤其是龙头企业。 第二，体量会大很多。 体量有多大呢？最保守估计，大概要一个数量级，就是说各种 IoT 设备，包括智能摄像头，它们有可能比我们现在的手机要贵，有的可能便宜，有些小家电可能便宜。 将来智能汽车是一个大的 IoT 设备，这比手机贵，一个智能摄像头也比你的手机贵。 — location: [3891]() ^ref-17314

---
事实上从第一代互联网到第二代互联网，可以看到通信的市场其实是很大的。这里要跟大家讲一句不算题外话，如果你们创业，怎么去找市场，找规模？ 我给个 2016 年的数据，因为这是各方面证实的。2018 年也有数据，可能还有待一些证实。就是说整个互联网企业，2016 年它创造的产值是 4500 亿美元，不算小。 但是你要知道，其中谷歌一家占了三分之一，腾讯、阿里巴巴、facebook 和亚马逊四家，也占得非常多。再加上稍微少一点的，eBay 和百度、今日头条其实现在也不错，也上百亿人民币了。 大概世界上七八家企业加起来，占到大概 80%。四千多亿除去这 80%，就剩大概一千亿了。全世界大大小小的互联网公司，你们知道吗，有上百万家，去争那一千亿，每家平均十万美元，就是养一个工程师的钱。 这也就是说为什么这些互联网都亏损不挣钱，创业这么艰难，因为你完全走错了市场，不是说你们，而是说那些创业者，完全占错了市场。 有些时候，你们看媒体的东西要动脑子，媒体又那么爱报道互联网，好像互联网很热闹似的。确实很热闹，但是这个市场不算大。 — location: [3908]() ^ref-24218

---
但是从另一点来讲，电信这个市场非常大，2016 年 3.5 万亿，包括两个，一个是设备制造商，一个是运营商。 — location: [3921]() ^ref-46539

---
设备商是进得去的。 过去四五年里，中国真正的 IT 企业办得比较好、比较成功的都跟这件事有关。比如我们说华为，比如我们说小米，包括段永平的 VIVO 和 OPPO，其实他们都是闷着头挣钱，为什么？因为他们占到了一个大的市场，不是一个小的市场。 但是这两个市场有一个特点，这个特点是什么呢？计算机互联网这个市场，它规模小到发展比较有动力，比较快。电信这个市场比较保守，比较慢，所以到了未来，IoT 的时代和 5G 时代，我说它会融合。融合以后，就会形成一个相对发展又比较快一点，然后又给了类似于计算机公司一个发展空间的机会。这也就是说，它形成将来从现在大概两个加起来四万多亿到八万亿美元这样一个市场的原因。所以在未来，这还是可以期盼的。 — location: [3923]() ^ref-47688

---
车和车直接联网会比你把信息都上传到高德或者百度再告诉你会好，因为都上传再告诉你会有一个很大的延时。 这时候，我们就需要每一个 IoT 设备直接上网。直接上网就遇到一个什么问题呢？带宽不够，总的带宽不够，以及我们的基站处理不了这么多并发的上网请求。 — location: [3946]() ^ref-22172

---
4G 这个结构从两方面来讲，不适合整个 IoT 的上网。 — location: [3957]() ^ref-21619

---
无线电波频率一开始比较低的时候，就像我们说话的时候，可以绕过这个障碍物。你在外面，虽然这个门虚掩着，但是你在外面也听得见。频率比较高的时候，障碍物就把它挡住了。 — location: [3970]() ^ref-52433

---
