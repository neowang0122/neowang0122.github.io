---
kindle-sync:
  bookId: '24230'
  title: >-
    智能时代 -- 吴军 -- 2016 -- cj5_0005 -- 725848fb8dd98fbd46c55ef590618712 -- Anna’s
    Archive
  author: '吴军 [吴军]'
  highlightsCount: 248
---
# 智能时代 -- 吴军 -- 2016 -- cj5_0005 -- 725848fb8dd98fbd46c55ef590618712 -- Anna’s Archive
## Metadata
* Author: [[吴军 [吴军]]]

## Highlights
作者在介绍科学发展史时用实例说明了数据在科学发现中的位置，在牛顿和麦克斯韦时代，他们所导出的简洁的公式给出的确定性的规律是由大量观察数据所验证的。现在我们面对的是更复杂的自然和社会现象，多维度和多变量导致很大的不确定性，虽然还不能用解析式来说明因果关系，但如果从足够多的数据中发现相关性也能把握事物发展的轨迹，这就是数据密集型科学产生的背景。 — location: [24]() ^ref-26324

---
机器智能革命的发生来自大数据量的积累达到质变的奇点。从这个角度来 — location: [65]() ^ref-261

---
本书的一个重要观点是：机器智能革命的发生来自大数据量的积累达到质变的奇点。 — location: [65]() ^ref-20055

---
几千年以来，我们人类的知识都建立在归纳法之上，归纳法隐含的假设是“未来将继续和过去一样”，换句话说应该叫连续性假设。但即将到来的这个“智能时代”，可以说人类将遭遇前所未有的“不连续性”。如何在新的时代里生存，跨越底层认知的不连续性，是前进的第一步。 — location: [66]() ^ref-43457

---
具体到下棋的策略，AlphaGo里面有两个关键的技术。第一个关键技术是把棋盘上当前的状态变成一个获胜概率的数学模型，这个模型里面没有任何人工的规则，而是完全靠前面所说的数据训练出来的。第二个关键技术是启发式搜索算法——蒙特卡罗树搜索算法（Monte Carlo Tree Search），它能将搜索的空间限制在非常有限的范围内，保证计算机能够快速找到好的下法。虽然AlphaGo的训练使用了上万台服务器，但是它在和李世石对弈时仅仅用了几十台服务器（1000多个CPU 〔5〕 的内核以及100多个GPU 〔6〕 ）。相比国际象棋，围棋的搜索空间要大很多倍，AlphaGo的计算能力相比深蓝，其实并没有这么多倍的提高，它靠的是好的搜索算法，能够准确地聚焦搜索空间，因此能够在很短的时间里算出最佳行棋步骤。由此可见，下围棋这个看似智能型的问题，从本质上讲，是一个大数据和算法的问题。 — location: [102]() ^ref-51953

---
今天，计算机已经开始完成很多过去必须用人的智力才能够完成的任务，比如：医疗诊断，阅读和处理文件，自动回答问题，撰写新闻稿，驾驶汽车，等等。 — location: [119]() ^ref-58967

---
未来的社会，属于那些具有创意的人，包括计算机科学家，而不属于掌握某种技能做重复性工作的人。 — location: [124]() ^ref-34591

---
在AlphaGo取得人机大战胜利之际，我们出版这本书，希望能让大家更多地了解大数据的本质、它的作用、它和机器智能的关系、机器智能的原理和发展历程，以及它们对未来产业和社会的影响。本书一共分为七章，分别介绍了数据的作用，大数据和机器智能，机器智能的原理及其发展历程，大数据思维的核心及其重要性，大数据和机器智能与商业的关系，它们对社会正反两个方面的巨大影响。 — location: [125]() ^ref-40308

---
在计算机出现之前，一般书籍上的文字内容并不被看成是数据，而今天，这种以语言和文字形式存在的内容是全世界各种信息处理中最重要的数据，也是全世界通信领域和信息科技产业的核心数据——包括我们的信件、电话和电子邮件内容、电视和广播节目、互联网网页，以及各种社交产品中由用户产生的内容（User Generated Content，简称UGC）。这些数据的共同特点是以语音和文字为载体。因此，研究人员为了更好地研究和处理它们，还建立了专门针对语音和文字的数据库，即所谓的语料库（Corpus）。 — location: [182]() ^ref-410

---
信息是关于世界、人和事的描述，它比数据来得抽象。信息既可以是我们人类创造的，比如两个人的语音通话记录，也可以是天然存在的客观事实，比如地球的面积和质量。 — location: [193]() ^ref-55807

---
不过，数据和信息还是稍有不同，虽然它最大的作用在于承载信息，但是并非所有的数据都承载了有意义的信息。数据本身是人造物，因此它们可以被随意制造，甚至可以被伪造。 — location: [198]() ^ref-53291

---
早期人类得到的数据是从哪里来的？其中一个重要的来源是对现象的观察。从观察中总结出数据，是人类和动物的重要区别，后者虽具有观察能力，却无法总结出数据，但是人类有这个能力。而得到数据和使用数据的能力，是衡量文明发展水平的标准之一。 — location: [226]() ^ref-60247

---
我们从天文学的发展历程中可以看出，数据的作用自古有之，并非到了今天大数据时代大家才意识到。但是在过去数据的作用常常被人们忽视。这里面有两个原因，首先是由于过去数据量不足，积累大量的数据所需要的时间太长，以至于在较短的时间里它的作用不明显。其次，数据和所想获得的信息之间的联系通常是间接的，它要通过不同数据之间的相关性才能体现出来。可以说，相关性是让数据发挥出作用的魔棒。 — location: [300]() ^ref-63322

---
20世纪70年代，中国的国际交往开始恢复正常，为了加快中国的建设，中国政府决定向其他国家就一些重大建设项目进行招标，其中一项是大庆油田石油设备。当时大庆油田的情况中国政府对外保密，西方国家了解甚少，甚至连它的具体地点都不知道。但是来自日本的投标却非常有针对性并且一举中标。其背后的原因是，日本人通过1964年中国的《人民画报》上刊登的铁人王进喜的照片，分析出了关于大庆油田的许多细节。 在照片中，王进喜穿着厚棉袄，戴着大皮帽，握着钻井机的扳手眺望远方，背景是高高的井架。在一般人看来，这张照片除了体现出石油工人的豪迈之气，并没有什么特别的地方，但是在日本情报人员看来却披露出许多信息。 首先它泄露了大庆油田的位置。根据王进喜穿的厚棉袄和戴的大皮帽，可以断定油田一定是在中国极北的地区，日本人估计油田应该在哈尔滨和齐齐哈尔之间。其次从背景中井架的密度，大致可以估算出油田的产量。 — location: [305]() ^ref-59650

---
2002年年初我到Google面试的时候，面试我的其中一位工程师是阿米特·帕特尔（Amit Patel），他是一位数学博士，考了我一些数学问题，由于我回答得很快，所以剩下很多时间聊一些别的事情。我就问他在Google里面做些什么，通常Google人喜欢故弄玄虚不告诉你他们工作的细节，但是帕特尔倒是挺坦诚。他给我随手画了下面这样一张图。 图1.11　Google用户在不同时间点对某个电视节目的搜索量 他在图中画出的是从Google内部看到的用户在不同时间点对某个电视节目的搜索量。 — location: [317]() ^ref-62564

---
几个月后，我加入了Google，发现帕特尔在Google确实不是很受人重视。他加入Google很早，但是人们知道他仅仅是因为他要求和当时新来的CEO（首席执行官）施密特挤一间办公室，而不是他所做的工作。好在Google总是支持每个人干自己所喜欢的事情，因此帕特尔就在Google内部一直研究搜索的模式。 — location: [326]() ^ref-23554

---
帕特尔问我为什么会出现4个高峰，我说可能是大家在看节目的前后回到Google上搜索这个节目，至于4个高峰，是因为美国跨了4个时区，节目播出的时间各差一个小时。帕特尔同意我这个说法，他又补充道，其实通过它以及各个时区的人口，可以了解到不同电视节目在不同地区（各个时区）的收视率。这样，帕特尔就将搜索量和收视率联系起来了。我称赞他这个发现很有意思，帕特尔感慨道，因为这个工作没有太多经济利益，因此在公司里无法获得多少资源。 — location: [321]() ^ref-43517

---
到了2007年，帕特尔突然在全世界声名薛起，因为他的研究成果被几个工程师开发成了Google的一款产品——Google趋势（Google Trends）。利用这款产品，任何人都可以看到全世界用户在Google上搜索的关键词随着时间和地点变化的趋势，从而知道大家关注什么事情。比如在2015年年底的巴黎气候大会期间，全球范围内“气候变化”（climate change）的搜索量暴增。 — location: [328]() ^ref-18164

---
如果把搜索和其他事情关联起来，就能发现非常重要的信息。 — location: [332]() ^ref-19020

---
疾病控制和预防中心的科学家和Google的工程师从2007年到2008年一起合作研究了流行病传播和各地区搜索量变化的关系，并且于2009年2月在著名的《自然》杂志上发表了他们的研究成果 〔14〕 ——通过各地区用户在Google上搜索和流感有关的关键词的趋势变化，预测流感流行到什么地方了。Google的工程师们从4.5亿种关键词的组合中，最终挑出45个重要的检索词条和55个次重要词条（归并成12类）作为特征，训练了一个线性回归模型 〔15〕 预测2007年和2008年冬季流感传播的趋势和地点，并且将机器预测的结果和疾病控制与预防中心公布的数据进行比对，发现准确率高达97%以上。 受到这篇论文的启发，疾病控制与预防中心在2009年了解禽流感疫情时采用了同样的方法，获得了更有效、更及时的数据。这个案例后来被各种媒体报道，成为利用大数据解决医疗问题的经典案例。在这个例子中，最关键的是建立起了数据之间的相关性，即疾病传播和该地区搜索关键词变化的关系。 — location: [340]() ^ref-53873

---
过去预报疫情传统的方法是由各地医院、诊所和医务人员向美国疾病控制和预防中心（Centers for Disease Controland Prevention，简称CDC）上报。但是这种方法的延时大约有10天至两周，而两周内疫情早已迅速扩散，因此公共卫生专家需要找到新的办法预测和监控疫情。值得庆幸的是，疾病控制和预防中心的科学家和Google的工程师从2007年到2008年一起合作研究了流行病传播和各地区搜索量变化的关系，并且于2009年2月在著名的《自然》杂志上发表了他们的研究成果 〔14〕 ——通过各地区用户在Google上搜索和流感有关的关键词的趋势变化，预测流感流行到什么地方了。Google的工程师们从4.5亿种关键词的组合中，最终挑出45个重要的检索词条和55个次重要词条（归并成12类）作为特征，训练了一个线性回归模型 〔15〕 预测2007年和2008年冬季流感传播的趋势和地点，并且将机器预测的结果和疾病控制与预防中心公布的数据进行比对，发现准确率高达97%以上。 受到这篇论文的启发，疾病控制与预防中心在2009年了解禽流感疫情时采用了同样的方法，获得了更有效、更及时的数据。这个案例后来被各种媒体报道，成为利用大数据解决医疗问题的经典案例。在这个例子中，最关键的是建立起了数据之间的相关性，即疾病传播和该地区搜索关键词变化的关系。 — location: [338]() ^ref-49859

---
鉴于完美的模型未必存在，即使存在，找到它也非常不容易，而且费时间，因此就有人考虑是否能通过用很多简单不完美的模型凑在一起，起到完美模型的效果呢？比如说，是否可以通过很多很多圆互相嵌套在一起，建立一个地心说模型，和牛顿推演出的日心说模型 〔16〕 一样准确呢？如今这个答案是肯定的，从理论上讲，只要找到足够多的具有代表性的样本（数据），就可以运用数学找到一个模型或者一组模型的组合，使得它和真实情况非常接近。 — location: [414]() ^ref-57144

---
这种思路在现实生活中已经被用到。比如美国和苏联在设计飞机、航天器和其他武器上的理念和方法就不同。苏联拥有大量数学功底非常深厚的设计人员，但是缺乏高性能的计算机和大量的数据，因此其科学家喜欢寻找比较准确但是复杂的数学模型；而美国的设计人员相比之下数学功底平平，但是美国的计算机拥有强大的计算能力和更多的数据，因此其科学家喜欢用很多简单的模型来替代一个复杂的模型。这两个国家做出的东西可谓各有千秋，但从结果来看，似乎美国的更胜一筹。 — location: [419]() ^ref-21407

---
在工程上，采用多而简单的模型常常比一个精确的模型成本更低，也被使用得更普遍。比如在光学仪器的设计上，一个完美的镜头里面的透镜其实不应该是球面镜，因为那样边缘的图像会变形，只有采用抛物面或者其他复杂曲面，才能使得整个画面都清晰。但是这些非球面透镜的加工需要技艺高超的技工。德国因为拥有最好的技工，因此敢于在镜头设计上采用非球面透镜，这样整个光学仪器就非常小巧。而日本缺乏这种水平的技工，但是善于用机器加工，因此日本人在设计光学仪器时，就用好几个球面透镜来取代一个非球面透镜，这样的光学仪器虽然显得笨重，但是容易大规模生产，而且成本非常低。“二战”后，日本超过德国成为全球光学仪器（包括相机）第一大制造国。 — location: [423]() ^ref-16927

---
回到数学模型上，其实只要数据量足够，就可以用若干个简单的模型取代一个复杂的模型。这种方法被称为数据驱动方法，因为它是先有大量的数据，而不是预设的模型，然后用很多简单的模型去契合数据（Fit Data）。虽然这种数据驱动方法在数据量不足时找到的一组模型可能和真实的模型存在一定的偏差，但是在误差允许的范围内，单从结果上看和精确的模型是等效的 〔17〕 ，这在数学上是有根据的。从原理上讲，这类似于前面提到的切比雪夫大数定律。 — location: [429]() ^ref-543

---
当然，数据驱动方法要想成功，除了数据量大之外，还要有一个前提，那就是样本必须非常具有代表性， — location: [434]() ^ref-7250

---
数据驱动方法最大的优势在于，它可以在最大程度上得益于计算机技术的进步。尽管数据驱动方法在一开始数据量不足、计算能力不够时，可能显得有些粗糙，但是随着时间的推移，摩尔定律保证了计算能力和数据量以一个指数级增长的速度递增，数据驱动方法可以非常准确。相比之下，很多其他方法的改进需要靠理论的突破，因此改进起来周期非常长。在过去的30年里，计算机变得越来越聪明，这并非是因为我们对特定问题的认识有了多大的提高，而是因为在很大程度上我们靠的是数据量的增加。 — location: [439]() ^ref-47231

---
大量数据的使用，最大的意义在于它能让计算机完成一些过去只有人类才能做到的事情，这最终将带来一场智能革命。 — location: [487]() ^ref-42903

---
但是语音识别准确率的提高，主要是靠20世纪90年代以后数据的大量积累。从这个研究领域，大家开始看到了数据的重要性。类似地，图像识别也取得了根本性的突破。 — location: [490]() ^ref-10144

---
让一台机器和一个人坐在幕后，让一个裁判同时与幕后的人和机器进行交流，如果这个裁判无法判断自己交流的对象是人还是机器，就说明这台机器有了和人同等的智能。这种方法被后人称为图灵测试（Turing Test）。 — location: [519]() ^ref-43752

---
1．语音识别 2．机器翻译 3．文本的自动摘要或者写作 4．战胜人类的国际象棋冠军 5．自动回答问题 — location: [521]() ^ref-8817

---
1968年，明斯基在《语义信息处理》（Semantic Information Processing ）一书中分析了所谓人工智能的局限性，他引用了巴希勒（Bar-Hillel）使用过的一个非常简单的例子： The pen was in the box（钢笔在盒子里），这句话很好理解，如果让计算机理解它，做一个简单的语法分析即可。但是另一句语法相同的话： The box was in the pen. 图2.5　钢笔在盒子里，这句话很好理解 就让人颇为费解了。原来，在英语中，pen（钢笔）还有另外一个不太常用的意思——小孩玩耍的围栏。在这里，理解成这个意思整个句子就通顺了。但是，如果用同样的语法分析，这两句话会得到相同的语法分析树，而仅仅根据这两句话本身，甚至通篇文章，是无法判定pen在哪一句话中应该作为围栏，在哪一句话中应该是钢笔的意思。事实上人对这两句话的理解并非来自语法分析和语意本身，而是来自他们的常识或者说关于世界的知识（world knowledge），这个问题是传统的人工智能方法解决不了的。因此，明斯基给出了他的结论：“目前”（指1968年）的方法无法让计算机真正有类似于人的智能。由于明斯基在计算机科学界具有崇高的声望，他的这篇论文导致美国政府削减了几乎全部人工智能研究的经费，在之后大约20年左右的时间里，全世界人工智能在学术界的研究是处于低谷的。 — location: [564]() ^ref-39481

---
贾里尼克从来不是一位人工智能专家，他是一位通信专家，因此他看待语音识别问题的角度和先前的计算机科学家们都不相同——在他看来，语音识别不是一个人工智能的问题，而是一个通信问题。 — location: [592]() ^ref-17280

---
1972年，康奈尔大学的教授弗雷德·贾里尼克（Fred Jelinek，1932—2010）到IBM做学术休假 〔3〕 ，正好这时IBM想开发“聪明的计算机”，贾里尼克就“临时”负责起这个项目。至于什么是聪明的计算机，当时大家的共识是它要么能够听懂人的话，要么能将一种语言翻译成另一种语言，要么能够赢得了国际象棋的世界冠军。贾里尼克根据自己的特长和IBM的条件，选择了第一个任务，即计算机自动识别人的语音。 — location: [582]() ^ref-48711

---
既然是一个典型的通信问题，就可以用解决通信问题的方法来解决，为此贾里尼克用两个数学模型（马尔可夫模型）分别描述信源和信道。至于计算机识别时需要从语音中提取什么特征，贾里尼克的想法很简单，数字通信采用什么特征，语音识别就采用什么特征。 — location: [596]() ^ref-35608

---
正如我们在前面介绍的，找到了数学模型之后，下一步就是要用统计的方法“训练出”模型的参数，这在今天来讲就是机器学习。在这个过程中，需要使用大量的数据，同时要有足够的计算能力。在当时，只有IBM具备这些条件。那时不仅没有互联网上大量的内容，甚至没有很多存在计算机里的文本（又称机读文本），好在IBM有大量的电传文本，这成了IBM语音识别系统使用的最早期的数据。 — location: [600]() ^ref-26176

---
贾里尼克除了找到一条不同于传统人工智能的语音识别方法，另一个特点就是喜欢招收数学基础好的，特别是学习过理论物理的员工。出于某种原因，他不喜欢语言学家并且把他们都请出了IBM。贾里尼克的团队花了4年的时间，就开发了一个基于统计方法的语音识别系统，它的语音识别率从过去的70%左右提高到90%以上，同时语音识别的规模从几百词上升到两万多词。这样语音识别就有了本质的飞跃。 — location: [605]() ^ref-25513

---
贾里尼克和他的同事在研究语音识别时，无意中开创了一种采用统计的方法解决智能问题的途径，因为这种方法需要使用大量的数据，因此又被称为数据驱动方法。这种方法最大的好处是，随着数据量的积累，系统会变得越来越好，相比之下过去人工智能的方法很难受益于数据量的提升。 — location: [612]() ^ref-41654

---
后来在IBM和Google先后担任过主管研究的副总裁艾尔弗雷德·斯伯格特（Alfred Spector）博士，20世纪80年代时是卡内基-梅隆大学的教授，据他介绍，当年卡内基-梅隆大学已经在传统的人工智能领域走得非常远了，大家遇到了很多跨不过去的障碍。后来教授们去IBM沃森实验室参观，看到那里采用数据驱动方法取得的巨大成绩，回来以后很多教授接受了这种新的方法论。李开复就是在这样的背景下，在传统的人工智能实验室里，采用基于统计的方法开展他的博士论文的工作，并且最终和洪小文一起构建了世界上第一个大词汇量、非特定人、连续语音识别系统 〔4〕 。按照斯伯格特的说法，如果没有李开复等人的工作，他们的论文导师瑞迪（Raj Reddy）不可能获得图灵奖。 — location: [615]() ^ref-5841

---
在语音识别和自然语言理解领域，提倡数据驱动的一派比较快地占了上风；而在图像识别和机器翻译方面，在较长时间里，数据驱动这一派处于下风。这里面主要的原因是，在图像识别和机器翻译领域，过去的数据量非常少，而这种数据的积累非常困难。图像识别就不用讲了，在互联网出现之前，没有一个实验室有上百万张图片。在机器翻译领域，所需要的数据除了一般的文本数据，还需要大量的双语（甚至是多语种）对照的数据，而在互联网出现之前，除了《圣经》和少量联合国文件，再也找不到类似的数据了。 — location: [628]() ^ref-33682

---
在20世纪90年代互联网兴起之后，数据的获取变得非常容易。从1994年到2004年的10年里，语音识别的错误率减少了一半，而机器翻译的准确性 〔8〕 提高了一倍，其中20%左右的贡献来自方法的改进，80%则来自数据量的提升。虽然在每一年，计算机在解决各种智能问题上的进步幅度并不大，但是十几年量的积累，最终促成了质变。 — location: [637]() ^ref-9321

---
数据创造奇迹：量变到质变 从某种意义上讲，2005年是大数据元年，虽然大部分人感受不到数据带来的变化，但是一项科研成果却让全世界从事机器翻译的人感到震惊，那就是之前在机器翻译领域从来没有技术积累、不为人所知的Google，以巨大的优势打败了全世界所有机器翻译研究团队，一跃成为这个领域的领头羊。 — location: [641]() ^ref-48691

---
这一年的7月，大家来到NIST所在的弗吉尼亚州北部开会交流经验，奥科则是这次会议的焦点人物。大家都想听他的秘诀，但是这个秘诀一讲出来就不值钱了，他用的还是两年前的方法，但是用了比其他研究所多几千倍甚至上万倍的数据。 — location: [665]() ^ref-55167

---
。简单地讲，一个好的三元模型可以准确地构造英语句子中的短语和简单的句子成分之间的搭配，而六元模型则可以构造整个从句和复杂的句子成分之间的搭配， — location: [671]() ^ref-9461

---
但是，当奥科用了上万倍的数据时，量变的积累就导致了质变的发生。奥科能训练出一个六元模型，而当时大部分研究团队的数据量只够训练三元模型 〔11〕 。简单地讲，一个好的三元模型可以准确地构造英语句子中的短语和简单的句子成分之间的搭配，而六元模型则可以构造整个从句和复杂的句子成分之间的搭配，相当于将这些片段从一种语言到另一种语言直接对译过去了。 — location: [669]() ^ref-14301

---
在Google之則，不是没有人想到五元或者六元模型，但是如果没有充足的数据，那么训练出来的五元或六元模型准确性非常差，对翻译没有任何帮助。 — location: [674]() ^ref-22070

---
如今在很多与“智能”有关的研究领域，比如图像识别和自然语言理解，如果所采用的方法无法利用数据量的优势，会被认为是落伍的。 — location: [678]() ^ref-10955

---
数据驱动方法从20世纪70年代开始起步，在八九十年代得到缓慢但稳步的发展。进入21世纪后，由于互联网的出现，使得可用的数据量剧增，数据驱动方法的优势越来越明显，最终完成了从量变到质变的飞跃。如今很多需要类似人类智能才能做的事情，计算机已经可以胜任了，这得益于数据量的增加。 — location: [680]() ^ref-35742

---
数据之间的关联性极大地增强， — location: [684]() ^ref-50447

---
大数据最明显的特征是体量大，这一点无论是内行还是外行都认可，没有什么异议。但是仅仅有大量的数据并不一定是大数据， — location: [686]() ^ref-49522

---
大数据之所以有用，是因为它除了数据量大以外，还具有其他的特征。一些数据专家将大数据的特征概括成三个V，即大量（Vast）、多样性（Variety）和及时性（Velocity）， — location: [692]() ^ref-10411

---
计算机利用数学模型，能够在棋盘的任何一个状态下，比如说某个状态叫作S，评估出自己和对方获胜的概率为P（S） 。当它要考虑接下来可能的走法，比如说有N种 〔20〕 走法时，先要考察这些走法分别对应状态，假设是^、叉……心，计算出相应的获胜概率P（S（A）、……P（S），……N）。根据这些概率，深蓝找出一个让自己获胜概率最大的状态，我们不妨假设是S（A），它就往这个方向走。接下来，该对方走棋了，对方走出一步棋后棋盘进入一个新的状态S '' 。这时深蓝再根据自己能够选择的有限种走法，假如这回是M种，分别对应状态S '' 1 、^1、〇2......^M，再计算出每一个对应的新状态的胜率P （S'' 1 ）、P （S '''2 ）……P （S '''M ），然后挑一个产生最大胜率的走法，比如是P （S i '''）, — location: [831]() ^ref-7798

---
此外，作为机器，深蓝还具有卡斯帕罗夫所不具备的另一个优势，那就是不受情绪的影响，发挥可以相对稳定。这个性质在很多智能应用中至关重要。 — location: [851]() ^ref-21181

---
在计算机自动问答研究领域，科学家们已经研究了多年。通常我们把问题归结为7类：“是什么”（What）、“什么时候”（When）、“什么地点”（Where）、“哪一个”（Which）、“是谁”（Who）、“为什么”（Why）和“怎么做”（How）。由于它们都是以W或者H开头的，这7个疑问词又被称为WH单词（WH words），各种问题也被称为WH语句。 — location: [864]() ^ref-7588

---
难回答的是询问原因的“为什么”（Why）问题，以及询问过程的“怎么做”（How）问题。全世界的自然语言处理专家和机器智能专家对这两类问题的机器自动问答研究了很多年，直到2012年，都没有找到好的方法。 — location: [868]() ^ref-18998

---
即在方法论的层面，大数据是一种全新的思维方式。按照大数据的思维方式，我们做事情的方式与方法需要从根本上改变。 — location: [940]() ^ref-32394

---
今天说起机械思维，很多人马上想到的是死板、僵化，觉得非常落伍，甚至“机械”本身都算不上什么好词。但是在两个世纪之前，这可是一个时髦的词，就如同今天我们说互联网思维、大数据思维很时髦一样。可以毫不夸张地讲，在过去的三个多世纪里，机械思维可以算得上是人类总结出的最重要的思维方式，也是现代文明的基础。 — location: [945]() ^ref-3171

---
机械思维是如何产生的？为什么它的影响力能够延伸至今，它和我们将要讨论的大数据思维又有什么关联和本质区别呢？ — location: [949]() ^ref-12392

---
思维方式决定科学成就：从欧几里得、托勒密到牛顿 机械思维的形成可以追溯至古希腊。欧洲之所以能够在科学上领先于世界其他地方，在很大程度上是依靠从古希腊建立起来的思辨的思想和逻辑推理的能力，依靠它们可以从实践中总结出最基本的公理，然后通过因果逻辑构建起整个科学的大厦。 — location: [950]() ^ref-54841

---
在欧几里得之后大约5个世纪，古希腊罗马时代最伟大的天文学家托勒密将欧几里得的这种方法论应用到天文学上，建立起一套完整、严格而且相当精确的描述天体运动规律的理论体系，即地心说。讲到托勒密要顺便提一句，有些时候，一些好心人建议我将书中“最伟大”之类的词改成“最伟大的之一”，以免犯错误，或者他人有异议。其实，写书表达思想是一件颇为主观的事情，最重要的不是避免犯错误，而是不可缺乏思想。在我看来，托勒密在近代之前是当之无愧的最伟大的天文学家，没有之一。 — location: [965]() ^ref-16591

---
欧几里得将他的公理化体系几何学写成了一本书，名为《几何原本》，这也是对世界影响力最大的一本书。欧几里得的这种基于逻辑推理的公理化系统不仅为几何学、数学和自然科学后来的发展奠定了基础，而且对西方人的整个思维方法都有极大的影响。甚至在法学界，整个罗马法都是建立在类似于欧几里得公理系统这样的基础上的，当然罗马法里面的公理不是几何学的，而是自然法 〔2〕 ——所有的法律都可以从自然法中演绎出来。 — location: [961]() ^ref-24128

---
应该讲，托勒密等人的方法虽然很朴素，但是很管用，直到今天，我们在做事情的时候还是会首先想到这种方法，比如几乎所有经济学家的理论，都是按照这种方法提出来的。如果我们把他们的方法论做一个简单的概括，其核心思想有如下两点：首先，需要有一个简单的元模型，这个模型可能是假设出来的，然后再用这个元模型构建复杂的模型；其次，整个模型要和历史数据相吻合。 — location: [983]() ^ref-27580

---
思维方式和方法远不如方法论对科学的发展至关重要，东方的文明长期以来在技术上领先于西方，但是在科学体系的建立上远远落后于西方，关键是输在方法论上。 — location: [988]() ^ref-22559

---
托勒密方法论的第二缺陷是致命的，那就是确定性假设。它假定模型一旦产生，就是确定的和不会改变的。机械论延续了这种先验假设。 — location: [992]() ^ref-10747

---
在古希腊罗马以后，人类对自然界的认识进步非常缓慢，西方进入了中世纪的黑暗时代。东方的中国和阿拉伯帝国虽然在工程和技术上不断进步，但是既没有形成科学体系，也没有在方法论方面做出太多的贡献。最终，发展科学方法的任务留给了笛卡儿和牛顿。笛卡儿的贡献在于提出了科学的方法论，即大胆假设，小心求证，这个方法论在我们今天的工作中还在使用。不过对近代社会思想贡献最大的还是著名科学家和思想家牛顿。 — location: [996]() ^ref-29901

---
牛顿最直接的贡献，在于他用简单而优美的数学公式破解了自然之谜。牛顿在他的巨著《自然哲学之数学原理》（简称《原理》）一书中，用几个简明的公式（力学三定律和万有引力定律）破解了宇宙中万物运动的规律，用微积分的概念把数学从静止的变量拓展为连续变化函数。在他的《光学》一书中，他把看上去虚幻的光分解为单个原色。 牛顿通过自己的伟大成就宣告了科学时代的来临，作为思想家，他让人们相信世界万物的运动变化规律是可以被认识的。他告诉人们：世界万物是运动的，而且这些运动遵循着确定性的规律，这些规律又是可以被认识的。 — location: [1007]() ^ref-15960

---
后来人们将牛顿的方法论概括为机械思维，其核心思想可以概括成这样几句话： 第一，世界变化的规律是确定的， — location: [1027]() ^ref-44102

---
第二，因为有确定性做保障，因此规律不仅是可以被认识的，而且可以用简单的公式或者语言描述清楚。 — location: [1028]() ^ref-37548

---
第三，这些规律应该是放之四海而皆准的，可以应用到各种未知领域指导实践，这种认识是在牛顿之后才有的。 — location: [1030]() ^ref-6982

---
瓦特还发明了一种通用的机器用以解决所有的问题。在瓦特之前的蒸汽机是为特定目的设计和制造的，很难从一个厂矿拆下来用于其他地方。瓦特的蒸汽机的通用性则要好很多，同一种蒸汽机可以卖到不同的工厂。这也是机械思维的重要特征——所有问题有一个通用的解决方法。 — location: [1044]() ^ref-9841

---
正是因为瓦特蒸汽机的这个特性，才使得工业革命后有了“蒸汽机+现有产业=新产业”的模式。 — location: [1047]() ^ref-42648

---
机械的广泛使用和机械的思维方式直接导致了人类迄今为止最为伟大的事件——工业革命。在工业革命之前的两千年里，世界各地的人们的生活水平其实没有太大的提高。已故著名历史学家安格斯·麦迪森（Angus Maddison，1926—2010）对全球各个文明在不同历史时期所做的经济学研究发现，世界人均财富从公元元年左右到18世纪工业革命前是没有提高的 〔5〕 。但是，到了工业革命之后，情况就大不相同了。马克思曾经讲过：“资产阶级在其不到100年的阶级统治中所创造的生产力，比过去一切时代创造的全部生产力还要多，还要大。” — location: [1062]() ^ref-14446

---
牛顿的物理学理论是建立在确定性基础，即所谓的绝对时空 〔7〕 之上的，他发现万有引力定律则是寻找因果关系的结果。牛顿发现行星围绕太阳运动这个结果，然后找到了万有引力这个原因。爱因斯坦的研究方式是类似的，他的理论也是建立在一种确定性——光速恒定的基础之上的，基于这种假设，利用逻辑推理，就可以推导出整个狭义相对论。就连爱因斯坦自己也说，如果不是他，也会有人在很短的时间内发现狭义相对论，因为狭义相对论就是光速恒定的必然结果。类似地，如果将重力和加速度等价起来，利用因果逻辑，就能推导出广义相对论。 — location: [1089]() ^ref-29172

---
当然，机械思维的局限性更多来源于它否认不确定性和不可知性。爱因斯坦有句名言——“上帝不掷色子”，这是他在和量子力学的发明人波尔等人争论时讲的话。今天我们知道，在这场争论中，波尔等人是正确的，爱因斯坦错了，上帝也掷色子。 — location: [1102]() ^ref-37494

---
张首晟教授也让我给出三个公式。有两个公式我们是不约而同想到的，即质能转换和熵的定义。 — location: [1108]() ^ref-24543

---
青霉素真正得以从偶然的发现变成一种万灵药，在很大程度上是科学家们自觉应用因果逻辑的结果。在制药这个行业，直到今天其核心的方法都遵循“研究病理找到真正致病的原因，然后针对这个原因找到解决方案”。 — location: [1122]() ^ref-50983

---
从牛顿开始，人类社会的进步在很大程度上得益于机械思维，但是到了信息时代，它的局限性也越来越明显。首先，并非所有的规律都可以用简单的原理描述；其次，像过去那样找到因果关系已经变得非常困难，因为简单的因果关系规律性都被发现了。另外，随着人类对世界认识得越来越清楚，人们发现世界本身存在着很大的不确定性，并非如过去想象的那样一切都是可以确定的。因此，在现代社会里，人们开始考虑在承认不确定性的情况下如何取得科学上的突破，或者把事情做得更好。这也就导致一种新的方法论诞生。 — location: [1136]() ^ref-58688

---
在概率论的基础上，香农博士建立起一套完整的理论，将世界的不确定性和信息联系了起来，这就是信息论。信息论不仅仅是通信的理论，也给了人们一种看待世界和处理问题的新思路。 — location: [1173]() ^ref-54949

---
总之，世界上很多事情是难以用确定的公式或者规则来表示的。但是，它们并非没有规律可循，通常可以用概率模型来描述。在概率论的基础上，香农博士建立起一套完整的理论，将世界的不确定性和信息联系了起来，这就是信息论。信息论不仅仅是通信的理论，也给了人们一种看待世界和处理问题的新思路。 — location: [1172]() ^ref-11414

---
不论是因为数据量太大导致的不确定性，还是因为世界本身带有的不确定性，总之，世界上很多事情是难以用确定的公式或者规则来表示的。但是，它们并非没有规律可循，通常可以用概率模型来描述。在概率论的基础上，香农博士建立起一套完整的理论，将世界的不确定性和信息联系了起来，这就是信息论。信息论不仅仅是通信的理论，也给了人们一种看待世界和处理问题的新思路。 — location: [1171]() ^ref-7852

---
那么如何度量信息呢？这个问题其实是几千年来很多人想知道却无法回答的问题。直到1948年，克劳迪·香农在他著名的论文《通信的数学原理》（A Mathematic Theory of Communication ）中提出了“信息熵”的概念，才解决了对信息的度量问题，并且量化地给出了信息的作用。同时，香农还把信息和世界的不确定性，或者说无序状态联系到了一起。 — location: [1183]() ^ref-34077

---
，其中鲁道夫·克劳修斯（Rudolf Clausius）提出了一种叫作“熵”的概念，来描述一个系统中趋向于恒温的程度。当这个系统完全达到恒温时，就无法做功了，这时熵最大。 — location: [1189]() ^ref-36784

---
玻尔兹曼则把熵（宏观特性Entropy）和封闭系统的无序状态（每一个分子的微观特性Ω）联系起来，即： E=klog（Ω） 其中k被称为玻尔兹曼常数。玻尔兹曼等人还发现，在一个封闭的系统中，熵永远是朝着不断增加的方向发展的，也就是说从微观上讲，这个系统越来越无序， — location: [1191]() ^ref-27539

---
香农在信息论中借用了热力学里熵的概念，他用熵来描述一个信息系统的不确定性。接下来香农指出，信息量与不确定性有关：假如我们需要搞清楚一件非常不确定的事，或是我们一无所知的事情，就需要了解大量的信息。相反，如果我们对某件事已经有了较多的了解，那么不需要太多的信息就能把它搞清楚。所以，从这个角度来看，可以认为，信息量的度量就等于不确定性的多少，这样香农就把熵和信息量联系起来了。他还指出要想消除系统内的不确定性，就要引入信息。 — location: [1195]() ^ref-45490

---
虽然香农提出信息论最初的目的只是建立通信的科学理论，但是，信息论的作用远不止在科学和工程上——它也是一种全新的方法论。与机械思维是建立在一种确定性的基础上所截然不同的是，信息论完全是建立在不确定性基础上，而要想消除这种不确定性，就要引入信息。至于要引入多少信息，则要看系统中的不确定性有多大。这种思路成为信息时代做事情的根本方法。我们不妨用互联网广告的例子来说明上述原理的作用。 — location: [1203]() ^ref-45819

---
。搜索广告因为有用户输入的关键词，准确率会大幅提高，至于提高了多少，取决于关键词所提供的信息量。 — location: [1210]() ^ref-11296

---
假定还是从10万种广告中猜10个，这时猜中的可能性就是十几分之一到几分之一，因此读者点击广告的可能性大增。在实际情况中，Google搜索广告每1000次展示所带来的收入大约是50美元，比展示广告高出两个数量级。 — location: [1212]() ^ref-13222

---
类似地，我们大致计算出，像Facebook或者Google通过挖掘注册用户的使用习惯，大约能够获得12比特的信息量，这样就将广告匹配的难度下降了大约一半，事实上，那些与用户相关的展示广告比完全随机的正好产生高一倍左右的广告收入。 上面虽然是一个特定的例子，但是反映出在信息时代的方法论：谁掌握了信息，谁就能够获取财富， — location: [1214]() ^ref-53277

---
再比如要识别一个人脸的图像，实际上可以看成是从有限种可能性中挑出一种，因为全世界的人数是有限的，这也就把识别问题变成了消除不确定性的问题。我们在前面一章里讲到了贾里尼克等人的工作，从那时开始，人类在机器智能领域的成就，其实就是不断地把各种智能问题转化成消除不确定性的问题，然后再找到能够消除相应不确定性的信息，如此而已。 我们在利用信息时使用的很多原理和方法，在信息论中都能找到根据。比如用信息论中的一个重要概念——互信息（Mutual Information），可以解释为什么信息的相关性可以帮助我们解决很多问题。 — location: [1220]() ^ref-19258

---
当然“有关联”这种说法太模糊，不科学，最好能够量化地度量两件事之间的“相关性”。为此，在信息论里用互信息这个概念，实现了对相关性的量化度量。 — location: [1227]() ^ref-50834

---
香农第一定律，也称为香农信源编码定律，它大致的含义是这样的：假定有一个信息源，里面有N种信息，现在我们需要对这N种信息—一进行编码，比如我们用0011表示第一种信息，10000111表示第二种.这些编码当然不能重复，否则我们就无法根据编码来断定是哪一种信息了。虽然编码可以有很多种方法，但是有的方法效率局，有的则效率低，或者说用了很长的编码才能表示一个信息。香农第一定律讲的是，对于信源发出的所有信息设计一种编码，那么编码的平均长度一定大于该信源的信息熵，但同时香农还指出，一定存在一种编码方式，使得编码的平均长度无限接近于它的

ADD NOTE

HIGHLIGHT (YELLOW) • LOCATION 1238

对于没有学过信息论的读者而言，上面这段话可能有点费解，让我们看一个具体的例子就好理解了。比如要对汉字编码，有些字用得多，有些字用得少，因此可以把常用字的编码做得短些，生僻字的编码做得长些，但是不论怎么做，编码的平均长度一定会超过汉字的不确定性，即它们的信息熵，这是香农第一定律的第一层意思。同时，香农第一定律还有第二层意思，也就是说一定存在一种（最优的）编码方法，使得每个汉字的平均编码长度可以非常接近它的不确定性（信息熵）。至于怎么才能做到，霍夫曼（Huffran）给了一个非常简单的方法—只要把最短的编码分配给最常见的汉字即可。这种编码方法具有通用性，又称为霍夫曼编码，它可以被认为是对香农第一定律的补充。香农第一定律不仅是现代通信的基础，也代表了一种新的方法论。经济学上的吉尔德定律（Gilder'sLaw），即尽量多地采用便宜的资源，尽可能节省贵的资源，与信息论中的霍夫曼编码从本质上讲是相同的。在信息时代，由于摩尔定律的作用，计算机是便宜的资源，而且越来越便宜，人力成本则会越来越局，因此聪明的公司懂得利用计算机来取代人的工作，像Google或者Facebook这样的公司，都是尽可能地將越来越多的事情交给机器去做，而不是雇用很多人。在过去的半个世纪里，生产力的提高实际上就是靠用便宜的机器取代人工，这种做法有意无意地和信息论的原理相符合。当然，也有的企业主不愿意在T方面进行投入而坚持使用人工，因为这种投入在初期看上去显得比人工昂贵，这些企业后来就逐渐地被淘汰了。

ADD NOTE

HIGHLIGHT (YELLOW) • LOCATION 1250

在信息论中，还有香农第二定律，通俗地讲就是信息的传播速率不可能超过信道的容量，这和我们的现实生活也是契合的。我们经历了互联网发展全过程的这一代人都有这样一种体会，互联网发展的各个阶段实际上是建立在不断拓宽带宽的基础之上的。

ADD NOTE

HIGHLIGHT (YELLOW) • LOCATION 1257

香农第二定律不仅描述了通信领域最根本的规律，而且它是自然界本身所固有的规律，能够解释很多商业行为。比如我们常说做生意要靠人脉，其实这个人脉就是人与人交往的带宽。如果人脉不够，发出的信息和获得的信息都有限，生意一定做不大。现代通信手段的本质，就是以相对低廉的成本让人们获得人脉，而媒体行业的不断进步，本质上是不断地在为企业拓宽对外连接的带宽，使得它们做生意越来越方便。

ADD NOTE

HIGHLIGHT (YELLOW) • LOCATION 1260

关于信息论，还有一个原理必须了解，那就是最大熵原理。这个原理的大意是说，当我们要对未知的事件寻找一个概率模型时，这个模型应当满足我们所有已经看到的数据，但是对未知的情况不要做任何主观假设。在很多领域，尤其是金融领域，采用最大熵原理要比任何人为假定的理论更有效，因此它被广泛地用于机器学习。最大熵原理实际上已经不同于我们使用了几百年的“大胆假设、小心求证”的方法论，因为它要求不引入主观的假设。当然，不做主观假设的前提是取得了足够多的数据，否则最大嫡模型只能给出一些平均值而已，而不能对任何细节进行描述和预测。〔12〕今天，信息论已经被广泛地用于管理，因为它为我们提供了信息时代的方法论。而熵这个词，也成了信息论和不确定性的代名词。


大数据的本质

HIGHLIGHT (YELLOW) • LOCATION 1268

大数据的本质有了信息论这样一个工具和方法论，我们便很容易认清大数据的本质了。首先我们必须承认世界的不确定性，这样我们就不会采用确定性的思维方式去面对一个不确定性的世界。当我们了解到信息或者说数据能够消除不确定性之后，便能理解为什么大数据的出现能够解决那些智能的问题，因为很多智能问题从根本上来讲无非是消除不确定性的问题。对于前面提到的大数据的三个特征，即数据量大、多维度和完备性，我们可以从信息论出发，对它们的重要性和必要性一一做出解释。

ADD NOTE

HIGHLIGHT (YELLOW) • LOCATION 1273

先谈谈数据量的问题。在过去，由于数据量不够，即使使用了数据，依然不足以消除不确定性，因此数据的作用其实很有限，很多人忽视它的重要性是必然的。在那种情况下，哪个领域先积攒下足够多的数据，它的研究进展就显得快一些。具体到机器智能方面，语音识别是最早获得比较多数据的领域，因此数据驱动的方法从这个领域产生也就不足为奇了。

ADD NOTE

HIGHLIGHT (YELLOW) • LOCATION 1276

关于大数据多维度的重要性问题，可以从两个角度来看待它。第一个视角是前面提及的“互信息”，为了获得相关性通常需要多个维度的信息。比如我们要统计“央行调整利息”和“股市波动”的相关性，只有历史上央行调整利息一个维度的信息显然是不够的，需要上述两个维度的信息同时出现。第二个视角是所谓的“交叉验证”，

ADD NOTE

HIGHLIGHT (YELLOW) • LOCATION 1284

交叉熵，这个概念并非由香农提出的，而是由库尔贝克等人提出的，因此在英文里更多地被称为库尔贝克-莱伯勒距离（Kullback-Leibler Divergence），它可以反映两个信息源之间的一致性，或者两种概率模型之间的一致性。当两个数据源完全一致时，它们的交叉熵等于零，当它们相差很大时，交叉熵也很大。所有采用数据驱动的方法，建立模型所使用的数据和使用模型的数据之间需要有一致性，也就是盖洛普所讲的代表性，否则这种方法就会失效，而交叉熵就是对这种代表性或者一致性的一种精确的量化度量。

ADD NOTE

HIGHLIGHT (YELLOW) • LOCATION 1288

回过头来讲大数据的完备性。在过去，使用任何基于概率统计的模型都会有很多小概率事件覆盖不到，这在过去被认为是数据驱动方法的死穴。很多学科把这种现象称为“黑天鹅效应”〔13〕。在大数据出来之前，这件事是无法避免的，就连提出数据驱动方法的鼻祖贾里尼克也认为，不论统计数据量多大，都会有漏网的情况。这些漏网的情况反映到交叉熵时，它的值会达到无穷大，也就是说数据驱动方法在这个时候就失效了。怎样才能防止出现很多漏网的情况呢？这就要求大数据的完备性了。在大数据时代，在某个领域里获得数据的完备性还是可能的。比如在过去把全国所有人的面孔收集全是一件不可想象的事情，但是今天这件事情完全能做到。当数据的完备性具备了之后，就相当于训练模型的数据集合和使用这个模型的测试集合是同一个集合，或者是高度重复的，这样，它们的交叉熵近乎零。在这种情况下，就不会出现覆盖不了很多小概率事件的灾难。这样数据驱动才具有普遍性，而不再是时灵时不灵的方法论。

ADD NOTE

从因果关系到强相关关系

HIGHLIGHT (YELLOW) • LOCATION 1360

2003年Google推出了根据网页内容安插广告的AdSense服务〔20〕，以与那些在网页中随机投放广告的产品竞争。


数据公司Google

HIGHLIGHT (YELLOW) • LOCATION 1378

数据公司 Google在一般人眼里，Google是一家局科技公司，不断地研发新的技术，并且成功地将一部分技术转化成了产品。但是，它从根本上讲其实是一家数据公司。著名的机器智能专家，前

Google研究院院长诺威格博士对 Googe的这个本质有深刻的认识。他在接受母校（加州大学伯克利分校）授予他的菜誉证书时，曾经这样讲述他为什么要加入 Google:2001年，当全球互联网泡沫破碎后，大家都在逃离这个领域，很多人从互联网行业回到了学术界。人们问我为什么在这样一个时候离开 NASA（美国国家航空航天局），加入Google这家不大的互联网公司。我和他们讲了大萧条时期（1929—1933年）的一个故事。在大萧条时，有些人买了银行的股票，后来都发了财。事后人们问那些买了银行股票的人为什么在银行如此糟糕时敢买它们的股票，那些投资人讲，“因为全世界的钱都在它们那里。”所以，加入 Google的决定并不难做，因为全世界的数据都在Google那里。

ADD NOTE

HIGHLIGHT (YELLOW) • LOCATION 1391

在所有的数据中，与搜索质量相关性最高的是大量的点击数据，即对于不同的搜索关键词，用户们都点击了哪些搜索结果（网页）。比如对于“虚拟现实”这个查询，用户有31000次点击了网页A，

15000次点击了网页B，11000次点击了网页C在这种情况下，网页A应该被排在第一位，但是如果搜索排序算法不好，有可能出现它没有被排在第一位的情况。这时搜索引擎的设计者就面临一个选择，是采用通过研究改进原有的排序算法，还是干脆相信用户的点击结果，或者是将它们结合在一起。如果单纯改进排序算法，这个周期特别长。如果相信用户点击的结果，其实就是用相关性取代因果关系，当然这里面有两个风险：首先是用户点击容易形成马太效应，排在前面的结果即使不是很相关，也容易获得更多的点击；其次是单纯依靠点击，搜索结果的排名容易被一些使用者操纵。因此，比较稳妥的办法是对用户的点击数据建立一个简单的模型，作为搜索排序算法的一部分。今天，各个搜索引攀都有一个度量用户点击数据和搜索结果相关性的模型，通常被称为“点击模型”。随着数据量的积累，点击模型对搜索结果排名的预测越来越准确，它的重要性也越来越大。今天，它在搜索排序中至少占70%~80%的权重〔21〕，也就是说搜索算法中其他所有的因素加起来都不如它重要。换句话说，在今天的搜索引擎中，因果关系已经没有数据的相关性重要了。当然，点击模型的准确性取决于数据量的大小。对于常见的搜索，比如“虚拟现实”，积累足够多的用户点击数据并不需要太长的时间。但是，对于那些不太常见的搜索（通常也被称为长尾搜索），比如“毕加索早期作品介绍”，需要很长的时间才能收集到“足够多的数据”来训练模型。一个搜索引攀使用的时间越长，数据的积累就越充分，对于这些长尾搜索就做得越准确。微软的搜索引擎在很长的时间里做不过Google的主要原因并不在于算法本身，而是因为缺乏数据。

ADD NOTE

HIGHLIGHT (YELLOW) • LOCATION 1407

当整个搜索行业都意识到点击数据的重要性后，这个市场上的竞争就从技术竞争变成了数据竞争。这时，各公司的商业策略和产品策略就都围绕着获取数据、建立相关性而开展了。后进入搜索市场的公司要想不坐以待毙，唯一的办法就是快速获得数据。比如微软通过接手雅虎的搜索业务，将必应的搜索量从原来Google的10%左右陡然提升到Google的20%~30%，点击模型估计得准确了许多，搜索质量迅速提高。但是即使做到这一点还是不够的，因此一些公司想出了更激进的办法，通过搜索条（Toolbar）、浏览器甚至输入法来收集用户的点击行为。这种办法的好处在于它不仅可以收集到用户使用该公司搜索引擎本身的点击数据，而且还能收集用户使用其他搜索引擎的数据，比如微软通过旧浏览器收集用户使用Google搜索时的点击情况。这样一来，如果一家公司能够在浏览器市场占很大的份额，即使它的搜索量很小，也能收集大量的数据。有了这些数据，尤其是用户在更好的搜索引攀上的点击数据，一家搜索引擎公司可以快速改进长尾搜索的质量。

ADD NOTE

HIGHLIGHT (YELLOW) • LOCATION 1432

很多时候，落后与先进的差距，不是购买一些机器或者引进一些技术就能够弥补的，落后最可怕的地方是思维方式的落后。西方在近代走在了世界前列，很大程度上靠的是思维方式全面领先。机械思维曾经是改变了人类工作方式的革命性的方法论，并且在工业革命和后来全球工业化的过程中起到了决定性的作用，今天它在很多地方依然能指导我们的行动。如果我们能够找到确定性（或者可预测性）和因果关系，这依然是最好的结果。但是，今天我们面临的复杂情况，已经不是机械时代用几个定律就能讲清楚的了，不确定性，或者说难以找到确定性，是今天社会的常态。在无法确定因果关系时，数据为我们提供了解决问题的新方法，数据中所包含的信息可以帮助我们消除不确定性，而数据之间的相关性在某种程度上可以取代原来的因果关系，帮助我们得到我们想知道的答案，这便是大数据思维的核心。大数据思维和原有机械思维并非完全对立，它更多的是对后者的补充。在新的时代，一定需要新的方法论，也一定会产生新的方法论。


第四章 大数据与商业

HIGHLIGHT (YELLOW) • LOCATION 1480

在未来我们可以看到，大数据和机器智能的工具就如同水和电这样的资源，由专门的公司提供给全社会使用。

ADD NOTE

从大数据中找规律

HIGHLIGHT (YELLOW) • LOCATION 1540

2002年，塔吉特连锁百货店聘请统计学硕士安德鲁-波尔（Andrew Pole）来分析数据。在此之前，塔吉特通过信用卡号、接收发票的邮箱〔8〕能把某些顾客与其所购买的商品联系起来（回顾大数据的多维度特征）。但是这些数据有什么用、怎么用，塔吉特并没有考虑。波尔来了以后，就用这些数据分析用户行为。有一天市场部的同事来找他，问他能否判断一位女性顾客是否怀孕了，因为如果一个家庭有了孩子，他们的购物习惯将改变，甚至会疯狂购物，这时，百货店就可以给这些顾客推送相应商品的优惠券，牢牢把握住这些有刚需的用户。

ADD NOTE

HIGHLIGHT (YELLOW) • LOCATION 1557

塔吉特利用大数据的故事非常具有代表性，它反映出大数据和未来商业的关系。但是塔吉特的故事并没有到此结束，接下来的事情就非常戏剧化了。接下来的这一段内容被《福布斯》等多家媒体不断报道和转载，因此读者可能已经读到过了，在这里我就不赞述细节了，只是为了便于讨论，介绍一下故事的梗概〔9〕：有一天，一位中年男子闯进明尼阿波利斯的一家塔吉特商店，要求找他们的经理。在见到经理后，这位男子说：“我那个才上高中的女儿收到了这些优惠券—婴儿的衣服、婴儿的摇车等，你们这是鼓励她过早怀孕么？”经理开始时一头雾水，看了男子手里拿的信件的地址和里面的优惠券，确实是他们寄出去的。于是经理就向这位男子道歉。几天后，这位经理又专门打电话给这位男子，再次道歉，并且了解一下后者对他们的处理是否满意。这回让这位经理吃惊的是，在电话的另一端，那位男子说：“我和女儿谈了，家里有些事情我确实不知道，她真的怀孕了，预产期是8月。我应该向你道歉。”记者杜西格在他的长文中这样评论道：“塔吉特比一个十几岁女孩的父亲先知道他的孩子怀孕了。事实上它很清楚顾客家庭的情况，却装作不知道。这件事就如同跑去相亲的男女，虽然事先已经把对方了解得一清二楚，还装作什么都不知道。”当然，塔吉特挖掘大数据并非为了刺採隐私，而是为了做生意，但是这也从另一方面说明商家掌握了大数据之后，对顾客的需求可以说是了如指掌。相比电子商务公司，塔吉特的IT技术力量并不强，而且作为传统的连锁店，它所收集到的与用户行为相关的数据并不算多，即便如此，在使用大数据之后，它比客户的家庭更了解自家的情况。那些手握更多数据的电子商务公司，诸如亚马逊和阿里巴巴，就更可能比我们更了解我们自己的需求了。

ADD NOTE

巨大的商业利好：相关性、时效性和个性化的重要性

HIGHLIGHT (YELLOW) • LOCATION 1571

巨大的商业利好：相关性、时效性和个性化的重要性在大数据出现之前，并非我们得不到信息直接的关联性，而是需要花费很长的时间才能收集到足够多的数据，然后再花费更长的时间来验证它，这也是过去大部分传统的企业对于细节数据的收集和处理不是很重视的原因，相比之下他们更看重经验和宏观数据。但是到了大数据时代，这些企业的观念也在慢慢转变。

ADD NOTE

HIGHLIGHT (YELLOW) • LOCATION 1587

亚马逊的优势倒不在于价格便宜，事实上美国实体店和网上的价格差不太多，


HIGHLIGHT (YELLOW) • LOCATION 1588

它的优势是能够有针对性地给用户推荐商品，这占到亚马逊销售额的1/3。为什么亚马逊能够做到这一点而沃尔玛做不到呢？这就涉及大数据的时效性等特点了。

ADD NOTE

HIGHLIGHT (YELLOW) • LOCATION 1590

亚马逊在推荐商品方面做得最成功，今天它的销售额中有1/3是靠给用户推荐而产生的。相比沃尔玛，亚马逊有三个优势，首先它的交易数据是即时而完整地记录下来的，而且是随时可以用，可以分析的，因此亚马逊挖掘到类似廉价早餐点心和应急用品的搭配只需要几个小时，而不是多少年。沃尔玛等传统的公司，虽然交易数据都是保留的，但都是支离破碎地存放在各处，有些还是存放在第三方〔10〕，用起来并不方便。亚马逊的第二个优势在于它拥有顾客全面的信息，

ADD NOTE

HIGHLIGHT (YELLOW) • LOCATION 1598

亚马逊的第三个优势在于它的任何市场策略都能马上实现，比如它能够随时捆绑商品，并且随时调整价格进行促销；而美国所有的实体店，调整价格都需要在晚上关门之后进行，因此即使它们数据挖掘的速度和亚马逊一样快（当然这是不可能的），在市场上的反应也跟不上亚马逊这样的电商公司。

ADD NOTE

HIGHLIGHT (YELLOW) • LOCATION 1606

事实证明将顾客聚类的方式效果非常不好，最终亚马逊不得不放弃这种方式。好在随着亚马逊数据量的积累，它可以采用直接但是需要非常大量数据的方法，即它所谓的“由商品直接推荐商品”（Itemto Item），这才使得亚马逊的推荐系统变得准确而有时效性。像沃尔玛这样的百货店，今天能做到把两类商品准确地关联起来已经很不错了，而且比过去大大地提高了营业额，但是，亚马逊却能做到两件具体的商品直接的关联。这样一来，两家商店在吸引顾客方面的差异就显而易见了。2015年7月，亚马逊的市值超过了沃尔玛，这标志着一个新时代的到来——以大数据为基础的电子商务将超越传统的零售商业。后者并非不能利用大数据，只是在个性化和时效性等方面，很难做得像电子商务公司那么有效而已。

ADD NOTE

HIGHLIGHT (YELLOW) • LOCATION 1623

Netflix后来将邮寄改为通过宽带在线观看，这有点像我在拙著《浪潮之巅》里描述的“根据需求收看”（on demand）。虽然从理论上讲观众省了来回邮寄的时间，应该能看更多的电影，事实却是大部分观众并非如此，因为一开始在线观看并没有解决如何有针对性地推荐电影的问题，大部分用户的活跃度并不高，因此在很长时间里，大家都不看好这家公司。

ADD NOTE

HIGHLIGHT (YELLOW) • LOCATION 1627

但是，随着数据量的积累，尤其是和每一个用户相关的各种维度数据的积累，Netflix给每一个用户的推荐越来越靠谱，越来越准确。Netflix不仅知道每个用户看什么风格的电影（风格、题材、导演、演员等）最多，而且知道它给用户推荐的效果是否好（是否点击观看，是否看到一半就转去看别的节目了，等等），这些数据是过去其他传媒公司无法获得的。

HIGHLIGHT (YELLOW) • LOCATION 1634

和亚马逊类似，Netflix的数据具有较强的时效性，它可以根据用户的反应很快调整它的市场策略，这种灵活性也是过去那些事先安排好一周节目的有线电视网所不具备的。时效性很强的个性化的推荐不仅体现在商品上，还可以用于任何意义上的信息搜寻。在Google内部，直到2005年，反对为用户提供相关搜索的声音依然占上风，因为很多人认为应该由用户自己输入他们所要查找的关键词，而不是由搜索引擎引导用户去搜索。事实上，早在2005年，我们就开发出了利用搜索关键词之间的相关性提供相关搜索的技术，我们甚至能够在搜索条中自动地根据用户搜索习惯和输入的一两个字提示出完整的关键词组合。但是这个服务迟迟未上线，因为佩奇和布林并不喜欢这种服务。最终，我们不得不先利用中、日、韩文字打字慢的特殊性说服了两位创始人允许我在这三种语言中试一试，结果这种相关搜索一下子让这三种语言的搜索量增加了10%。不到一年后，佩奇同意把这项技术应用到英语和其他语言中，与中、日、韩语言类似，它对提升英语等其他语言的流量有同样明显的帮助。

到了2008年，佩奇在这方面变得激进起来，不仅同意我们在搜索结果页的下方提供相关搜索，而且希望能够在搜索栏内根据用户当前部分输入和历史数据，自动提示搜索的关键词，这使得搜索关键词输入的速度大大提高，Google搜索在用户中的黏性进一步提升。再到后来，由于数据量的增加，特别是能做到针对每一个用户都积累了足够量的历史数据，以至于关键词的提升能够做到完全个性化，也就是说，两个不同用户，在输入一半关键词后，Google给他们的提示常常是不同的。到了2011年，Google不仅积累了大量的用户数据，而且了解了用户使用互联网的行为，甚至是生活的习惯（比如住在哪里，每天工作做些什么事情等），因此进一步提出“无关键词的搜索”，也就是说，对特定用户，根据他某个时间过去的行为，以及当前使用Google产品的场景，自动产生搜索关键词（在用户看来自己没有输入任何关键词），从互联网上查找信息，然后提供给用户。Google基于这项技术最重要的产品就是安卓手机上的Google Now—它可以提示用户接下来该做什么，而这种提示靠的是当时的时间、地点、应用场景和不同用户本身的习惯特点。

ADD NOTE

大数据商业的共同点——尽在数据流中

HIGHLIGHT (YELLOW) • LOCATION 1655

大数据商业的共同点—尽在数据流中在上述大数据应用的案例中，存在着一些普遍的规律，这些规律可以通过数据流（Data Flow）的一致性体现出来。

ADD NOTE

HIGHLIGHT (YELLOW) • LOCATION 1656

首先，大量看似杂乱无章的数据点，从很多不同的地方（可以是不同的人、不同的公司，甚至是不同的采样点）收集上来，这些数据在生成时常常是彼此独立的，而且在收集上来之前是原始的、未加工的、无目的的。无论是亚马逊上顾客的购买行为，Netflix上用户收看电影的行为，还是Google用户上网搜索或者做其他事情的行为，事先与这些服务的提供商都是没有沟通和商量的，而且彼此是独立的。这些大量独立的数据聚合在一起，才能得到客观而准确的统计结论，比如网页搜索和结果之间的相关性，不同商品之间的相关性，或者不同电影之间的联系等。在这个过程中，各种数据如同百川入海一般汇聚到一起。

ADD NOTE

HIGHLIGHT (YELLOW) • LOCATION 1667

数据的流向是从枝末的局部到整体。而当我们利用从大数据得到的规律指导商业行为和其他行为时，数据的流向则是从整体到局部，如图4.8所示。图4.8 在大数据的商业应用中，数据通常要完成两个方向的流动

ADD NOTE

HIGHLIGHT (YELLOW) • LOCATION 1669

前面的几个例子无一不是先从大数据找到普遍规律，然后再应用于每一个具体的用户，并且影响到每一个具体的操作。


HIGHLIGHT (YELLOW) • LOCATION 1691

开过小餐馆的人都会有这样的经验，自己是否在店里看着，对营业额的影响特别大，因此做这种餐饮买卖的人特别辛苦，稍微不注意就开始亏损。针对酒吧老板的这些麻烦，戴维设计了一套解决方案

—改造酒吧的酒架，装上可以测量重量的传感器，以及无源的射频识别芯片（RFID）〔12〕的读写器，然后再在每个酒瓶上贴上一个RFID的芯片。这样，哪一瓶酒在什么时候被动过，倾倒了多少酒都会被记录下来，并且和每一笔交易匹配上。酒吧的老板可以用平板电脑查询每一笔交易，因此即使出门办事也可以了解酒吧经营的每一个细节。当然，戴维提供的服务如果只是停留在这个层面，那么更像是一个“万物联网”（Internet of Things，简称IoT）的应用，与我们所说的大数据其实关系并不大。戴维对酒吧的改造带来了一个额外的好处，就是积累了不同酒吧比较长时间的经营数据。在这些数据的基础上，他为酒吧的主人提供了一些简单的数据分析。

ADD NOTE

HIGHLIGHT (YELLOW) • LOCATION 1699

首先，分析每一家酒吧过去经营情况的统计数据，这有助于酒吧的主人全面了解经营情况。在过去，像酒吧这样传统的行业，业主除了知道每月收入多少钱，主要几项开销是多少，其实对经营是缺乏全面了解的。至于哪种酒卖得好，哪种卖得不好，什么时候卖得好，全凭经验和自己是否上心，没有什么分析。戴维提供的数据分析让这些酒吧老板首先对自己的酒吧有了准确的了解。其次，为每一家酒吧的异常情况提供预警。比如戴维可以提示酒吧老板某一天该酒吧的经营情况和平时相比很反常，这样就可以引起酒吧老板的注意，找到原因。在过去，发生这种异常情况时老板很难注意到，比如某个周五晚上的收入比前后几个周五晚上少了20%，老板们一般会认为是正常浮动，也无法去——检查库存是否和销售对得上。有了戴维提供的数据服务，这些问题都能及时被发现。最后，综合各家酒吧数据的收集和分析，戴维会为酒吧老板们提供这个行业宏观的数据作为参考。

ADD NOTE

HIGHLIGHT (YELLOW) • LOCATION 1726

但是，这些问题在大数据时代开始有了答案。早在2001年，普拉达就开始利用最新的I技术来提升它的销售。首先，它在商品的标签里嵌入一个很小的 RFID芯片（图4.10）。RFID是一种不需要电源的芯片，里面存储的信息可以被专门的阅读器发出的无线电波探测出来。

ADD NOTE

HIGHLIGHT (YELLOW) • LOCATION 1730

这个芯片可以把客户正感兴趣的这一件商品和他们可能感兴趣的其他商品联系起来，这有点像亚马逊的商品推荐。据普拉达的销售副总裁丹•斯坦尼克（Dan Stanek）讲，通常顾客和店员的交互越多，购买的可能性越大，因此相关的推荐非常有用，没有这种智能芯片之前，其实店员不知道该推荐什么给顾客。当然，普拉达所做的远不止嵌入一个小芯片做商品推荐，它还改造了专卖店的试衣间，这样每一次顾客把时装拿到试衣间试穿，店里都能记录下来。普拉达的数据分析师根据这些数据就能知道如果一件时装卖得不好，是因为放在店里没有人注意到（根本没有拿去试穿），还是因为试穿后顾客不喜欢。根据这些信息，公司就知道问题出在设计和制作上，还是出在销售上。

ADD NOTE

HIGHLIGHT (YELLOW) • LOCATION 1748

但是，金风公司在海外面临着中国制造业企业通常都会遇到的困境，就是虽然市场占有率不低，营业额也不少，却没有多少利润，其根本原因在于中国的企业常常只能控制从设计到销售诸多环节中的制造环节，其他六七个环节的收益则被外国公司赚走了。当然，像金风这样具有不少自主知识产权和技术的公司，有能力赚取设计环节的利润，却无法掌控市场。这并不是因为金风的市场能力不够强，而是由企业级设备销售的特点决定的。

HIGHLIGHT (YELLOW) • LOCATION 1752

在过去，企业级的设备采购常常是购买者的主动行为，也就是说购买者有了需求后，向销售者购买。在世界贸易中，销售者和制造者常常不是同一家公司。比如巴西的某个连锁的零售百货店要更新1亿美元的计算机和通信设备，它通常会找一个工程的合同商（中间商）来承包整个工程，这样方便设备的运行和维护。这些中间商一方面搭建了制造商和顾客之间的桥梁，另一方面在主观或者客观上也阻断了买卖双方的联系。在过去一旦买卖双方货款两清，它们的关系就基本中断了。接下来买方的设备使用得怎么样，是否有新的需求，卖方是一无所知的，直到买方有了再次购买的意愿而通知设备生产厂商来竞标。当然，比较主动的卖家会做一些市场分析，当然这些市场分析很难做到准确。即使像波音和空中客车这种两家就完全垄断了全球市场的公司，对市场的预测也常常是错的。只要读一读波音公司每年向美国证监会提供的年度财报就会发现，它对未来一到两年市场预测的准确率只有60%左右。

ADD NOTE

HIGHLIGHT (YELLOW) • LOCATION 1763

该公司利用互联网，将发电机的各种数据（地点、发电量、运行情况）全部收集到公司，进行大数据分析。这样他们一方面可以全面地了解全球的风能分布情况、各地的风力利用情况等宏观信息，有利于公司有针对性地做市场推广；另一方面，他们可以了解每一台发电机日常运行的每一个细节，不仅发电机有了问题可以及时发现并解决，而且如何进一步改进也有了数据依据，这样一来该公司的经营策略就从依赖市场预测、打价格战等传统的营销手段，提升到成为高质量的服务商，业绩也得到明显的提升。再到后来，它的商业模式也开始发生变化，这一点我们后面还会讲到。像金风这样的中国企业非常多，我在给一些传统行业的企业家讲课时了解到，在中央空调、工业制冷等很多行业，中国的企业在完成制造和安装后，就和海外顾客鲜有联系了，更不用说通过对那些顾客的服务了解全球的市场状况。

ADD NOTE

重新认识穷举法——完备性带来的结果

HIGHLIGHT (YELLOW • LOCATION 1841

首先，Google自动驾驶汽车项目其实是它已经成熟的街景项目的延伸。对Google自动驾驶汽车的各种报道通常都会忽视一个事实，那就是它只能去Google“扫过街”的地方。对于这些已经去过的地方，Google都收集到了非常完备的信息，比如周围的各种目标的形状大小、颜色，每条街道的宽窄、限速，不同时间的交通情况、人流密度等，Google都事先处理好以备未来使用。因此，自动驾驶汽车每到一处，对周围的环境是非常了解的，它可以迅速把这些数据调出来作为参考。而过去那些研究所里研制的自动驾驶汽车使用的是人的思维方式，每到一处都要临时识别目标，这样即使所搭载的计算机再快，也来不及进行太深入的计算，因此无法做出准确判断。

ADD NOTE

HIGHLIGHT (YELLOW) • LOCATION 1847

其次，自动驾驶汽车上装有十多个传感器，每秒钟进行几十次的各种扫描，这一方面超过了人所能做到的“眼观六路、耳听八方”，同时大量的数据要在短时间内处理完，计算的压力是非常大的。

Google的自动驾驶汽车是通过移动互联网与Google的超级数据中心相连的，虽然它本身携带的电脑不过是一台简单的服务器，但是整体的数据量和计算能力要远远超出过去其他公司和大学那些自动驾驶汽车上面所携带的计算机。再次，我们人开车，常常是根据周围情况临时做出判断，遇到死胡同，转弯掉头再找其他的道路。Google拥有一个最好的全球地图数据，它的自动驾驶汽车不仅行驶的路线大部分是事先规划好的，而且对各地的路况以及不同交通状况下车辆行驶的模式有准确的了解，因此它可以规避很多不必要的麻烦。当然，如果开到了事先（扫街汽车）没有去过的地方，自动驾驶汽车常常会无计可施。

HIGHLIGHT (YELLOW) • LOCATION 1866

在历史上，一项技术带动整个社会变革的事情也曾经发生过。它们通常遵循一个模式，即：新技术+原有产业=新产业那些有意或者无意接受了这个规律的企业家，常常在新的时代又站到了浪潮之巅。

ADD NOTE

HIGHLIGHT (YELLOW) • LOCATION 1932

类似地，证券交易也发生了根本性的变化。1971年美国的全国证券交易商协会推出了自动报价系统，这套系统的英文全称为 National Association of Securities Dealers Automated Quotations，简称 NASDAQ，即我们常说的纳斯达克。纳斯达克和纽交所不同，交易者不需要再到交易所，而是通过网络和电话进行交易，

ADD NOTE

HIGHLIGHT (YELLOW) • LOCATION 1943

逼着和惠普从事T服务一样。从这个趋势可以看出，各种服务在信息革命之后变得越来越重要。

ADD NOTE

技术改变商业模式

HIGHLIGHT (YELLOW) • LOCATION 1982

在信息时代，商业模式的变化更加明显，它突出地表现在两方面，一是产业链从一种产品扩展到整个 IT行业，二是服务业的重要性突显出来。

ADD NOTE

HIGHLIGHT (YELLOW) • LOCATION 1983

我们先来看看IT产业链的形成。在上一节我们盛赞摩尔定律给我们带来的好处，但是它也带来了一个问题，那就是让很多电子产品，尤其是与计算机相关的产品（比如个人电脑、DVD机、电视机和手机等）的价格持续下降。这对消费者看起来是福音，但是对生产厂家来讲是灾难性的，因为一旦出现这样明显的通货收缩，就不会再有消费者急于购买新产品了，这和消费拉动经济增长的格局是相违背的。为了解决这个根本性矛盾，就需要将整个行业整合成一条大的产业链，这条产业链可以被概括为“安迪-比尔定律”。安迪-比尔定律的原话是：“比尔要拿走安迪所给的。”（What Andygives，Bil take saway.）这里面的安迪是个人电脑巅峰时代英特尔当时的CEO安迪 格罗夫，比尔则是大名鼎鼎的比尔•盖茨，他当时是微软公司的CEO。这句话的含义是，在计算机领域，软件功能的增加和改进要不断地吃掉硬件性能的提升。这一点经历过个人电脑发展或者智能手机历程的人都会有亲身体会。虽然今天我们的个人电脑比1981年IBM推出的PC（个人电脑）快了两万倍左右，但是我们并没有觉得它有那么快，因为微软操作系统使用的计算和存储资源比30年前要多得多，给人的感觉是它吃掉了所有硬件性能的提升。

HIGHLIGHT (YELLOW) • LOCATION 1995

安迪-比尔定律反映出计算机工业的整个生态链：以微软为代表的软件开发商吃掉硬件提升带来的全部好处，迫使用户更新机器，让惠普、戴尔和联想等公司受益，而这些PC整机商再向英特尔这样的半导体公司订购新的芯片，同时向希捷（Seagate）等外设厂商购买新的外设。在这个过程中，各家的利润先后得到相应的提升，股票也随着增长。各个硬件半导体和外设公司再将利润投入研发，按照摩尔定律预定的速度，提升硬件性能，为微软下一步更新软件、吃掉硬件性能做准备。从上述产业链中我们可以看出，主动的一方不是各种看得见摸得着的工业品生产商，而是提供软件和服务的一方。正是出于这个原因，微软成为个人电脑时代最成功的公司，而曾经以生产计算机为主的IBM则坚决地进行了转型，将主营业务从制造计算机转向提供软件和技术服务。

ADD NOTE

HIGHLIGHT (YELLOW) • LOCATION 2002

20世纪90年代，IBM传奇般的CEO郭士纳敏锐地觉察到摩尔定律将导致IT行业的格局发生巨变，为IBM找到了一个至今依然有钱赚的商业模式—T服务。人类对服务的需求总是有的，而且随着科技进步，人们对服务的要求越来越高，因此它的利润就有保障。

ADD NOTE

HIGHLIGHT (YELLOW) • LOCATION 2006

通过上述对历次技术革命中商业模式变迁的分析，我们可以得到这样三个结论：首先，技术革命导致商业模式的变化，尤其是新的商业模式的诞生。其次，生产越来越过剩，需求拉动经济增长的模式变得不可逆转。同时，单纯制造业的利润越来越低，那些行业越来越没有出路。相反，人们对服务的需求越来越强烈。在T时代，唱主角的公司逐渐从制造设备的IBM、DEC、爱立信、诺基亚和惠普等公司，变成了提供软件和服务的微软、甲骨文和Google等公司。最后，商业模式的变化既有继承性，又有创新性。

ADD NOTE

HIGHLIGHT (YELLOW) • LOCATION 2013

长久的生意、更多的利润。

ADD NOTE

在大数据时代，I软件和服务业依然会是【T领域最好的行业，而且这个趋势将更加明显。提供服务虽然不像销售产品一次能挣比较多的钱，但是细水长流的技术服务最终会给这些服务的提供者带来更

加（+）大数据缔造新产业

HIGHLIGHT (YELLOW) • LOCATION 2017

我们在前面提到过的金风公司的故事在2015年又有了新的进展。在和我进行了多次关于大数据时代商业模式的探讨后，该公司决定向IBM学习，在商业模式上做根本性的转变，主营业务从风力发电机的制造，转变成发电设备的运营和服务。当然，并非什么公司想做服务就能做得好并挣到钱，金风公司有底气转型，源于其在宏观上对全球风能市场的了解，在微观上对每一台风能发电机运营细节的了解，加上通过大数据对发电机可能出现的问题的分析，能够比一般工程公司更有效地维护发电机。至于发电机的生产，该公司只负责研制，然后将设备制造交给其他公司去做。这样一来，金风公司就在风力发电领域成功地复制了IBM服务的模式。大多数亚洲制造企业虽然在全球市场上占的份额不小，但是通常竞争的手段就是压低利润降价，最后把整个行业变得都没有利润。金风公司转型的做法，或许能给这些企业一些后发，当然如果没有大数据这样的机遇，这种转型是非常困难的。与金风公司面临类似情况的还有诸多的电器生产厂商。这些电器无论是高端的还是低端的，厂家只能赚到一次钱，而且由于亚洲制造业同行相互压价，利润也不可能很高。为了解决利润的问题，一些对新技术敏感的公司想到了利用大数据和移动互联网来改变商业模式。

加（+）大数据缔造新产业
HIGHLIGHT (YELLOW) • LOCATION 2032
GE将 Wi-Fi安装到它的冰箱和其他大型家电上，用来提示用户更换冰箱取水器的滤芯等消耗性材料。这些滤芯通常需要每半年更换一次，但是大部分用户都难得更换，即使冰箱上的指示灯亮了。GE将冰箱通过Wi-F连到互联网上之后，可以通过手机 APP（应用程序）来提醒用户及时更换滤芯，这样一来用户更换滤芯的比例提高了很多。值得一提的是，用户订购滤芯只需要在手机APP上点击确认即可，GE可以用快递将滤芯直接邮寄给顾客，这样就省去了很多中间环节。对GE来讲，两个滤芯（可以使用一年，大约100美元左右）的利润就抵得上一台冰箱本身的利润。
ADD NOTE
HIGHLIGHT (YELLOW) • LOCATION 2038
当然，GE通过Wi-F获得的信息远不止滤芯的寿命，它可以全面了解用户使用电器的情况，并且可以从千百万用户那里收集到关于用户的大数据。通过分析这些数据，GE可以牢牢地把握住这些用户，知道他们接下来需要什么，有的放矢地推销后续产品。
ADD NOTE
HIGHLIGHT (YELLOW) • LOCATION 2043
当那些厂商能够把控每一个用户、每一个产品和每一次交易细节，它们就能绕过很多经销的中间环节，直接和顾客做生意。善用大数据之后，家电的销售可以不再是一锤子买卖。如果我们对比拥有大
(11)
ADD NOTE
HIGHLIGHT (YELLOW) • LOCATION 2054
小米是一家手机制造公司，其主要收入来源就是它的手机销售，比较单一。单从这一点上看，它与中国的两个主要竞争对手华为和联想没有什么区别，它甚至还不如华为，因为华为自己能生产手机处理器，而小米主要的元器件完全要从高通和东芝等厂家购买。至于智能手机的核心—操作系统，小米用的是Google的安卓（Android），尽管它修改了一些UI的功能和接口。在很多人看来，这样的企业就是一个没有核心技术的亚洲制造企业，未来免不了陷入以打价格战为主的低层次竞争中，事实上从 2013年开始，小米为了增加市场份额，已经开始用极低的价格推广它的低端手机了。这似乎完全没有摆脱过去亚洲制造企业一贯的做法。因此，多年来致力于发展自主知识产权、打造基于技术的核心竞争力的格力电器，看不起移动互联网暴发户小米是在情理之中的事情。但是，就是这样一家产品单一、仍在亏损的“电器”企业，2015年7月再融资时，却被国际上知名的风险投资公司估值为450亿美元。而与此同时，手机出货量和小米相当、个人电脑全球占有率第一、连续多年赢利的联想公司，市值只有100亿美元左右。
ADD NOTE
HIGHLIGHT (YELLOW) • LOCATION 2064
要么从长远来讲小米具有联想等公司所不具有的价值。
ADD NOTE
HIGHLIGHT (YELLOW) • LOCATION 2066
小米从一开始就以一家互联网公司的方式来经营它的手机业务。从本质上讲手机只是小米获得用户的手段，在获得用户后，它需要通过其他方式挣钱，这一点小米和华为、联想都不同，后两者在卖掉手机后就完成了交易。事实上，最早利用智能手机特点开发移动社区的公司不是腾讯，而是小米，只不过小米因为用户的数量远不如腾讯多，它的米聊才最终败给了腾讯的微信。在拥有一定数量的用户后，小米也拿到了大量的用户数据，但是怎么能不断有效地从每个用户身上挣到钱，这是小米必须解决的问题。目前，它通过手机成功地推销出不少配件，包括一些可穿戴式设备，但是这些都还不足以让它挣到足够的利润。为了进一步绑定用户，小米还开发了其他的产品线，比如电视、空气净化器等。因此，从某种程度上讲，小米更像是一个以家电为主的垂直电商，而不是家电生产厂商。与传统电商所不同的是，小米从一开始就注重对用户行为的分析和数据的作用，因此它有可能在一些垂直领域做得比传统电商更有效。

加（+）大数据缔造新产业
HIGHLIGHT (YELLOW) • LOCATION 2078
在争论小米和格力哪一家更有前途这个话题时，董明珠间了雷军一个问题：如果没有生产工厂，小米还能有销售吗？显然，董明珠按照思维定式把小米当作制造型企业来看待。作为制造型企业，有关它的产品的核心技术、自主知识产权当然很重要，所以董明珠才会认为格力经过20多年的积累，有深厚的技术沉淀，是不可能被小米超越的。但是，正如我们前面分析的，小米根本就没有把自己定位为制造型企业，它卖手机并非满足于挣硬件的利润，而在于获得用户，然后再从每一个用户身上获得长期的收益。因此，雷军和董明珠之争，其实体现了大数据时代和摩尔时代不同的思维方式的冲突。至于小米是否能在5年内（即2013~2018年）超过格力，我倒认为雷军话说得太满了，从长远看，如果小米不出现重大失误，它一定能够超过格力，但是这个时间点恐怕不是2018年。
ADD NOTE
HIGHLIGHT (YELLOW) • LOCATION 2084
说回到格力电器，它其实是传统的家电企业的典型代表。这类企业在过去20多年里一直在努力地发明和创新，但是在外人看来却缺乏创造力。它们一方面是全球的专利大户，比如索尼、东芝和三星一直是获得美国专利前10名的大公司，但是另一方面它们在世界经济中的地位却在不断下降。在互联网大潮中，很多这类企业已经变相落伍了，甚至开始苦苦挣扎，比如索尼公司。当大数据时代到来时，它们应该非常有所作为，因为它们已经占据了家庭的客厅和卧室，但是如果它们自己的思维方式还局限在摩尔时代做硬件、卖产品的定式上，那么它们将失去一次绝好的转型机会，其中很多不免会被淘汰。就以格力电器的核心产品空调为例，每一台能用10年左右甚至更长的时间，而且它的购买和安装也不像买个手机那么容易（虽然价格差不多），因此很少有人经常换空调。在工业化国家，除非某年遇到了特别极端的天气，否则空调的销售增长非常有限；在中国由于城市化的进程还没有完成，大家只是暂时感觉不到市场快要饱和而已。其他家电，比如电冰箱、洗衣机，都是如此。家电行业不仅增长缓慢，而且它在世界各国的利润其实都非常薄，因此家电企业的投资回报率都不高。怎样才能让家电行业获得稳定的利润呢？这在大数据时代之前是很难做到的。虽然商学院很早就在教授吉列公司送刀架卖刀片的商业模式，但是这种做法过去在家电领域很难模仿，因为家电的交易完成之后，用户和商家就没有关系了，商家不知道向谁提供服务。即便知道，后续的增值服务（如果能够进行的话）也不是换一个刀片那么简单，用户的需求常常干变万化，如果不了解用户的具体情况强行提供所谓的服务，会让他们感到反感。更重要的是，过去生产厂商和经销商通常不是同一个，经销商刻意要切断厂商和用户的联系，以便他们有可能做后续的增值服务。
HIGHLIGHT (YELLOW) • LOCATION 2101
大部分家电企业只能从家电本身赚钱，它们根本不知道自己的产品卖给了哪一个具体的消费者，更不要说了解消费者更多的个人情况和生活习惯了。但是在大数据时代，家电厂商可以通过一些产品跟踪技术（我们后面会讲到）知道自己出产的每一个电器是如何一步步进入顾客家的，并且知道用户是准。而每个大件电器本身又是收集用户数据的采集器，因此家电公司可以完全了解用户的很多生活细节，比如他们在哪里，每天使用该电器的情况，使用其他电器的情况，甚至什么时候回家，什么时候吃饭等。从宏观的角度看，商家可以了解到它的商品是通过什么渠道卖给了具体的消费者，从而优化它的销售网络；从微观的角度看，它可以了解每一位顾客的生活，知道接下来每一个人需要什么。这样，生产厂商其实就不再受经销商控制了，厂商和用户的直接联系就建立起来了。这样不仅厂商能获得更多的利润，顾客因为消除信息的不对称性也能在价格上获得优惠，而且厂商和顾客之间能够建立一种细水长流的商业关系。这时，厂商之间的核心竞争力不再是商品本身，而是更重要的服务。未来产品的服务水平不完全取决于厂商对它的重视程度（比如服务态度）和相关技术，而更多要依靠智能化。未来，商家将在数据层面和智能化方面展开竞争。当然，像格力这样的传统企业必须做出一个选择—是否愿意利用大数据转型。从蒸汽机时代、电气时代到半个多世纪前开始的信息时代，它们一直验证着这样一个规律，即原有的产业加上新技术就成为新产业，否则将被淘汰。在今天的大数据和机器智能时代，这条规律依然成立。
ADD NOTE
HIGHLIGHT (YELLOW) • LOCATION 2120
更切合实际的是，他们付费使用第三方的服务。在未来我们可以看到，大数据和机器智能的工具就如同水和电这样的资源，由专门的公司提供给全社会使用。


第五章 大数据和智能革命的技术挑战

HIGHLIGHT (YELLOW) • LOCATION 2158

每一次技术革命除了有生产力发展需要，还要有很多技术准备，只有当所有这些必要的技术都成熟时，技术革命才变为可能。历史上虽然不乏“穿越时空”的人，比如达•芬奇和尼古拉•特斯拉，他们能设计出很多后世才用得到的东西，但是由于市场没有准备好，配套的技术不成熟，他们的想法在当时只能算是空想而已。以大数据为核心的智能革命也是如此，它之所以在今天这个时间点爆发，除了在商业上有了应用的可能性之外，也是因为很多相关技术已经成熟。在未来它要想进一步发展和普及，还需要解决很多技术上的瓶颈。在这一章，我们首先分析产生大数据的技术基础，然后再探讨它所面临的技术挑战。

ADD NOTE

技术的拐点

HIGHLIGHT (YELLOW) • LOCATION 2163

技术的拐点科学技术的发展并非是匀速的。重大的科技突破常常需要酝酿很长的时间，在这段时间里，我们发现技术进步是一个缓慢的量的积累，有人把它称为相对停顿的状态，因为这个阶段一切发展都是平衡的。但是当这些量的积累到一定程度后，科技在短时间内获得单点突破，然后新科技全面进发，这便是拐点。

ADD NOTE

HIGHLIGHT (YELLOW) • LOCATION 2176

为什么大数据的拐点会发生在今天？从过去的10年开始，最容易看到的特征就是全球数据量呈爆炸式增长。

ADD NOTE

HIGHLIGHT (YELLOW) • LOCATION 2183

数据量的增长在所有的增长中是最快的数据来源：Cisco VNL，2011.6；Gartner，2009& 2001数据的产生大数据的第一个来源是电脑本身。全球数字化让几乎每一个使用电的设备都有

了一个“电脑”，这些电脑或者设备中内置的处理器、传感器和控制器一直在产生数据，比如记录设备状态的日志（Log）。

ADD NOTE

HIGHLIGHT (YELLOW) • LOCATION 2191

大数据的第二个来源是传感器。传感器技术的进步使得收集数据变得非常容易。我们在前一章中提到无源的射频视频芯片（RFID）就是一种帮助收集数据的工具。今天无所不在的摄像头，其作用与收集数据的传感器也有着相似之处。我们先看看射频视频芯片是怎样工作的。这种芯片里面可以存储一些信息，芯片外有一个回形的天线（线圈），用于接收阅读器发出的无线电波。当天线线圈接收到无线电信号后，根据电磁感应原理，它会产生微小的电流让芯片工作，并将里面的信息发出，再由阅读器读取。这种射频视频芯片非常便宜，零售价也不过4美分一片。将它装到各种物品上，就可以自动识别各种物品，进而跟踪物品。

技术的拐点

HIGHLIGHT (YELLOW) • LOCATION 2207

数据的第三个来源是将那些过去已经存在的、以非数字化形式存储的信息数字化，这个过程开始于2000年左右。非数字化的数据包括语音、图片、设计图纸、视频、档案、古稀图书和医学影像等，这些信息过去都是以各种各样的形式存储的，由于积累的时间很长，因此数量巨大。据约翰•霍普金斯大学生物工程系系主任麦克维（Elliot McVeigh）教授介绍，在2010年时，全美国病例档案的文件规模比互联网上（非重复）的网页数量高出一个数量级，当然，在过去的几年里互联网上的内容增加很快，很难说今天病例的数据量是否依然超过互联网，但至少说明它的规模很大。产生上述数据的主要是企业，而非个人。在互联网时代，网络用户产生的数据（UGC）以更快的速度在增长。对于用户产生的数据，大家可能并不陌生，因为我们每一个人都是这些数据的制造者。我在拙著《浪潮之巅》中讲到过互联网2.0的特点，它的本质是一个互联网的平台，而上面的文字、图片、祝频和各种其他信息都是由用户提供的。在图片共享网站Pinterest中，每天有7000万张图片〔1〕被上传，累计上传了300亿张。在Google旗下的 YouTube视频网站，数据量更是大得惊人，每分钟有300小时的视频被上传到 YouTube。至于互联网用户每天在社交网络上的聊天和互动所产生的内容就更多了。

ADD NOTE

HIGHLIGHT (YELLOW) • LOCATION 2236

只是存储的容量上去还不够，因为随着数据量剧增，查找和使用数据的时间会变得相当长，因此存储设备的读写速度也必须随着容量的增加而大幅度提高。早期海量存储设备采用的是顺序访问数据的磁带，因此大数据的使用显然是不可能的，人们连存储数据的兴趣都不大。20年前硬磁盘取代了磁带成为海量存储设备，数据访问的时间缩短到原来的大约1/1000，这时批处理数据不再是个问题，人们开始重视收集和存储数据。但是随机存储和访问数据依然很缓慢，而且由于硬盘的速度取决于机械运动，不可能大幅度提高，因此数据的使用受到限制。直到大约七八年前，半导体的固态存储器（Solid State Drives，简称SSD）的容量增加成本下降，才使得人们能够很方便地使用数据，这时从存储技术上讲，使用大数据的时机才成熟。在能够产生大量的数据，也能够存储这些数据之后，还有一个问题必须解决，那就是这些数据怎样才能从采集端传到存储设备上，这就要求数据传输技术有所突破了。

ADD NOTE

HIGHLIGHT (YELLOW) • LOCATION 2257

应用大数据的一个前提就是能够将一个大的计算任务分到很多台便宜的服务器上去做并行计算。

ADD NOTE

HIGHLIGHT (YELLOW) • LOCATION 2262

才成为可能。

ADD NOTE

上述计算问题直到2002年之后才被Google等公司陆续解决，也就是在那个时期，云计算开始兴起。通过互联网、廉价服务器，以及比较成熟的并行计算工具，实现了大规模并行计算，大数据的处理

数据收集：看似简单的难题

HIGHLIGHT (YELLOW) • LOCATION 2268

数据收集：看似简单的难题按照信息论的观点，要消除不确定性就需要信息，因此信息的收集非常关键。大数据与传统的数据统计方法相比，在收集数据方面有了很大的不同。首先，传统的数据方法常常是先有一个目的，然后开始收集数据。

数据收集：看似简单的难题

HIGHLIGHT (YELLOW) • LOCATION 2273

在大数据时代，在收集数据时常常没有这样预先设定的目标，而是先把所有能够收集到的数据收集起来，经过分析后，能够得到什么结论就是什么结论。正是因为在收集数据时没有前提和假设，大数据分析才能给我们带来很多预想不到的惊喜，也才使得大家觉得计算机变得很聪明了。在获取数据方面，大数据和传统的统计方法另一个不同点在于，过去我们是通过少量的采样获得所谓具有代表性的数据，这些数据被称为样本。根据统计学的原理，只要样本具有代表性，通过分析这些少量的样本数据，就可以总續出规律性。

ADD NOTE

HIGHLIGHT (YELLOW) • LOCATION 2300

但是能够通过机顶盒设备和电视机拳据用户数据的只有它们的生产厂商和有线电视运营商，而三者都不会轻易把这个数据分享出来。这便是很多想利用大数据做事的人和公司所面临的困境。因此，数据的收集可以说是一个看似简单的难题。那么，聪明的公司会怎样解决收集数据的难题呢？最常见的方法就是统一个弯路，间接地收集数据，然后利用数据的相关性，导出自己所要知道的信息。但是这条路并不好走。Google是一个亚视数据的公司，它很想了解每一个家随的具体情况。为此，它做了很多尝试，但大部分都失败了。2010年，Google推出了自己的电视机頂盒 Google TV，为获取数据进入电视广告市场做准备，但是，GoogleTV的销售如此之差，以至于后来每个季度退回来的机顶盒比卖出去的还多。最终Google彻底放弃了这个产品，但是没有放弃收集数据的想法。2014年，Google斥巨资32亿美元收购了只有130名员工、用户数量200万左右、还处在亏损状态的nest公司。该公司的产品是具有自主学习功能和Wi-F的智能空调控制器，可以根据人在案里活动的习惯控制空调节省20%左右的电。如果单算经济账，这笔投资不知道猴年马月才能账回来，或许永远挣不回来。Google之所以花如此高的价格购买nest，最主要的目的是获取每一个家庭的数据。nest智能空调控制器的王作原理是靠跟踪家里人在每一个房间里的活动，比如几点回象，几点看电视，几点吃饭，晚上都待在哪里，什么时候睡觉。在Google收购 nest不久，它又花了5.55亿美元的巨资收购了家隨录像监控公司Dropcam，这样就能获得更多的居家效据。

ADD NOTE

HIGHLIGHT (YELLOW) • LOCATION 2313

在现实的世界里有一个匪爽所思的现象。一方面，彼软、苹果和Google这些【T公司，为了挖掘每一个家庭的消费潜力，想尽办法千方百计地要掌握每一个家庭客厅的数据。它们有的通过游戏机，有的通过类似机顶盒的设备（Google过去的机顶盒、后来的Chromecast，苹果的AppleTV），在为用户提供服务的同时，在不经意之间收集用户数据。另一方面，拥有这些数据的公司除了统计一下收视率，计算一下可能的广告观众，并没有什么大的作为。从这个现象可以看出，一些公司已经敏说地看到了数据的价值，而另外一些公司却拿着金饭碗在要饭，这其实反映出两种类型的公司在方法论上的差异。

ADD NOTE

HIGHLIGHT (YELLOW) • LOCATION 2319

图5.9

Google旗下nest增能空调控制器，其实是一个数据收集器

ADD NOTE

HIGHLIGHT (YELLOW) • LOCATION 2329

在大数据这个概念不断地被炒作，数据变得越来越值钱时，一些公司和个人开始赤裸课地收集用户的数据，然后想办法卖饯〔3〕。事实上这样刻意收集来的数据意义不大，因为收集数据的过程会引起用户的警觉、恐慌和反感，一部分对倌息安全敏感的人可能会关闭收集数据的传感设备，导致收集的数据不全面；而另一部分人的行为会变得不自然。这种变了形的数据，既不具有统计意义，也失去了大数据的完备性。因此，真正高明的公司都会像微软、苹果和Google那样采用曲线救国的方法。有些时候，为了收集数据，这个弯需要绕得特别大。Google为了推出它的基于手机的语音识别系统GoogleVoice，需要大量的语音数据。在过去，各家语音识别公司和实验室都是找人来录入数据，比如美国标准的电话语音库Switchboard就是这么构造的。这种类似于来样方法导致的缺陷我们在前面已经介绍了，不再赘述。Google的方法则不同，它为了收集数据，先推出了一个类似玩具的电话语音识别系统 Google-411（识别率相比后来真正的产品 Google Voice是非常低的），很多

人出于试验和玩的目的打这个电话，这样就在无意中为Google提供了大量的电话录音。数据的收集是一个开放性的话题，不存在唯一的、最佳的方法。但是好的方法一定能够保证数据的全面性（完备性）和不变性。

数据收集：看似简单的难题

数据存储的压力和数据表示的难题

HIGHLIGHT (YELLOW) • LOCATION 2347

数据量增长的速度是高过存储设备发展速度的，越往后，它们之间的差距越大。因此，不能简单地依靠更多地生产和购买设备来解决数据存储的问题，而是需要技术解决方案来提高存储的效率，保证不断产生出来的数据都能够存得下。目前节约存储设备的技术体现在两方面，第一类技术是存储同样的信息占用的空间小。当然，这并不是简简单单的数据压缩。从信息论的角度讲，就是要去除数据的冗余，但是在去除冗余之时，相应的数据读写处理要做改变。

ADD NOTE

HIGHLIGHT (YELLOW) • LOCATION 2354

第三类技术涉及数据安全，在这里所讲的数据安全是指数据不丢失、不损坏，而不是指防止数据被盗。

ADD NOTE

HIGHLIGHT (YELLOW) • LOCATION 2378

大效援面临的另一个技术难题就是如何标准化数据格式，以便共享。

ADD NOTE

HIGHLIGHT (YELLOW) • LOCATION 2385

非學进入大数撰领域的 Google公司孩计了一种被称少 Frotocol Bufer的數据桥式。在Googe内部，Brotocol Duffers是数频释储的主要格式，也退它所开没的备种软件在进行数据酒们时标准的主

口

ADD NOTE

并行计算和实时处理：并非增加机器那么简单

HIGHLIGHT (YELLOW) • LOCATION 2389

并行计算和实时处理：并非增加机器那么简单大数据由于体量大、维度多，处理起来计算量巨大，它的使用效率取决于并行计算的水平。我们在前面提到了 Google的MapReduce（编程棋型）和雅虎的Hadoop（海杜普）婚工具，它们能够把相当一部分大型计算任务拆成若干小任务在很多并行的服务器上运算。这确实给大数据处理带来了福音，但是并没有完全解决计算瓶颈的问题。在一般人想象中，增加10倍的处理器并行计算，可以同样成倍地节省时间，但是在工程上这是做不到的。首先，任何一个问题总有一部分计算是无法并行的，这类计算占比越大，并行处理的效率越低。

ADD NOTE

HIGHLIGHT (YELLOW) • LOCATION 2403

完成了自己计算任务的服务器，在等待个别尚未完成计算的服务器。最终的计算速度取决于最后完成的子任务。如果考虑到一些子任务会因为系统不稳定出现计算错误需要重新计算，并行计算的效率还会进一步降低。因此，并行计算的时间是远远做不到和服务器数量成反比。事实上，使用的处理器越多，并行计算的效率越低。

并行计算和实时处理：并非增加机器那么简单

数据挖掘：机器智能的关键

HIGHLIGHT (YELLOW) • LOCATION 2429

虽然香农告诉我们，信息越多，我们就越能消除系统的不确定性，但是数据中常常不仅仅是信息，还不可避免地夹杂着嗓声，这个问题在大数据中特别明显。

ADD NOTE

HIGHLIGHT (YELLOW) • LOCATION 2432

在信息处理领城，大家使用一个被称为偵号与噪声之比（Signal Noise Ratio，简称偵噪比 SNR）的度量来描述信号的质量。

ADD NOTE

HIGHLIGHT (YELLOW • LOCATION 2436

归等，早在40年前就已经成热了。

ADD NOTE

现在，我们可以认为这样处理过的数据能直接使用了，接下来关键的一步就是机器学习。机器学习并不是什么新鲜事，今天广泛使用的机器学习算法，比如人工神经网络算法、最大熵棋型、逻辑自回

HIGHLIGHT (YELLOW) • LOCATION 2441|

但是如果认为机器学习就是把几十年前的论文拿过来用计算机的程序实现一遍，那也未免太天真了，因为机器学习一旦上了规模，实现起来可不是一件容易的事情。不幸的是，大数据的机器学习还真是一个上规模的难题。要理解为什么数据量一大机器学习就变得非常困难，我们不妨简单介绍一下机器学习的原理。

ADD NOTE

HIGHLIGHT (YELLOW) • LOCATION 2444

机器学习的过程无一例外是一个不断迭代、不断进步的过程，用机器学习的专业术语来说就是“期望值最夫化”（Expectation Maximization）的过程：只要事先定出一个学习的目标，这些算法就会不断地优化模型，让它越来越接近真实的情况。可以说，机器学习训练算法迭代的次数越多，或者迎俗地说学习得越深入，得到的数学模型效果越好。因此，同样的数据，同样的算法，采用不同深度的机器学习方法，得到的结果会有所不同。但是机器学习的算法通常都比较“慢”，用比较专业的术语讲，就是计算复杂度太高〔8〕，因此随着数据量的增加，计算时间会剧增。在过去，由于计算能力的限制，以及并行计算工具不够有效，人们在机器学习时，逗常要在下面两种情况下三选一：1.数据量大，但是采用比较简单的模型，而且比较少的选代次数，也就是说用夫量的数据做一个浅层的机器学习。

ADD NOTE

HIGHLIGHT (YELLOW) • LOCATION 2452

2.数据量较小，但是采用比较复杂的模型，而且经过很多次选代训练出准确的模型参数。通常，由大量的数据、较少选代训练出的“软粗糙”的模型，要比用少量的数据、深度的学习精耕细作得到的棋型效果更好。

数据挖掘：机器智能的关键

HIGHLIGHT (YELLOW) • LOCATION 2459

2010年，Google宣布开发出名 Google大脑（Google Brain）的深度学习工具。从机器学习理论上来讲，它没有任何突破，只是把过去的人工神经网络并行地实现了。但是从工程的角度上来讲，它有非常大的意义。首先，过去的人工神经网络无法训练很大的模型，即使计算的时间再长也傲不到，因为内存中根本放不下和模型参数相关的数据。Google的突破在于找到了一种方法，可以将一个很大的模型上百万参数同时训练的问题，简化为能够分布到上万台（甚至更多）服务器上的小问题，这样使得大型的人工神经网络训练成为可能。当然，Google还找到了（不是发明了）一些对大棋型并行训练收效比较快的训练算法，可以在能够接受的时间内，深度训练出一个大型的数学模型。Google在几个带有智能特色的问题上，用这个深度学习的工具对语音识别的参数进行重新训练，就将识别的错 率降低了15%（相对值）［9〕，这对于机器翻译效果同样显著。

ADD NOTE

HIGHLIGHT (YELLOW) • LOCATION 2477

当然，机器学习的算法很多，Google或者某个大公司也不可能把每一种算法都实现得最有效，而一般的公司也不可能有技术力最去开发工程难度很大的机器学习软件，因此最好的解决方式就是出现一些专门做机器学习的公司，来为需要使用大数据和机器智能的公司提供服务。2012年Google在安迪：鲁宾的主导下，以5亿美元的巨资收购了只有100人左右的小公司DeepMind。这家公司对外宣传其所做的事情是让计算机有思维，其核心技术就是研究通用的机器学习算法，

ADD NOTE

HIGHLIGHT (YELLOW) • LOCATION 2483

机器学习的方法不可能由每冢公司自已去研究，最终会由专业的公司为大众提供机器学习的服务。但是这样又会引发大家的一个优虑，那就是数据安全和隐私保护的问题。

ADD NOTE

数据安全的技术

HIGHLIGHT (YELLOW) • LOCATION 2486

数据安全有两层含义，首先是要保证用户的数据不报坏、不丢失。10年前，云计算刚开始普及，大家所担心的是数据存储在云端会丢失。经过了10年，互联网用户或多或少都有了使用云计算的经历，已经体会到数据放在云端上的方便性。在这10年里，也没有发生什么数据存在云端取不回来的情况，实际上比放在自己的电脑上或者手机上安全多了，因此大象不再担心这方面的问题。

ADD NOTE

HIGHLIGHT (YELLOW) • LOCATION 2540

硅谷的Trustlook公司和中国一象电信运書商的信息安全服务公司就是这么做的。它们都利用大数提分析和机器学习了解公司正常的业务流程，发现并防止异常操作。不仅一家公司正常的业务沉程可以学习，当数据量足够大时，每个被授权的使用者的操作习惯也可以学习，那么不符合这些习惯的操作就可能来自非法的闯入者，这些操作就会被禁止。

ADD NOTE

保护隐私：靠大数据长期挣钱的必要条件

HIGHLIGHT (YELLOW) • LOCATION 2569

大家通常会夸大大数据带来的便利之处而忽视它对个人隐私带来的危害，因为大众对于隐私的重要性普過不够重视。当然可能会有一些读者挑战我的这个说法，认为大众，特别是欧美国家的人，还是很重视保护个人隐私的。但实际上，欧美国家的人常常也只是把保护陈私挂在嘴边而已。


保护隐私：靠大数据长期挣钱的必要条件

HIGHLIGHT (YELLOW) • LOCATION 2613

需要指出的是，保护隐私并非简简单单地屏藏撑一些个人信息那么简单。在过去这种方法是有效的，因为各种维度的数据联系不到一起。但是在大数据时代，由于大数据多维度和全面性的特点，简单屏藏據的很多信息是可以从其他维度利用相关性恢复的。因此，保护隐私需要新的技术。一类保护隐私的技术是从收集信息的一开始就对数据进行一些预处理，预处理后的数据保留了原来的特性，使得数据科学家和数据工程师能够处理数据，刧“读不懂”“数据的内容。这样至少能防止个人窃取和泄解隐私，但是并不能限制那些拥有非常多数据的大公司了解每一个人的隐私。另一类保护隐私的技术是所谓的双问监视。这是一个很新额的保护隐私的想法，简单地讲就是当使用者看计算机时，计算机也在盯着使用者看。大部分人喜欢偷窥别人隐私的一个原因是，这种行为是没有任何成本的。但是，如果有人在刺探别人隐私时，他的行为本身暴解了，那么他就会多少约束自己的行为。这就好比一个偷窥者悄悄推开门缝往里面婉视，发现里而有双眼睛正在看着他，那么他的反应可能是马上把门关上。凯文-凯利对各种保护隐私的技术做了评估，他和研究人员发现，如果给窥视者一个选择，输入自己的真实信息然后才可以窥视他人，那么绝大多数人会选择直接离开。正如制约权力最好的办法是使用权利，解决一种技术带来的湯洞最好的办法是采用另一种技术，那么保护隐私最好的办法或许是让侵犯隐私的人必须以自己的隐私来做交换。

ADD NOTE

第六章 未来智能化产业

HIGHLIGHT (YELLOW) • LOCATION 2666

智能产业”。在这些产业中，具有智能的计算机可以帮助我们完成相当多的工作，甚至是绝大部分工作。

ADD NOTE

未来的农业

HIGHLIGHT (YELLOW) • LOCATION 2680

1990年我去中国西部出差，参观一些治理沙淡的项目。当地人告诉我这样一件事，他们听说以色列人能在干旱的土地上实现农业高产，就请了一些以色列的专家来指导农业。这些以色列人到中国的大西北考察了自然条件之后说，你们这里哪儿吗缺水，水比我们以色列多多了。以色列的自然环境实在是太差，绝大部分士地为沙谈，可耕种面积不到国土面积的五分之一，而且士层是世所罕见的贪瘠，更要命的是水资源严重匮乏。在以色列境内只有一条约旦河（还要和阿拉伯人共享水源），以及一个小得微不足道的淡水湖。以色列降雨极少，年降水量约200毫米，古士地面积一大半的南部内盖夫沙谈，每年平均降雨量仅有25~50毫米。这么少的降雨量是什么概念呢？对比一下我们常说的缺水的大西北就知道了。兰州年降雨量达325毫米，西宁380毫米，乌鲁木齐200~800毫米不等，都比以色列多很多。然而，就是在这样一片生存条件恶劣之地，以色列人创造了令人噸舌的奇迹，许多农产品的单产量领先于世界先进水平。他们的奶牛单产奶量居世界第一，平均每头年产奶

10500公斤，每只鸡年均产蛋280个，棉花单产居世界之首，盲产近1000斤（中国为228斤）〔1〕，柑橘年均亩产多达3吨（中国为0.5吨），西红柿年均盲产产20吨（2〕。由于单产高，以色列

居然成为农产品出口大国，每年向欧洲出口夫量的蔬来和水果，有“欧洲的厨房”之称。不仅如此，这个于早的沙谈国家还成为仅次于荷兰的世界第三大花齐供应国。2007年，以色列农业总产值为55亿美元，其中，农业出口占40%，达21.72亿美元，也就是说，以色列平均一个国民贡献了世界上1.7个人的食物。以色列取得这样的成就，其根本原因是靠科技兴农，而不是靠破坏生态环境，蝎洋而渔。

ADD NOTE

HIGHLIGHT (YELLOW) • LOCATION 2696

作为严重缺水的国度，以色列人发明了滴灌技术—装有滴头的管线直接将水和肥料送达植物的根系，大大节约了水和肥料。所有涨溉方式都采用计算机进行自动化控制，溉系统中有传感器，能通过检测植物茎果的直径变化和地下湿度，来决定对植物的灌溉量，这样可以节省人力和水资源。

未来的农业

HIGHLIGHT (YELLOW) • LOCATION 2702

如果农田可以靠精确的灌溉，那么草地、花园、院落等凡是需要用水灌溉的地方是否也能够采用类似的方法大幅度节省用水呢？答案是肯定的。2013年7月的《时代》周刊报道了硅谷一家小公司发明的Drople像庭院落自动喷水机器人。这种机器人从外观上和行走的方式上看与目前很多家庭使用的扫地机器人有点像，但是智能水平要高很多。Droplet的喷水机器人首先会对每个家庭的院落扫描一遍，看看院子里有多少植物和草坪需要浇灌，同时它还测试各处土地的湿度和植物的高度，以决定喷水量。

ADD NOTE

HIGHLIGHT (YELLOW) • LOCATION 2709

根据《时代》周刊的报道，一些家庭使用 Droplet之后，可以节省95%以上的浇水量。在2015年加州最干早的季节，很多小区为了节水，由物业补贴钱让住户购买这种喷水机器人。

ADD NOTE

未来的体育

HIGHLIGHT (YELLOW) • LOCATION 2723

硅谷地区有两种人最不缺，即风险投资人和工程师，勇士队的奇迹从很大程度上讲是靠他们创造的，前者善于看到其他人还没有发现的投资潜力，然后把它经营成值钱的实业；后者善于利用技术创造奇迹。勇士队的成功就是他们合作的结果。6年前勇士队的比赛成绩跌到了谷底，因此价值较低，一些风险投资人决定将这支不值钱的球队买下来好好经营，让它成为美国体育界最耀眼的明星。这个计划看上去有点疯狂，不过投资人有自己的考虑，他们有秘密武器，那就是能够应用大数据的工程师。最终，投资人花了4.5亿美元这个相对较低的价格完成了对勇士队的收购。在收购完成后，投资人为球队委派了新的管理层，在管理层的背后，有一些工程师在利用大数据制定球队的发展战略和比赛战术。新的管理层在上任后所做的第一件事，不是购买大牌球星，反倒是把队伍中的明星给卖掉了，然后他们围绕一位当时毫无名气的球员重新制定球队的风格和战术，当然管理层的决策依据是从大数据中得到的结论。根据数据分析的结果，管理层认为现在NBA以及很多职业联赛所追求的打法是低效率甚至是错误的。几十年来，NBA的发展一直在追求制空权，球队寻找个人身体条件突出的球员们，他们要么伸手就能将篮球装进球筐（比如姚明），要么能高高跃起从上往下把篮球扣进球筐（比如乔丹）。这样的打法虽然看起来漂亮，但是效率很低，因为需要全队费很大力气攻到篮下，把球传给那个大高个儿，即便不出现传球失误，也就是得2分，扣篮也是如此，在耗费巨大的体力之后，也是得2分。勇士队的管理层设计的新打法却是尽可能地从24英尺（大约7.3米）外的三分线投篮，这样可以得3分。正是因为不再按照篮球传统的战术作战，勇士队才卖掉了那些价钱高劫效率低的明星，而着重培养自己看中的新人。这位新人叫斯蒂芬•库里（Stephen Curry），今天他在美国已经家喻户晓，中国的篮球迷对他也非常熟悉，但当年他可是一个没有人要的球员。库里身高只有

1.91米，在篮球场上和那些明星大腕相比可谓相形见绌，高中毕业时，那些篮球强校的教练都看不上他。2009年他被勇士队以很便宜的价格签约（4年只有1270万美元，而姚明登陆NBA第一年的薪酬就高达1250万美元），尽管他在大学篮球队表现不错，但那并不是一支顶级的大学篮球队，因此他的对手们也没有把他放在眼里。

ADD NOTE

HIGHLIGHT (YELLOW) • LOCATION 2741

勇士队的管理层之所以要重用库里，是因为他有一个特长，那就是投篮准确，勇士队最终把他培养成了一位三分球的神投手。在2014~2015年赛季中，库里的神投让勇士队夺得了40多年来的第一个总冠军，他自己也成为当年的最有价值球员（MVP）。到了2015~2016赛季，库里投进了403个三分球，创造了 NBA历史上的纪录，打破了由雷•阿伦所保持的个人单赛季269记三分命中数的纪录。库里投篮的准确率高达50%，三分球的命中率也高达45%，这意味着他的三分球比那些大牌球星的篮下投球更准。到后来，很多球迷跑去看勇士队训练，主要就是为了欣赏库里投三分球。当然，库里成名之后，在赛场上各个球队都要派人盯紧他，但这也给勇士队其他选手在篮下创造了机会。


未来的体育

HIGHLIGHT (YELLOW) • LOCATION 2748

按照一般教练的想法，勇士队应该趁机加强内线进攻才对，但教练史蒂夫•科尔不这么看。2014年科尔执教勇士队时，没有任何执教 NBA的经验，但勇士队的老板乔•拉格布（Joe Lacob）坚持使用这位新教练。拉格布是个篮球迷，却并不是篮球界的人士，他是著名风险投资公司凯鹏华盈的合伙人，套用俗话讲，他是一位“技术控”。他的合伙人很多甚至就是工程师出身，比如YouTube的联合创始人查德赫利（Chad Hurley）。因此他们更相信自己根据数据得到的结论，而不是来自 NBA的经验。拉格布看中科尔的是他在 NBA生涯中准确的投篮，后者作为和乔丹同时代的公牛队队员，夺得过5次总冠军，个人的投篮命中率高达45.4%，位列当时 NBA球员之首。科尔在执掌勇士队之后，坚持用数据说话，而不是凭经验，他根据背后团队对历年来 NBA比赛的统计，发现最有效的进攻是眼花缭乱的传球和准确的投篮，而不是彰显个人能力的突破和扣篮。

ADD NOTE

未来的制造业

HIGHLIGHT (YELLOW) • LOCATION 2772

造业的全面智能化。

ADD NOTE

2011年德国提出工业4.0的概念，即通过数字化和智能化来提升制造业的水平。相应地，中国也提出了中国制造2025的概念，其核心是通过智能机器、大数据分析来帮助工人甚至取代工人，实现制

HIGHLIGHT (YELLOW) • LOCATION 2775

曾几何时，产业工人的数量被看成是制造业竞争力的重要标志，大量低工资的生产线上的工人造就了全球制造业的繁菜。被称为“世界工厂”的中国在改革开放以后正是靠这一项核心竞争力跻身世界制造业大国行列。在中国，全球最大的OEM制造商富士康雇用了130万名廉价的工人，使得全球的电子产品制造商无法在成本上和它竞争。当然，富士康也得到了“血汗工厂”的恶名。由于雇用的工人太多，像富士康这样的公司即便有心将自己办成高福利的企业，也是做不到的。另一方面，它也不可能通过进一步压榨工人来降低制造成本。为了解决这些矛盾，富士康一直在研制取代生产线工人的工业机器人。富士康预计未来将装备上百万合机器人，逐渐取代装配工人。这使得工人们不再需要从事繁重而重复性的工作，但由于工厂所需要的工人数量大幅度减少，很多低技能的工人将失去工作。

ADD NOTE

HIGHLIGHT (YELLOW) • LOCATION 2790

机器人取代人类从事制造业的另一个巨大优势在于，产品很容易按照个性化定制。

ADD NOTE

HIGHLIGHT (YELLOW • LOCATION 2794

特斯拉很少雇用原来汽车行业的人员，除了降低成本外，还有一个更深层次的原因一它一直把自己定位成一个 TT公司，而不是汽车公司。汽车其实就是承载着特斯拉 IT技术的平台，特斯拉内部将汽

车看成是一个巨大的智能终端，通过这个智能终端，特斯拉把它的各种技术服务提供给大家，同时也参与到消费者的日常生活中，这和我们在前面提到的小米手机有不少相似之处。特斯拉颠覆现有汽车行业所做的另一件事，就是取消存在了一个世纪的汽车代理商制度。为什么特斯拉能够做到这一点，而比它更大的、更有话语权的那些大牌汽车公司却不得不分利给各地的代理商呢？这就要从产品生产和流通的产业链说起。

未来的制造业

HIGHLIGHT (YELLOW) • LOCATION 2800

一个。除了生产，商品的设计和研发、仓储和物资管理、物流和运输、批发和零售，在过去都是不可或缺的环节。我在《浪潮之巅》中介绍过戴尔的商业模式，它的成功在于一方面出让了最需要人力的生产环节，以降低成本，另一方面依然牢牢把控着其他重要的环节，以保证利润。过去，在生产以外的环节，要么需要所谓知识型的员工来完成，要么需要本地的员工。比如汽车的销售在过去依靠的就是本地员工，如果由汽车厂直接在销售地雇人，成本会比交给代理商更高。但是到了大数据时代，除了商品的设计和研发，剩下的环节要么高度智能化（比如仓储和物资管理），要么干脆被砍掉（比如批发行业），因此在制造业中那些所谓高端的工作也面临着被机器智能所取代。比如阿里巴巴的崛起，就让很多批发行业的工作从此消失了，当然，同时也带来了全社会效率的提升。

ADD NOTE

HIGHLIGHT (YELLOW) • LOCATION 2814

仅仅靠降低工人工资的低水平竞争将不再具有制造业方面的优势，因为它在未来的竞争要靠从设计到销售全过程的智能化水平。当然，在我们欢呼整个制造业效率提升、产品质量提升的同时，有一个问题值得关注，那就是被机器智能取代的劳动力如何安排，

ADD NOTE

未来的医疗

HIGHLIGHT (YELLOW) • LOCATION 2823

今天，人类在医疗保健上遇到了一些瓶颈，主要体现在以下几方面：首先是医疗的成本越来越高。以美国为例，今天医疗保健的开销已经占到GDP的17%~18%左右〔4〕，而且按照目前的发展趋势，到2020年，这个比例将上升到20%。在中国，虽然这个比例很难准确估计，因为很多与医疗保健有关的花销是隐形的，但是“看不起病”是社会的共识。其次，医疗资源不平衡，这一点几乎每一个中国老百姓都认同。在医疗发达的美国，这个问题同样存在，拥有约翰•霍普金斯医院〔5〕、海军总医院〔6〕、协和医院（Union Memorial Hospital）和国家医学院的马里兰州，人均医疗资源是全美国平均水平的3倍。由于医院集中，像协和医院这样历史悠久的大医院居然会为病人的数量发愁。在全世界范围内，医疗资源不平衡的问题更加严重。最后，也是最关键的，很多疾病治不好，比如癌症、帕金森综合征和阿尔茨海默症（即人们常说的“老年痴呆”）。尽管全世界医生和科学家们已经努力了许多年，世界各国也投入了大量的资金来寻找上述疾病的治疗方法，但是在过去的20多年里，医学在这些领域的进展十分缓慢。我们不妨从这三个方面来看看大数据和机器智能将如何改变全世界医疗保健以及制药行业的现状。

ADD NOTE

HIGHLIGHT (YELLOW) • LOCATION 2834

降低医疗成本先看看医疗成本的问题。美国医疗系统有一个制度上的缺陷，就是医疗事故赔偿过高，律师拿钱太多。

ADD NOTE

HIGHLIGHT (YELLOW) • LOCATION 2840

从医疗本身讲，医疗成本高的前两个重要原因是药品的研制周期太长、费用太高，以及医务人员培养的成本太高。

ADD NOTE

HIGHLIGHT (YELLOW) • LOCATION 2847

造成美国医疗成本非常高的第二个原因是医务人员的收费很高。在欧美等发达国家，医生可以说是“三高”的职业—高学历、高收入和高地位，而在医生中间，专科医生，比如诊断癌症的放射科医生或者做手术的胸外科医生、脑外科医生，又是医生群体中收入最高的群体，他们的平均收入远远高于上市公司高管的平均水平。


未来的医疗

(8)

HIGHLIGHT (YELLOW) • LOCATION 2861

具体讲，在美国培养一名合格的专科医生的过程大体如下：首先，他们要完成4年大学本科学习，因为在美国只有获得本科学位之后才能够学医。在本科毕业后，那些所谓的医学预科生（Pre Med）要经过激烈的竞争才能进入医学院，好的医学院的录取率要远比哈佛大学低〔13〕。在医学院里，这些幸运的未来的医学博士要接受4~5年的医科学习，医学院的学习负担要比一般的研究生专业重得多。在完成医学院学习之后，如果运气好的话，经过2年左右的医院实习（实习医生）和2~3年的专科实习（Fellow），才能获得专科的行医执照。整个过程平均要花费13年之久，中间还会有很多次被淘汰的可能。实际上，高中毕业时想成为专科医生的人并不算少，但是真正获得行医执照的少之又少。其次，成为专科医师的学习费用也是相当高的，因为读医学博士的人是没有奖学金的，如果再考虑到读本科时也要自己掏钱，那么一个成绩优秀的学生从本科算起，到医学院毕业，大概需要花费50~70万美元。在欧美国家，大多数人又不愿意啃老，因此，每一个专科医师在能够开始挣钱时都已经负债累累。从投资回报的角度讲，既然时间和金钱的投入都如此巨大，他们必须有高收入才合算。

HIGHLIGHT (YELLOW) • LOCATION 2887

今天，世界上最有代表性的做手木的机器人就是达•芬奇手术系统。达•芬奇手术系统分为两部分：手术室的手术台和医生可以在远程控制的终端。手术台是一个有三个机械手臂的机器人，它负责对病人进行手术，每一个机械手臂的灵活性都远远超过人，而且带有摄像机可以进入人体内手术，因此不仅手木的创口非常小，而且能够实施一些人类医生很难完成的手术。在控制终端上，计算机可以通过几台摄像机拍摄的二维图像还原出人体内的高清晰度的三维图像，以便监控整个手术过程。医生也可以在远程对手术的过程进行人工干预。达：芬奇手术系统的主要发明人之一，约翰-雀普金斯大学的拉塞尔•泰勒（Russell Taylor）教授是我的朋友和师长，因此我有幸亲身体验操作该机器人。他为我在手术台上设置的是一个仿制的人脑，我在远程用手术刀虚拟切割时，手的感觉和切割真实的组织是一样的。目前全世界共装配了3000多台达-芬奇机器人，完成了300万例手术。

ADD NOTE

HIGHLIGHT (YELLOW) • LOCATION 2918

人类在抗癌研究方面投入的资金比阿波罗登月或者语音识别要多得多，但为什么至今依然难以根治癌症呢？李文森博士讲，世界上并不存在一种一劳永逸的万灵药，能够像青霉素杀死细菌那样杀死所有的癌细胞，这是今天医学界普遍的认知，与半个世纪前大不相同。我们知道，癌细胞是动物和人自身细胞在复制的过程中基因出了错，而非来自体外，因此它们与人和动物正常的细胞非常相似。今天最有效的方法是，使用基因技术研制出的抗癌药来治疗，从机理上讲是找到病变的基因并且把相应的癌细胞杀死。不过，由于不同人即使得了同一种癌，其癌细胞病变的基因未必相同，因此一种抗癌药可能对某些病人管用，但是对其他病人并不管用。我们通常听到的发生在身边的故事就是这样。实际上，大部分医生在给癌症患者用药时，需要对患者进行基因比对，以确定是否能用某种抗癌药。医治癌症第二个难点，也是最根本的难点在于癌细胞本身的复制也会出错。这一点其实并不难理解，因为基因在复制的过程中出了一次错误就可能出第二次。这样一来，原本管用的抗癌药就变得不管用了。抗癌药在杀死癌细胞时，未必能够把所有的都杀死〔16〕，剩下哪怕只有一个癌细胞未被杀死，它依然可以迅速繁殖，并且可能出现新的基因突变。我们通常会听到这一类故事：某个患有癌症的亲友已经将病情控制了很长时间，突然一夜之间复发，而且药物不起作用，很快便离世了。这里面的原因就是癌细胞基因的变化使得原有的抗癌药不灵了。由于癌细胞基因的突变和人有关，而且可能一再突变，因此要想彻底解决问题，就需要针对不同的患者设计特定的抗癌药，而且要根据患者癌细胞每一次新的变化研制新药。李文森博士认为，只要这个研制速度能够赶得上癌细胞的变化，那么，即使不能彻底杀死所有的癌细胞，患者仍可以长期和癌症共存。从理论上讲，这种方法是可行的。但是这样做的成本太高：首先要有一个专门的研发团队围绕着每一个患者进行药品的研制，而且研发的速度还要足够快；其次，它的耗费至少在每人10亿美元以上。因此，全世界除了个别的亿万富翁，都不可能用这种方法来治疗癌症。这就是目前人类在抗癌方面遇到的困境，这个困境是无法通过传统的医学进步走出来的。事实上，在过去的20多年甚至更长的时间里，全世界医学界对癌症机理的理解和治疗方式的改进都是非常有限的。那么出路在哪里呢？李文森博士认为这要依靠最新的IT技术，尤其是大数据。根据基因泰克的科学家解释，我们已知的各种可能导致肿瘤的基因错误不过在万这个数量级，而已知的癌症不过在百这个数量级。也就是说，即使考虑到所有可能的恶性基因复制错误和各种癌症的组合，不过是几百万到上千万种，这个数量级在TT领域是非常小的，但是在医学领域则近乎无穷大。如果能利用大数据技术，在这不超过几千万种组合中找到各种真正导致癌变的组合，并且对这样每一种组合都找到相应的药物，那么对于所有人可能的病变都能够治疗。针对不同人的不同病变，只要从药品库中选一种药即可，比如对患者约翰，他原本是使用第1203号药品，如果发生新的病变，经过检查确认后，改用256号药品即可，这样并不需要每一次重新研制药品。如此一来，便可以控制癌症了。虽然这样成千上万种药总的研发成本不低，但是如果摊到全世界每一个癌症患者身上，李文森博士估计只需要人均5000美元左右。

未来的医疔

HIGHLIGHT (YELLOW) • LOCATION 2956

•在他和Google创始人佩奇看来，治疗癌症的意义远没有大众想象的大，而人类长寿面临的最大挑战是衰老问题—只要人们活得足够长（而且不患癌症），最后的结局都会是阿尔茨海默症，无一例

ADD NOTE

未来的律师业

HIGHLIGHT (YELLOW) • LOCATION 2986

大数据对司法领域的另一个重大影响在于机器智能会逐渐取代律师做一些案例分析工作，这使得诉讼的成本有可能大幅度下降。

ADD NOTE

HIGHLIGHT (YELLOW) • LOCATION 2996

高昂的律师费不仅对大公司来讲是个负担，而且使得小公司几乎难以赢得官司，因为它们常常在打赢官司之前就已经拿不出律师费将官司继续打下去。在美国打官司，律师费用高昂的原因有很多，其中最重要的一个是英美法系是判例型法律体系（又称海洋法系），打一场大官司，需要将历史上相关的官司法律文件都拿出来分析，这个工作量巨大。像 Google和 Viacom之间的官司，需要分析上百万份历史文档。到了大数据时代，这个情况会慢慢得到改变。今天，一些公司利用自然语言处理和信息检索技术，发明了让计算机阅读和分析法律文献的软件，可以取代很多人工。位于硅谷帕罗奥图市的 Blackstone Discovery（黑石发现）公司发明了一种处理法律文件的自然语言处理软件，使得律师的效率可以提高500倍，而打官司的成本可以下降99%，这意味着未来将有相当多的律师（尤其是初级水平的律师）可能失去工作。事实上这件事情在美国已经发生，新毕业的法学院学生找到正式工作的时间比以前长了很多。

ADD NOTE

未来的记者和编辑

HIGHLIGHT (YELLOW) • LOCATION 3011

未来的记者和编辑如果我们把计算机分析案卷和病例看成是一种阅读行为，那么今天的计算机已经发展到不仅能读，而且还能写作了。其实计算机在自动回答问题时，就已经具有了简单的写作本领，因为计算机回答问题的最后一个步骤就是将知识的片段写成优美的文字段落。当然，在回答问题时，所需要写的只是简单的段落而非完整的文章。今天计算机写作的本领到底有多大？我们可以把写作从简单到复杂分为下面5个层次：1.书写完整的句子。2. 组织几个句子构成符合逻辑的段落。3.给予特定格式，或者写作模板，能够清晰传递信息，表达意思。4.能够不限定格式地写作内容，达到一般人平均水平。5.能够达到专业记者、作家和学者水平。

ADD NOTE

HIGHLIGHT (YELLOW) • LOCATION 3028

这样合成的文章读起来未免生硬，因此计算机还要用一种被称为语言模型〔20〕的概率模型，将文字构造成优美的句子，再用另一个语言模型将句子组合成段落。这些模型也是从以往的数据中训练出

来的。

ADD NOTE

HIGHLIGHT (YELLOW) • LOCATION 3036

机器智能会给人类带来一个终极问题：既然什么事情都可以让机器来做，而且还比人做得好，那么人类怎么办？


未来的记者和编辑

第七章 智能革命和未来社会

HIGHLIGHT (YELLOW) • LOCATION 3062

第七章智能革命和未来社会在历次技术革命中，一个人、一家企业，甚至一个国家，可以选择的道路只有两条：要么加入浪潮，成为前2%的人，要么观望徘徊，被淘汰。

ADD NOTE

智能化社会

HIGHLIGHT (YELLOW) • LOCATION 3075

大数据和机器智能将把我们社会的管理水平提升到一个前所未有的高度，使我们生活的环境更加安全。

ADD NOTE

精细化社会

HIGHLIGHT (YELLOW) • LOCATION 3167

其实，今天大家用药和就诊这件事透露出工业时代的一个特征，就是一切标准化。在工业革命开始以前，人类使用的产品、享受的服务都有细微的差别，当然这样效率很低。

ADD NOTE

无隐私的社会

HIGHLIGHT (YELLOW) • LOCATION 3179

无隐私的社会到目前为止，我们一直在讲的是大数据和智能革命对社会、对我们的生活所带来的正面影响。但是任何事情一定都有两面性，大数据和智能革命对未来社会的冲击也是不能小视的，我们或许会生活在一个没有隐私的环境里，或许会被一些超级权力在无形中控制，甚至很多人因为没有掌握未来生存的技能而找不到工作，财富可能会更加集中在少数人手里。根据历史的经验，这些问题是无法回避的，而且也不存在快速的解决方法。

ADD NOTE

HIGHLIGHT (YELLOW) • LOCATION 3185

实际上，大数据和机器智能引发的隐私问题会非常严重，在今天和未来，当移动互联网（以及正在快速发展的万物联网技术）、大数据和机器智能三者叠加到一起之后，我们不再有隐私可言。

无隐私的社会

HIGHLIGHT (YELLOW) • LOCATION 3196

很多疾病也有这样的关联关系。这家医学院研究的目的当然是善意的——为了提前防治疾病。但是，研究成果如果让医疗保险公司使用，那么它们就有权利拒绝接受一位未来可能得重病的投保者。美国各大保险公司实际上掌握着投保人过去多年的身体状况信息，因为医生每一次向保险公司索要医疗费时，都会提供这些信息。在过去，由于机器智能的水平不高，这些事没法做，保险公司一般对投保者一律接受，但是在法律上，它们有拒绝投保人的权利。在过去，我们泄露隐私有时是不得已的，比如不能不去看病，而医生也不能不去问保险公司要钱。但是在移动互联网时代，尤其是今后万物联网的时代，我们本身就是主动的隐私泄密者。绝大部分智能手机的使用者安装了太多的、很少使用甚至并不必要的APP，参加了太多的优惠促销活动。同时，在自认为安全的社交网络说了很多在公众场合不适合说的话，或者发了太多的照片。这些都可能造成人为的隐私泄解。我们还在使用的各种电子产品，从可穿戴式设备到带有GPS的照相机，再到与Wi-F相连的各种智能电器，不自觉地记录下了我们详细的行踪和生活信息，并且提供给了服务商。很多时候，第三方再通过服务商获得这些信息，也并非难事，究其源头，是我们自己在不设防的情况下把信息泄露出去的。

ADD NOTE

HIGHLIGHT (YELLOW) • LOCATION 3213

其次是低估了机器智能的力量。很多人认为，虽然某个公司即使有了关于我的很多数据，但是那些数据都是杂乱无章的，该公司哪有工夫专门和我这个小人物过不去。岂不知在机器智能时代，挖掘个人隐私并不需要人来做，而是由机器完成的。最后，也是最重要的原因，就是很多人一厢情愿地把个人隐私寄托在数据拥有者的善意（Goodwill）上。虽然到目前为止，Facebook、腾讯和阿里巴巴这些实际上已经掌握了用户隐私的公司似乎还靠得住，但是掌握了大量用户数据的公司远不止这几家。当掌握大量用户数据的公司和用户利益发生冲突时，前者会有意无意地最大化自己的利益，而牺牲掉用户的利益。我们从前面的一些案例中看到，把我们的隐私权建立在别人的善意上，是根本靠不住的。

ADD NOTE

HIGHLIGHT (YELLOW) • LOCATION 3221

约翰-霍普金斯大学工学院院长施乐辛格（Edward Schlesinger） 教授本身是大数据的倡导者，但是他也担心，如果保险公司能了解到每一个人今后会得什么病，将拒绝给那些可能得致命性疾病的人

提供保险，那么那些最需要医疗保险的人反而无法买到医疗保险，或者必须支付天价保费。

ADD NOTE

HIGHLIGHT (YELLOW) • LOCATION 3241

到了大数据时代，如果真有一个老大哥想监控每一个人，其实是可以做得到的，他也不需要采用东德安全部的笨办法，因为大家的隐私都保存在互联网的某处。假如出现一个强权，要求拥有大数据的服务提供商交出数据，建立在善意基础上的隐私保护就显得非常脆弱了。民众即便不懂得什么是大数据，不懂得大数据容易泄露隐私，对强权部门索要数据的事情也是非常担心的。

ADD NOTE

机器抢掉人的饭碗

HIGHLIGHT (YELLOW) • LOCATION 3263

当计算机变得足够聪明之后，一定会取代人类完成很多需要高智力的工作。

机器抢掉人的饭碗

HIGHLIGHT (YELLOW) • LOCATION 3264

人类总体来讲是过分自信的，趋利而忽视危害，这一点研究幸福学和心理学的学者早就有了定论，我们不做过多的讨论。机器智能如此天翻地覆的革命，不可能不对社会产生巨大的负面影响。我们在给大家展示大数据和机器智能带来的美好前景时，也必须强调它们可能会给很多人的生活带来负面影响。不过遗憾的是，很多人对此不以为然，就如同历史上工业化国家的民众曾经的不以为然一样。

当社会面对重大技术革命所产生的冲击不知所措，要两代人才能消除它的负面影响时，大家才开始感叹历史再一次重复。智能革命将比过去历次技术革命来得更深刻，对社会带来的冲击可能是空前的。为了说清楚这一点，我们首先来回顾一下历史。

ADD NOTE

HIGHLIGHT (YELLOW) • LOCATION 3294

新技术在出现的初期，受益者是非常少的，他们通常只是那些掌握新技术或者使用新技术、从事新行业的人。具体到工业革命，最初的受益者只有博尔顿那样的工厂主、瓦特那样的发明家，或者使用蒸汽机开拓瓷器制造新行业的韦奇伍德等人。其他人在短期内是很难受益的，甚至可能因为新技术的出现变得更加贫穷，因为机器抢了他们的生计。在工业革命后的半个世纪里，原有的经济结构被摧毁，靠有一技之长的工匠运作的小作坊纷纷破产，工匠的特长敌不过年轻劳工结实的身体，他们从中产阶级沦为赤贫。因此从 18世纪未到 19世纪上半叶，是英国贫富分化严重、社会矛盾重重的半个

ADD NOTE

HIGHLIGHT (YELLOW) • LOCATION 3307

那么工业革命的副作用是怎样被解决的呢？简单讲就是资本输出，开拓全球殖民地，推行自由贸易。英国的工业生产在工业革命之后让世界各国都无法望其项背，这使得它有能力、财力、武力按照自已的意志建立全球化市场。英国工业革命产生的产业工人只有几百万，但其巨大的生产能力却使得很多商品供大于求。由于在当时世界上没有第二个国家在国力上可以和英国匹敌，因此它的全球战略得以实施。

ADD NOTE

HIGHLIGHT (YELLOW) • LOCATION 3311

我们可以把工业革命对社会的影响分成三个阶段：第一个阶段只有发明家和工厂主们受益，普通英国民众并没有受益；第二阶段是全体英国民众普遍受益，但是在世界范围内大家未必受益，这两个阶段之间相差半个多世纪；第三个阶段才是整个世界受益，这和第二个阶段又相差很长时间。是否其他重大技术革命也有类似的特点呢？让我们来看看19世纪的第二次工业革命，有趣的是，上述的模式重复出现了。

ADD NOTE

HIGHLIGHT (YELLOW) • LOCATION 3330

贫富差距非常严重。运输业大王范德比尔特通过建立信托控制了10%的上市公司财富，而洛克菲勒聚集的财富占全美国的1%。为了实现社会的公平化，美国开展了坚决的反托拉斯行动。经过老罗斯福、塔夫脱和威尔逊三任总统近20年的努力，美国政府强行肢解了洛克菲勒的标准石油公司和JP摩根控制的北方钢铁公司，并且在制度上限制大家族过多地控制社会财富，比如征收高额的遗产税。

ADD NOTE

HIGHLIGHT (YELLOW) • LOCATION 3349

信息时代是人类历史上第二个创造财富的高峰年代。在美国，从20世纪50年代末到70年代初的20年间，出生了苹果公司创始人史蒂夫•乔布斯、微软公司创始人比尔•盖茨和保罗•艾伦、太阳公司创始人安迪-贝托谢姆和比尔-乔伊、戴尔公司创始人迈克尔-戴尔、Google创始人拉里•佩奇和谢尔盖•布林等人，他们在自己年富力强时幸运地赶上了信息革命的大潮。但是，美国大众的生活质量并没有

很大的改变。图7.8展现了美国最富有的5%的家庭、财富值中值的家庭，以及贫困家庭从1967年到2012年（扣除通货膨胀后）财富增长的情况。我们可以看出，除了最富有的5%的家庭财富有明显增长之外，其他人的财富变化很小。



机器抢掉人的饭碗

HIGHLIGHT (YELLOW) • LOCATION 3360

况，不太感受到它的负面影响。

ADD NOTE

这些数据表明以摩尔定律为核心的上一次技术革命带来的社会效益，即便是作为全球信息革命中心的美国仍然没有来得及消化完。而中国作为全球信息革命的另一个中心，由于我们前面所讲的特殊情

HIGHLIGHT (YELLOW) • LOCATION 3368

解决问题只有靠时间为什么每一次重大的技术革命都需要很长的时间来消除它所带来的负面影响呢？因为技术革命会使得很多产业消失，或者产业从业人口大量减少，释放出来的劳动力需要寻找出路。这个时间有多长呢？事实证明至少要一代人以上，因为我们必须承认一个并不愿意承认的事实，那就是被淘汰的产业的从业人员能够进入新行业中的其实非常少。虽然各国政府都试图通过各种手段帮助那些从业人员掌握新的技能，但是收效甚微，因为上一代人很难适应下一代的技术发展。事实上，消化这些劳动力主要靠的是等待他们逐渐退出劳务市场，而并非他们真正有了新的出路，能够和以前一样称心如意地工作。这就是每次技术革命都需要花半个世纪来消除它带来的动荡的原因。唯一不同的是，在一百年前，各国政府认识不到关心这些被产业淘汰的从业人员的重要性，因此让社会很动荡。如今，各国意识到社会稳定很重要，因此即使很多人并不创造价值，也只好“养着”。为此，有些国家将无所事事的人强制塞到公司里（比如日本和欧盟），有些国家不肯淘汰过剩产能（比如中国），但解决问题的途径都是一个“耗”字。耗上两代，社会问题就解决了。

ADD NOTE

HIGHLIGHT (YELLOW) • LOCATION 3395

对那些曾经为人类的文明做出过贡献，但已经被技术革命所淘汰的员工，唯一的希望就是他们的后代能够进入一个新的行业。这实际上是靠时间慢慢地消化技术革命带来的负面影响。

ADD NOTE

HIGHLIGHT (YELLOW) • LOCATION 3403

首先，信息革命本身带来的影响还没有消化完。全球信息化带来的效率已经使得很多人无事可做，很少人制造出来的东西就足够全球人口消费。在美国将近一半的人是不上税甚至从政府拿补贴的，从单纯经济的角度看，他们每天所提供的劳动仅仅是让自己生存下去而已，甚至还不够，他们对社会继续发展的贡献可以说是微乎其微的。在一个民主国家，这些人最大的用途就是手中的那一张选票，以至于政客们为了选票可以轻易许诺，然后把国家的债务和赤字越堆越高。第一次和第二次工业革命带来的负面影响都花了半个世纪以上的时间来消除，而摩尔定律从1965年提出距今已经半个多世纪了，它带来的影响至今还没有消化掉。这时，智能革命又开始了，因此这次的冲击力度将是双重叠加的结其次，今天的世界和200年前已经不同了，消化掉技术革命的影响要比工业革命时难得多。

由于全球化，全世界已经没有空自的市场可以开拓了。英国人在19世纪中期能够过上相对富裕而从容的生活，是因为他们只需要解决几百万产业工人的生活和工作问题就可以了。整个19世纪，是用全球的市场，解决当时只占世界人口很小一部分的产业工人的生活问题，相对要比今天容易得多。

ADD NOTE

HIGHLIGHT (YELLOW) • LOCATION 3413

最后，也是最重要的一点，智能革命所要替代的是人类最值得自豪的部分——大脑。

ADD NOTE

HIGHLIGHT (YELLOW) • LOCATION 3416

由于机械毕竟不能完成智能的工作，因此人们最终还是找到了谋生的手段。不过智能革命的结果是让计算机代替人去思考，或者说靠计算能够得到比人类思考更好的结果，能够更好地解决各种智能间题，这时，人类会突然发现自己还能做得比计算机更好的事情已经所剩不多了。我们在上一章介绍过，智能革命中，计算机所取代的不仅仅是那些简单重复性的劳动，还包括医生、律师、新闻记者和金融分析师等过去被认为是非常需要脑力的工作。概括来讲，智能革命对社会的冲击可以用强度更大、影响面更广、更深刻来概括。我们必须回答一个问题：当全社会各行各业的从业人数都因为机器智能而减少时，全世界几十亿劳动力怎么办？当然，很多人会天真地认为，船到桥头自然直，劳动力会被自然而然地分配到其他行业中去。但是，这种劳动力的再分配，一来需要非常长的时间，二来依赖于产生新产业。


机器抢掉人的饭碗

HIGHLIGHT (YELLOW) • LOCATION 3433

在1900年前后，美国东北部的波士顿地区的人只要有一份工作，就能在波士顿市内或者查尔斯河对岸的坎布里奇〔13〕买一栋连排别墅（Town House）。今天，那里的人需要在Google或者辉瑞制药公司里有一份非常好的工作，才能买得起同样水平的住房。在20世纪60年代，通用汽车公司一家就造就了近百万个中产阶级家庭。今天，全球市值最大的公司是苹果公司，它的市值（2016年）超过6000亿美元，创造出来的财富超出了当年通用汽车公司一个数量级，仅账面上的现金就超过1000多亿美元。但是，苹果公司在全球只雇用了8万名员工而已。市值和苹果类似的 Google公司，雇的人更少。今天，进入Google公司要比被哈佛录取难得多，哈佛的录取率超过5%，而Google的还不到干分之二。也就是说，受益于苹果或者Google这类公司的人，远比20世纪50年代普通汽车厂装配工人的数量少很多。那么大量淘汰下来的劳动力怎么办？新毕业的学生如何就业？答案是要么去从事一份工资足够低的服务性工作，要么没有工作靠领取救济过活。因此在过去半个世纪里引领了信息革命大潮的美国，国民的中位数收入并没有提高。

ADD NOTE

HIGHLIGHT (YELLOW) • LOCATION 3444

在智能时代，一定会有一小部分人参与智能机器的研发和制造，这是所谓的新行业，但是这只会占到劳动力的很小一部分。虽然很多乐观主义者认为，将来一定会有新的行业适合人们工作，但是这需要时间一半个世纪的时间。然而智能革命并不打算给人类等待的时间，它已经到来了，接下来大家不得不考虑社会问题怎么解决。图7.12从互联网时代开始，美国有大学学历的中位数工资的变化

ADD NOTE

HIGHLIGHT (YELLOW) • LOCATION 3451

当税率过高时，实际上等于鼓励懒情，当全社会都不去创造财富而只考虑再分配时，经济就开始衰退了。其实，只要理性地思考这个问题，而不是感情冲动地仇富，就不难理解这个道理。事实上，富人的钱财除了少部分用于个人消费并购买了一些不动产〔14〕外，剩下来的钱并没有放在保险柜里，而是又投入了再生产。过高的税收意味着投入再生产的钱减少了。

ADD NOTE

HIGHLIGHT (YELLOW) • LOCATION 3461

2014年，美国收入在前1%的人贡献了美国45%的联邦税收，这要感谢奥巴马总统对富人的各种征税手段，在2013年这个比例是43%，2012年是40%。

所反对的这2%的人，美国早就成了三流国家，甚至混得比希腊还要惨。

ADD NOTE

〔15〕可以说，如果没有占领华尔街的人

HIGHLIGHT (YELLOW) • LOCATION 3476

到了智能革命之后，任何简单动脑的工作可能都要消失，甚至那些现在从事所谓高大上职业的人，也会失去工作。这一次由机器智能带来的革命，对社会的冲击将是全方位的，我们所依赖的那些所谓需要智力的工作也在消失。即使有新的行业出现，由于机器智能的影响，它们所需要的就业人数相比过去的老行业也会少很多。

ADD NOTE

HIGHLIGHT (YELLOW) • LOCATION 3482

其根源在于，很多人被社会进步所抛弃了。随着技术革命的发展，并非每一个人的发展机会都是越来越多的，反而可能是越来越少。

ADD NOTE

HIGHLIGHT (YELLOW) • LOCATION 3484

越来越多的事情人类将做不过机器。我们今后的决定，应该根据这个前提来做，


争当2%的人

HIGHLIGHT (YELLOW) • LOCATION 3488

就是踏上智能革命的浪潮。

ADD NOTE

争当2%的人在历次技术革命中，一个人、一家企业，甚至一个国家，可以选择的道路只有两条：要么进入前2%的行列，要么被淘汰。抱怨是没有用的。至于当下怎么才能成为这2%，其实很简单，

HIGHLIGHT (YELLOW) • LOCATION 3501

如果我们不可避免地要被那2%的人通过大数据和机器智能控制，与其抱怨，不如干脆加入他们的行列。如果你现在已经在其中了，那么恭喜你，如果还不在，那么应该加入进去。讲到这里，我想大家可能会有一个疑问，那就是“我们怎样才能加入他们的行列”。我想说的不是每个人都要到上述公司去找工作，而是希望大家接受一个新的思维方式，利用好大数据和机器智能。回顾从工业革命开始的前三次重大技术革命，首先受益的是和那些产业相关的人、善于利用新技术的人。虽然并非每一个人都能够去开发大数据和机器智能产品，但是应用这些技术远不像想象中的那么难。

ADD NOTE

HIGHLIGHT (YELLOW) • LOCATION 3519

除了可以像GE那样通过消耗性材料挣钱，一些冰箱公司开始考虑将冰箱看成商场里货架的扩展，通过摄像头和传感器，可以收集到顾客购买食物的习惯，以及顾客对食品消耗的程度，通过移动互联网提示用户补充食物。这种冰箱装有可以上网的触摸屏，顾客可以通过冰箱上的触摸屏直接从电子商务公司购买食品。这样，耐用电子产品又具有了商场货柜和电商入口的功能。虽然上述功能还没有完全实现，但是三星等公司已经在销售可以直接购物的智能冰箱的雏形了。